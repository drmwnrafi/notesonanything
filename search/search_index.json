{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"Welcome to Notes on Anything !!!        These are my notes on what I have learned, mostly in the fields of AI, control theory, and various robotics topics.      <p>Next Goals</p> <p>Artificial Inteligences</p> <ul> <li>Long run to all DeepSeek technical reports</li> <li>Neural Net Scaling Laws by Kaplan et al.</li> </ul> <p>Mathematics</p> <ul> <li>Mathematics for Machine Learning by Deisenroth et. al</li> <li>Add examples and proof in each probability section</li> <li>Lie Theory</li> <li>Hamilton's Quaternion </li> </ul> <p>Robotics</p> <ul> <li>Lyapunov Stability Theory</li> <li>Quadcopter MoE (Lagrangian Mechanic, Hamiltonian Mechanics) </li> <li>Model Predictive Control</li> <li>Data-Driven Control </li> </ul>"},{"location":"AI/preface/","title":"Artificial Intelligence","text":"<p>This section covers foundational concepts and advanced techniques in artificial intelligence, including attention mechanisms, popular models, and tokenizers.</p>"},{"location":"AI/preface/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Preface</li> <li>Attention Mechanism<ul> <li>Additive Attention</li> <li>Dot Product Attention</li> <li>Scaled-Dot Product Attention</li> <li>Multi-Head Attention</li> <li>Multi-Query Attention</li> <li>Grouped Query Attention</li> </ul> </li> <li>Models<ul> <li>Large Language Models<ul> <li>JPEG-LM</li> <li>LLAMA-2</li> </ul> </li> <li>Computer Vision<ul> <li>U-Net</li> <li>U2-Net</li> </ul> </li> </ul> </li> <li>Tokenizers<ul> <li>Byte-Pair Encoding</li> </ul> </li> <li>SpinalNet</li> </ul>"},{"location":"AI/spinal/","title":"SpinalNet: Deep Neural Network with Gradual Input","text":"<p>Paper PDF : https://arxiv.org/pdf/2007.03347.pdf</p> <p></p> <p></p> <p>SpinalNet purposed to achieve higher accuracy than DNN with fewer computations. This network was developed by H M Dipu Kabir, Moloud Abdar, and Seyed Mohammad Jafar Jalali. The network structure consists of input sub-layers, intermediate sub-layers, and an output layer. </p> <p>Spinal Net is mimicking human Samotosensory System and Spinal Cord. Samotosensory system is the sensory system responsibile for detecting and processing information related to touch, pressure, temperature, and pain. Spinal Cord is the part of the body that receives all the senses from the rest of the body. Samostosensory Systems and Spinal Cord are closely related,as the spinal cord serves as gateway for somatosensory information to reach the brain.</p> <p>Spinal Net aim to mimic the following characteristics of human spinal cord: </p> <ol> <li>Gradual input and nerve plexus</li> <li>Voluntary and involuntary actions</li> <li>Attention to pain intensity</li> </ol> <p>The nerve plexus is a complex network for sensory neuron to reach spinal cord. It network sends all tactile signals to the spinal cord gradually. Sensory neurons may also convey information to the lower motor before getting instruction from the brain, its called involuntary or reflex movements.</p> <p>SpinalNet implement 3 characteristics of human spinal cord as mentioned above : </p> <ol> <li>Gradual input</li> <li>Local output and probable global influence</li> <li>Weights reconfigured during training</li> </ol> <p>Similar to our spinal cord, the proposed SpinalNet takes inputs gradually and repetitively. Each layer of the SpinalNet contributes towards the local output (reflex). The SpinalNet also sends a modulated version of inputs towards the global output (brain). The NN training process configures weights based on the training data. Spinal cord neurons are also get configured for tuning the pain sensitivity of different sensories of our body. </p> <p>Fig (b). demonstrates the structure of SpinalNet. The network structure consists of input sub-layers, intermediate sub-layers, and an output layer. The input is split and sent to the intermediate sub-layers of multiple hidden layers. </p> <p>In Fig. (b), the intermediate sub-layers contain two neurons per hidden layer. The number of intermediate neurons can be changed according to the user. However, both the number of intermediate neurons and the number of inputs per layer are regularly kept small to reduce the number of multiplication. As typically the number of inputs and the intermediate hidden neurons per layer allocates a small amount, the network may have an under-fit shape. </p> <p>As a consequence, each layer receives inputs from the previous layer. Since the input is repeated, if one important feature of input does not impact the output in one hidden layer, the feature may impact the output in another hidden layer. The intermediate sub-layers contain a nonlinear activation function and the output layer contains the linear activation function. In Fig. (b), the input values are split into three rows. These rows are assigned to the different hidden layers in a repeated manner.</p>"},{"location":"AI/attention/add_att/","title":"Additive-Attention","text":"<p>As far as i know, Bahdanau et. al is the first who introduce \"Attention Mechanism\". Neural Machine Translation (NMT) at that time based on RNN variants with fixed-length vector context is the background. It cann't translated \"long sequences\" token due to difficulties capturing the relationship of preciding tokens. So, they invented an dynamics vector context. </p> <p>The encoder of Additive Attention based on Bidirectional RNN (BiRNN) to capture the relationships of preceding and following tokens. Simply, BiRNN is an forward (from \\(x_{start}\\) to \\(x_{end}\\)) and backward RNN (from \\(x_{end}\\) to \\(x_{start}\\)) (donated by bottom part in Fig1), where \\(x\\) is the input sequences. From forward and backward, RNN produced the hidden states \\(h_f\\) and \\(h_b\\) of each input sequences and concatetating both hidden states \\(h = \\left[ h_f ; h_b\\right]\\).  This annotation \\(h\\) contains the summaries of preciding and following token due to concat the \\(h_f\\) and \\(h_b\\).</p> <p>Info</p> <p>In terms of Transformers model, we can say hidden state of encoder (\\(h\\)) as query and hidden state of decoder (\\(s\\)) as key. </p> <p>The decoder fed annotations (\\(h_i\\)) and previous hidden states (\\(s_{t-i}\\)) to alignment model (attention scores) :</p> \\[ e_{t, i} = a(s_{t-1}, h_i) \\] <p>where \\(a(\\cdot)\\) is</p> \\[ a(s_{t-1}, h_i) = \\text{v}^T \\tanh(\\text{W}_h h_i + \\text{W}_s s_{t-1}) \\] <p>\\(a\\) can be parameterized by using FNN. The attention scores tell how good the input and the output matches. To get probability of attention scores, it applied to softmax.</p> \\[ \\alpha_{t,i} = \\text{softmax}(e_{t,i}) \\] <p>Then, applied a weighted sum of all source token to get context vector \\(c_i\\):</p> \\[ c_i = \\sum_{i=start}^{end} \\alpha_{t,i}h_i  \\] <p>This context vector \\(c_i\\) guides the generation of the predicted token by summarizing information from the encoder's hidden states (\\(h_j\\)), weighted by attention probabilities that are computed based on the previous hidden state of the decoder (\\(s_{t\u22121}\\)). Generate a prediction (\\(y\\)) by using hidden state for time-i (\\(s_i\\)), last output (\\(y_{t-1}\\)), and context vector (\\(c_i\\)).</p> \\[ y_i = \\text{Decoder}(y_{t-1}, s_{i-1}, c_i) \\] <p>We can use RNN or RNN-like architeture to generate next token as Decoder.</p> <p>Info</p> <p>The <code>+</code> operator makes this algorithm named by additive.</p> <pre><code>class AdditiveAttention(nn.Module):\n    \"\"\"\n    PDF Link : https://arxiv.org/pdf/1409.0473\n    \"\"\"\n    def __init__(self, embedding_size):\n        super(AdditiveAttention, self).__init__()\n        self.Wh = nn.Linear(embedding_size, embedding_size)\n        self.Ws = nn.Linear(embedding_size, embedding_size)\n        self.v = nn.Linear(embedding_size, 1)\n\n    def forward(self, annotations, hidden_state):\n        hidden_state = hidden_state.unsqueeze(1) # batch, 1, embedding_size\n        scores = self.v(self.Wh(annotations) + self.Ws(hidden_state)) # batch, seq_len, 1\n        weights = F.softmax(scores, dim=-1) # batch, seq_len, 1\n        context = torch.sum(weights * annotations, dim=1) # batch, embedding_size\n        return context\n</code></pre>"},{"location":"AI/attention/dot_att/","title":"Dot-Product Attention","text":"<p>To the best of my knowledge, Luong's Dot-Product Attention or Multiplicative Attention is the first introduced Dot-Product Attention. Luong's Attention is a resambles of Bahdanau's Additive Attention. Luong's purposed 3 different alternatives alingment functions.</p> FN [\\(a_t(h_t, \\hat{h}_s\\))] Content \\(h_t^T \\cdot \\hat{h}s\\) dot \\(h_t^T \\cdot \\textbf{W}_a\\hat{h}_s\\) general \\(v_a^T\\tanh(\\textbf{W}_a[h_t;\\hat{h}_s])\\) concat <p>We can see it compare to Bandahau's Attention, Luong's Attention doesn't use the last decoder state (\\(s_{i-1}\\)) and lesser learnable parameter, it means Luong's Attention require less computation. As Luong et. al stated on their paper, their's version of Attention doesn't require a Bidirectional RNN.</p> <pre><code>class MultiplicativeAttention(nn.Module):\n    \"\"\"\n    PDF Link : https://arxiv.org/abs/1508.04025\n    \"\"\"\n    def __init__(self, embedding_size):\n        super(MultiplicativeAttention, self).__init__()\n        self.Wa = nn.Linear(embedding_size, embedding_size)\n\n    def forward(self, annotations, hidden_state):\n        hidden_state = hidden_state.unsqueeze(1) # batch, 1, embedding_size\n        scores =  self.Wa(annotations) @ torch.transpose(hidden_state, -2,-1) # batch, seq_len, 1\n        weights = F.softmax(scores, dim=-1) # batch, seq_len, 1\n        context = torch.sum(weights * annotations, dim=1) # batch, embedding_size\n        return context\n</code></pre>"},{"location":"AI/attention/gqa/","title":"Group-Query Attention (GQA)","text":"<p>Group-Query Attention is a combination of multi head and multi query attention with one key and value heads of each sub-groups of query.</p> <ul> <li>Multi-Head Attention (MHA) : Every queries head have unique keys and values. Require big memory bandwidth, make it slow when inference. </li> <li>Multi-Query Attention (MQA) : Every queries heads have single keys and values. Less memory bandwidth compare to MHA, but the quality become less and lead instability while training.</li> <li>Grouped Query Attention (GQA) : Queries divides to G groups. Each group have unique keys and values. Less memory bandwidth than MHA, and better quality than MQA</li> </ul> <pre><code>class GroupedQueryAttention(nn.Module):\n    \"\"\"\n    PDF Link : https://arxiv.org/pdf/2305.13245\n    \"\"\"\n    def __init__(self, embedding_size, n_heads, n_kv_heads):\n        super(GroupedQueryAttention, self).__init__()\n        assert n_heads % n_kv_heads == 0, (\n            f\"Query heads ({n_heads}) is not divisible by key and value heads ({n_kv_heads}), \"\n            f\"which will result in a non-integer number of groups.\"\n        )\n\n        self.embedding_size = embedding_size\n        self.n_q_heads = n_heads\n        self.n_kv_heads = n_kv_heads\n        self.n_groups = self.n_q_heads // n_kv_heads\n        self.head_dim = embedding_size // n_heads\n\n        self.groups = nn.ModuleList([\n            MultiQueryAttention(embedding_size, self.n_groups) for _ in range(n_kv_heads)\n        ])\n        self.out_proj = nn.Linear(embedding_size*n_kv_heads, embedding_size)\n\n    def forward(self, x:torch.Tensor, mask:torch.BoolTensor=None):\n        batch, seq_len, _ = x.size() \n        output = torch.cat([mqa(x, mask) for mqa in self.groups], dim=-1)\n        output = output.contiguous().view(batch, seq_len, -1)\n        return self.out_proj(output)\n</code></pre>"},{"location":"AI/attention/mha/","title":"Multi-Head Attention (MHA)","text":""},{"location":"AI/attention/mqa/","title":"Multi-Query Attention (MQA)","text":"<pre><code>class MultiQueryAttention(nn.Module):\n    \"\"\"\n    PDF Link : https://arxiv.org/pdf/1911.02150\n    \"\"\"\n    def __init__(self, embedding_size:int, n_heads:int):\n        super(MultiQueryAttention, self).__init__()\n        assert embedding_size % n_heads == 0, (\n            f\"Embedding size ({embedding_size}) is not divisible by query heads ({n_heads}).\"\n        )\n        self.n_heads = n_heads\n        self.head_dim = embedding_size // n_heads\n        self.q_proj = nn.ModuleList([nn.Linear(embedding_size, self.head_dim) for _ in range(n_heads)])\n        self.k_proj = nn.Linear(embedding_size, self.head_dim)\n        self.v_proj = nn.Linear(embedding_size, self.head_dim)\n        self.out_proj = nn.Linear(embedding_size, embedding_size)\n\n    def forward(self, x:torch.Tensor, mask:torch.BoolTensor=None):\n        batch, seq_len, _ = x.size()\n        K = self.k_proj(x).view(batch, seq_len, 1, self.head_dim)\n        V = self.v_proj(x).view(batch, seq_len, 1, self.head_dim)\n        output = []\n        for i in range(self.n_heads):\n            Q = self.q_proj[i](x).view(batch, seq_len, 1, self.head_dim)\n            output.append(ScaleDotProduct(Q, K, V, mask))\n        output = torch.cat(output, dim=-1).contiguous().view(batch, seq_len, -1)\n        return self.out_proj(output)\n</code></pre>"},{"location":"AI/attention/scaled_dot_att/","title":"Scaled Dot-Product Attention","text":"<p>This method comes from a \"Kang\" paper, Attention is All You Need by Vaswani et al. </p> <p>We came at the most famous equation in last 5 years on DL fields.</p> \\[ \\text{Attention}(Q,K,V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V \\] <p>Basically, Scaled Dot-Product Attention based on Dot-Product Attention but scaled with size embbeding \\(d_k\\), \\(\\frac{1}{\\sqrt{d_k}}\\). </p> <p>Query, key, value, and output are all vectors but applied a basic Linear Layers to pack it as matrix Q, K, V, respectively. Dot-product attention compute more faster and space efficient.</p> <p>Scaled Dot-Product and Dot-Product have similar performance at small embedding \\(d_k\\), while Additive Attention perform better.</p> <pre><code>def ScaleDotProduct(Q:torch.Tensor, K:torch.Tensor, V:torch.Tensor, mask:torch.BoolTensor=None):\n    \"\"\"\n    PDF Link : https://arxiv.org/abs/1706.03762\n    \"\"\"\n    scores = torch.matmul(Q, K.transpose(-2, -1)) / (Q.size(-1)**0.5)\n    if mask != None:\n        scores = scores.masked_fill(mask.logical_not(), -torch.inf)\n    scores = F.softmax(scores, dim=-1)\n    scores = torch.matmul(scores, V)\n    return scores\n</code></pre>"},{"location":"AI/model/jpeg-lm/","title":"JPEG-LM","text":"<p>Paper PDF: https://arxiv.org/pdf/2408.08459</p> <p>I know this model from Hu-Po's stream (shout out to him, you have to check out his YouTube channel). JPEG-LM is an autoregressive LLM (a conventional LLM) designed for image generation. What interests me about this paper is its claim that the model does not require convolutional layers or positional embeddings.</p> <p>Quote</p> <p>We use conventional LLM architectures (autoregressive transformers) without any vision-specific modifications (no convolutions, no 2D positional embeddings) to maximize the models\u2019 generality. - X. Han, et.al (2024)</p>"},{"location":"AI/model/jpeg-lm/#pre-processing","title":"Pre-processing","text":"<p>Info</p> <p>For this blog, I only discuss image generation (the JPEG-LM paper also covers video generation). </p> <p>JPEG-LM treats image generation like \"text generation\". Since LLAMA-2 is an autoregressive model, the input should be in discrete tokens.  There are many techniques to discretize image data (images are continuous data), such as VQ-VAE, ViT, ImageGPT, etc.  This model converts images to bytes using JPEG and AVC/H.264 codecs for images and videos, respectively.  You can see how JPEG codecs look by opening a .jpg file in a text editor or see apendix.</p> <p>Since the output of JPEG codecs is in bytes, we can apply Byte-Pair Encoding (like encoding text in UTF-8, which also uses a byte representation).  See this blog post for more on BPE.</p>"},{"location":"AI/model/jpeg-lm/#training","title":"Training","text":"<p> JPEG-LM is pre-trained with LLAMA-2 7B from scratch. You can check my explanation about LLAMA-2 here.  Pre-training on LLAMA-2 is a good idea since JPEG-LM and LLAMA-2 differ in domains.  As you can see in the appendix jpeg codec, the byte representation of the right PixelArt image. The JPEG codec is unreadable by humans and meaningless in terms of human language, unlike the purposes of LLaMA-2. For the training process, they use 256x256 pixels with a quality factor of 25 over 23 million images.  They train BPE with 10k and set <code>vocab_size</code> to 320 with BPE. For efficiency, they concatenate all tokens and chunk them into <code>seq_len</code> 12k. Then, training proceeds like a typical autoregressive model. </p> <p>My Thoughts</p> <p>I'm not entirely sure why JPEG-LM doesn't need positional encoding, but to the best of my knowledge, positional encoding in transformers-like models helps determine the meaning of the same tokens in different contexts, as word order is important. However, in JEPG codec, the order of tokens is inherently tied to the structure of the byte representation of an image. The byte sequence of a JPEG file includes specific markers, headers, and compressed data blocks, which organize the image content in a way that preserves spatial relationships. This allows the model to predict the next token without requiring explicit positional encoding.</p> <p>For example, the Discrete Cosine Transform (DCT) involves 64 basis images to determine the low and high frequencies of each patch. This converts the pixel domain to a frequency domain, which spatially decorrelates the image content.  This means the spatial relationships and frequencies in the image are embedded within the compression format itself, especially in the ordering of coefficients from the DCT blocks.</p>"},{"location":"AI/model/jpeg-lm/#jpeg-codec","title":"JPEG Codec","text":"<p>JPEG stands for Joint Photographic Experts Group and is used to compress images with adjustable quality settings. JPEG-LM uses the JPEG codec to generate a string-basisd prompt, which is then tokenized with Byte Pair Encoding (BPE). An autoregressive model (a decode-only transformer) works only for discrete data, so since images are continuous data, they must first be discretized.</p>"},{"location":"AI/model/jpeg-lm/#color-space-transformation","title":"Color Space Transformation","text":"<p>In this step, the RGB image is converted to YCbCr, where Y represents luminance, and Cb &amp; Cr represent chrominance. Luminance captures brightness, while chrominance captures color information. To convert RGB to YCbCr, we use the following equations:</p> \\[ \\begin{align*} Y &amp;= 0.299 R + 0.587 G + 0.114 B \\\\ Cb &amp;= - 0.1687 R - 0.3313 G + 0.5 B + 128 \\\\ Cr &amp;= 0.5 R - 0.4187 G - 0.0813 B + 128 \\end{align*} \\] <p>Human eyes are more sensitive to brightness (luminance) than color (chrominance). Therefore, we can downsample chrominance by some factor without significant loss in visual quality.</p>"},{"location":"AI/model/jpeg-lm/#discrete-cosine-transform","title":"Discrete Cosine Transform","text":"<p>Before applying DCT, the original YCbCr image is divided into 8x8 blocks. Each block's pixel values are then shifted from a positive range to one centered on zero (from [0, 255] to [-128, 127]). After that, DCT is applied to each block using the following equation:</p> \\[ DCT_{u,v} = \\frac{1}{4} \\text{S}(u) \\text{S}(v) \\sum_{x=0}^7 \\sum_{y=0}^7 B_{x,y} \\cos\\left[\\frac{(2x+1)u\\pi}{16}\\right] \\cos\\left[\\frac{(2y+1)v\\pi}{16}\\right]  \\] <p>Here, \\(DCT_{u,v}\\) is the DCT coefficient at coordinates (u, v); u represents horizontal counts within a block, and v represents vertical counts. \\(B_{x,y}\\) is the pixel value at coordinate (x, y). \\(\\text{S}\\) is a normalizing scale factor, calculated by:</p> \\[ S(z) =  \\begin{cases}  \\frac{1}{\\sqrt{2}} &amp; \\text{if } z = 0 \\\\  1 &amp; \\text{otherwise}  \\end{cases} \\] <p>Each coordinate determines how much each of the 64 basis cosine functions influences the block. The Discrete Cosine Transform (DCT) converts spatial-domain data to frequency-domain data, helping to determine which pixels can be removed.</p> <p></p> 64 basis cosine patterns <p>These 64 basis cosines are the same for all images.</p>"},{"location":"AI/model/jpeg-lm/#quantization","title":"Quantization","text":"\\[ Q_{Y} = \\begin{bmatrix} 16 &amp; 11 &amp; 10 &amp; 16 &amp; 24 &amp; 40 &amp; 51 &amp; 61 \\\\ 12 &amp; 12 &amp; 14 &amp; 19 &amp; 26 &amp; 58 &amp; 60 &amp; 55 \\\\ 14 &amp; 13 &amp; 16 &amp; 24 &amp; 40 &amp; 57 &amp; 69 &amp; 56 \\\\ 14 &amp; 17 &amp; 22 &amp; 29 &amp; 51 &amp; 87 &amp; 80 &amp; 62 \\\\ 18 &amp; 22 &amp; 37 &amp; 56 &amp; 68 &amp; 109 &amp; 103 &amp; 77 \\\\ 24 &amp; 35 &amp; 55 &amp; 64 &amp; 81 &amp; 104 &amp; 113 &amp; 92 \\\\ 49 &amp; 64 &amp; 78 &amp; 87 &amp; 103 &amp; 121 &amp; 120 &amp; 101 \\\\ 72 &amp; 92 &amp; 95 &amp; 98 &amp; 112 &amp; 100 &amp; 103 &amp; 99 \\end{bmatrix} \\] <p>Quantization introduces most of the information loss in this process. To quantize the DCT coefficients, we use the following equation:</p> \\[ \\text{Quant}_{x,y} = \\text{round}\\left(\\frac{\\text{DCT}_{x,y}}{Q_{x,y}}\\right) \\]"},{"location":"AI/model/jpeg-lm/#listing","title":"Listing","text":"<p>Each quantized 8x8 block is organized in a zigzag pattern, followed by run-length encoding and then Huffman encoding for further compression.</p> <p></p>"},{"location":"AI/model/jpeg-lm/#run-length-encoding","title":"Run-Length Encoding","text":"<p>Run-length encoding (RLE) simplifies redundant values in the quantized block to reduce memory usage. For example,</p> Before RLE After RLE AAAABBBCCDAA 4A3B2C1D2A <p>The RLE version is further compressed using Huffman encoding. </p>"},{"location":"AI/model/jpeg-lm/#huffman-encoding","title":"Huffman Encoding","text":"<p>Huffman encoding compresses the RLE output by assigning shorter codes to more frequent symbols and longer codes to less frequent symbols.</p>"},{"location":"AI/model/jpeg-lm/#appendix","title":"Appendix","text":""},{"location":"AI/model/jpeg-lm/#jpeg-codecs","title":"JPEG Codecs","text":"Original Bytes UTF-8 FF D8 FF E0 00 10 4A 46 49 46 00 01 01 00 00 01 00 01 00 00 FF DB 00 43 00 08 06 06 07 06 05 08 \ufffd\ufffd\ufffd\ufffd\u0010JFIF\ufffd\ufffdC\b\u0006\u0006\u0007\u0006\u0005\b 07 07 07 09 09 08 0A 0C 14 0D 0C 0B 0B 0C 19 12 13 0F 14 1D 1A 1F 1E 1D 1A 1C 1C 20 24 2E 27 20 \u0007\u0007\u0007 \b \f\u0014 \f\u000b\u000b\f\u0019\u0012\u0013\u000f\u0014\u001d\u001a\u001f\u001e\u001d\u001a\u001c\u001c $.' 22 2C 23 1C 1C 28 37 29 2C 30 31 34 34 34 1F 27 39 3D 38 32 3C 2E 33 34 32 FF DB 00 43 01 09 09 \",#\u001c\u001c(7),01444\u001f'9=82&lt;.342\ufffd\ufffdC 09 0C 0B 0C 18 0D 0D 18 32 21 1C 21 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 \f\u000b\f\u0018 \u00182!\u001c!22222222222222222222 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 FF C0 222222222222222222222222222222\ufffd\ufffd 00 11 08 00 10 00 10 03 01 22 00 02 11 01 03 11 01 FF C4 00 1F 00 00 01 05 01 01 01 01 01 01 00 \u0011\b\u0010\u0010\"\u0011\u0011\ufffd\ufffd\u001f\u0005 00 00 00 00 00 00 00 01 02 03 04 05 06 07 08 09 0A 0B FF C4 00 B5 10 00 02 01 03 03 02 04 03 05 \u0005\u0006\u0007\b \u000b\ufffd\ufffd\ufffd\u0010\u0005 05 04 04 00 00 01 7D 01 02 03 00 04 11 05 12 21 31 41 06 13 51 61 07 22 71 14 32 81 91 A1 08 23 \u0005}\u0011\u0005\u0012!1A\u0006\u0013Qa\u0007\"q\u00142\ufffd\ufffd\ufffd\b# 42 B1 C1 15 52 D1 F0 24 33 62 72 82 09 0A 16 17 18 19 1A 25 26 27 28 29 2A 34 35 36 37 38 39 3A B\ufffd\ufffd\u0015R\ufffd\ufffd$3br\ufffd \u0016\u0017\u0018\u0019\u001a%&amp;'()*456789: 43 44 45 46 47 48 49 4A 53 54 55 56 57 58 59 5A 63 64 65 66 67 68 69 6A 73 74 75 76 77 78 79 7A CDEFGHIJSTUVWXYZcdefghijstuvwxyz 83 84 85 86 87 88 89 8A 92 93 94 95 96 97 98 99 9A A2 A3 A4 A5 A6 A7 A8 A9 AA B2 B3 B4 B5 B6 B7 \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd B8 B9 BA C2 C3 C4 C5 C6 C7 C8 C9 CA D2 D3 D4 D5 D6 D7 D8 D9 DA E1 E2 E3 E4 E5 E6 E7 E8 E9 EA F1 \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd F2 F3 F4 F5 F6 F7 F8 F9 FA FF C4 00 1F 01 00 03 01 01 01 01 01 01 01 01 01 00 00 00 00 00 00 01 \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\u001f 02 03 04 05 06 07 08 09 0A 0B FF C4 00 B5 11 00 02 01 02 04 04 03 04 07 05 04 04 00 01 02 77 00 \u0005\u0006\u0007\b \u000b\ufffd\ufffd\ufffd\u0011\u0007\u0005w 01 02 03 11 04 05 21 31 06 12 41 51 07 61 71 13 22 32 81 08 14 42 91 A1 B1 C1 09 23 33 52 F0 15 \u0011\u0005!1\u0006\u0012AQ\u0007aq\u0013\"2\ufffd\b\u0014B\ufffd\ufffd\ufffd\ufffd #3R\ufffd\u0015 62 72 D1 0A 16 24 34 E1 25 F1 17 18 19 1A 26 27 28 29 2A 35 36 37 38 39 3A 43 44 45 46 47 48 49 br\ufffd \u0016$4\ufffd%\ufffd\u0017\u0018\u0019\u001a&amp;'()*56789:CDEFGHI 4A 53 54 55 56 57 58 59 5A 63 64 65 66 67 68 69 6A 73 74 75 76 77 78 79 7A 82 83 84 85 86 87 88 JSTUVWXYZcdefghijstuvwxyz\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 89 8A 92 93 94 95 96 97 98 99 9A A2 A3 A4 A5 A6 A7 A8 A9 AA B2 B3 B4 B5 B6 B7 B8 B9 BA C2 C3 C4 \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd C5 C6 C7 C8 C9 CA D2 D3 D4 D5 D6 D7 D8 D9 DA E2 E3 E4 E5 E6 E7 E8 E9 EA F2 F3 F4 F5 F6 F7 F8 F9 \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd FA FF DA 00 0C 03 01 00 02 11 03 11 00 3F 00 C5 F8 73 6B A5 78 7F C0 67 C4 D7 96 AF 7D 25 CD D9 \ufffd\ufffd\ufffd\f\u0011\u0011?\ufffd\ufffdsk\ufffdx\u007f\ufffdg\ufffd\u05d6\ufffd}%\ufffd\ufffd 85 C5 90 F3 24 89 06 02 AC 99 23 68 0C 0B 10 3A 86 8C 9C F1 83 E2 35 AE 95 E2 0F 01 8F 13 59 DA \ufffd\u0150\ufffd$\ufffd\u0006\ufffd\ufffd#h\f\u000b\u0010:\ufffd\ufffd\ufffd\ufffd\ufffd5\ufffd\ufffd\ufffd\u000f\ufffd\u0013Y\ufffd BD 8C 96 D7 62 14 17 A3 CB 92 54 39 0C B1 E0 9D C0 B1 0C 01 E8 16 42 31 CE 5D F0 7F 50 D3 4E 8F \ufffd\ufffd\ufffd\ufffdb\u0014\u0017\ufffd\u02d2T9\f\ufffd\ufffd\ufffd\ufffd\ufffd\f\ufffd\u0016B1\ufffd]\ufffd\u007fP\ufffdN\ufffd 7B 6C B2 C7 61 75 6D 89 6E 64 6C 7E F9 49 6F DE B1 27 21 10 7C A7 3F 2A E4 1C E5 CD 1F 18 35 0D {l\ufffd\ufffdaum\ufffdndl~\ufffdIo\u07b1'!\u0010 34 68 F6 56 CD 2C 77 F7 57 39 96 DA 45 C7 EE 54 15 FD EA 90 72 51 C7 CA 31 F2 B6 09 CE 50 54 5A 4h\ufffdV\ufffd,w\ufffdW9\ufffd\ufffdE\ufffd\ufffdT\u0015\ufffd\ufffdrQ\ufffd\ufffd1\ufffd \ufffdPTZ 17 BD B5 3C DB FF 00 B5 5F 93 E7 75 FE 7F 81 FF D9 \u0017\ufffd\ufffd&lt;\ufffd\ufffd\ufffd_\ufffd\ufffdu\ufffd\u007f\ufffd\ufffd\ufffd"},{"location":"AI/model/llama2/","title":"LLAMA-2","text":"<p>Paper PDF : https://arxiv.org/pdf/2307.09288</p> <p>Llama 2 is a decoder-only transformer model from Meta.</p> <p></p>"},{"location":"AI/model/llama2/#rotary-positional-embeddings-rope","title":"Rotary Positional Embeddings (RoPE)","text":"<p>The Self-Attention mechanism is inherently agnostic to the order of tokens in a sequence. So, Vaswani et.al used Absolute Positional Embeddings using a sinusoidal function or a learnable parameter. The disadvantage is that it doesn't capture relative positional information (e.g., the distance between two tokens). In natural language, the meaning of words often depends on their relative positions. For example, the first word in a sentence can relate to the last word.</p> <p>Absolute Positional Embedding using a learnable parameter also cannot capture position information if input sequences are larger than max training sequences, leading to poor predictions if using sinusoidal, as referred to in ALiBi.</p> <p>To tackle that problem, Shawn et. al proposed modifying the self-attention formula to capture relative positions by adding relative position information to key and value tensors as learnable parameters. The disadvantages are inefficient complexity, where larger sequence lengths require more time for training and inference, and it cannot be applied with KV Cache because every time a new token is added, it must recalculate the relative positional embedding.</p> <p>Then in 2023, Su et. al proposed RoPE, which captures both absolute and relative information. It involves a rotation matrix\u2014similar to SO(2) for 2D\u2014and is applied only to queries \\(W_q\\) and keys \\(W_k\\) weights. In 2D vector embeddings, it can be computed as follows:</p> \\[ f_{\\{q,k\\}}(x_m, m) = \\begin{pmatrix}  \\cos m\\theta &amp; -\\sin m\\theta \\\\ \\sin m\\theta &amp; \\cos m\\theta  \\end{pmatrix}  \\begin{pmatrix}  W_{\\{q,k\\}}^{(11)} &amp; W_{\\{q,k\\}}^{(12)} \\\\ W_{\\{q,k\\}}^{(21)} &amp; W_{\\{q,k\\}}^{(22)} \\\\ \\end{pmatrix}  \\begin{pmatrix}  x_m^{(1)} \\\\ x_m^{(2)}  \\end{pmatrix} \\] <p>The first right-hand term defines the absolute position with \\(m\\) as the index of the token or word, and the last term is the vector to be rotated. For D-dimensions &gt; 2, it scales up the 2D rotation matrix</p> \\[ f_{\\{q,k\\}}(x_m, m) = R_{\\Theta,m}^{d} W_{\\{q,k\\}} x_m \\] <p>with \\(R_{\\Theta,m}^{d}\\),</p> \\[ R_{\\Theta,m}^{d} =  \\begin{pmatrix} \\cos m \\theta_1 &amp; -\\sin m \\theta_1 &amp; 0 &amp; 0 &amp; \\dots &amp; 0 &amp; 0  \\\\ \\sin m \\theta_1 &amp; \\cos m \\theta_1 &amp; 0 &amp; 0 &amp; \\dots &amp; 0 &amp; 0  \\\\ 0 &amp; 0 &amp; \\cos m \\theta_2 &amp; -\\sin m \\theta_2 &amp; \\dots &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; \\sin m \\theta_2 &amp; \\cos m \\theta_2 &amp; \\dots &amp; 0 &amp; 0 \\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots &amp; \\vdots \\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; \\dots &amp; \\cos m \\theta_{d/2} &amp; -\\sin m \\theta_{d/2} \\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; \\dots &amp; \\sin m \\theta_{d/2} &amp; \\cos m \\theta_{d/2} \\\\ \\end{pmatrix} \\] <p>In the RoPE paper, they define \\(\\Theta = \\{ \\theta_i = 10000^{-2(i-1)/d}, \\, i \\in [1, 2, \\dots, d/2] \\}\\). Then,</p> \\[ q^T_m k_n = \\left( x^T W_q (R^d_{\\Theta,m})^TR^d_{\\Theta,n} W_k x_n \\right) \\] <p>Now, we can see from the equation above that it handles relative position, shown by \\((R^d_{\\Theta,m})^TR^d_{\\Theta,n}\\), called the relative rotation matrix.</p>"},{"location":"AI/model/llama2/#root-mean-square-normalization-rms-norm","title":"Root Mean Square Normalization (RMS Norm)","text":"<p>The Vanilla Transformers Model (Encoder-Decoder) uses Layer Norm for normalization. LayerNorm normalizes the activations across the features dimension for each individual input (instead of across the batch, as in BatchNorm). We use normalization because we don\u2019t want our network learning in one direction due to large gradients between layers.</p> <p></p> <p>LayerNorm takes the means and variances of each individual input, re-centering and re-scaling the input. LayerNorm can be determined by:</p> \\[y = \\frac{x - \\mu}{\\sqrt{Var[x]-\\epsilon}} * \\gamma + \\beta \\] <p>Where \\(x\\) is the input, \\(\\mu\\) and \\(Var[x]\\) are the mean and variance of x across the features dimension, and \\(\\gamma\\) and \\(\\beta\\) are learnable params that tune the effect of re-scaling and re-centering invariance.</p> <p>Root Mean Square Normalization (RMSNorm) is a simplified version of LayerNorm. The authors of the RMSNorm paper by B. Zhang (2019) hypothesized that the re-centering part of LayerNorm doesn't contribute significantly during training. Therefore, the network can be more efficient since we don\u2019t need to calculate the mean. Root Mean Square is a statistical function that doesn't require the mean.</p> \\[y = \\frac{x}{RMS(x)} * \\gamma\\]"},{"location":"AI/model/llama2/#grouped-query-attention-gqa","title":"Grouped Query Attention (GQA)","text":"<p>Grouped Query Attention is an interpolation between Multi Query Attention and Multi-Head Attention. GQA uses one head of keys and values for each sub-group. The number of groups in GQA can be determined by:</p> \\[n_{groups} = \\frac{n_{Q heads}}{n_{{KV heads}}}\\] <p>Multi-Head Attention (MHA) slows during inference due to the large memory bandwidth cost when loading keys and values N. Shazeer (2019). As explained by Umar Jamil, GPU calculations are faster than memory bandwidth (the speed at which the GPU can access data in VRAM). It\u2019s better to (1) perform the same operations on the same tensor N times than (2) perform the same operations on different tensors N times because, in case (1), the tensor is only traveled once. This is the rationale behind Multi-Query Attention (MQA); MQA uses one set of keys and values shared across all queries, requiring less KV cache than MHA and speeding up decoder inference. J. Ainslie (2023) stated that MQA can lead to quality degradation and training instability, so they proposed Grouped Query Attention (GQA), which balances quality and speed during training and inference.</p> <p></p> <p>In the graphic above, when KV heads = 1 (\\(n_{groups} = n_{Q heads}\\)), it\u2019s more like MHA, and when KV heads = Q heads (\\(n_{groups} = 1\\)), it\u2019s more like MQA.</p>"},{"location":"AI/model/llama2/#kv-cache","title":"KV Cache","text":"<p>Basic decoder-only inference computes the dot product of key and value tensors for all tokens with quadratic time complexity, making the model slow during inference. KV cache is a mechanism that stores keys and values tensors of processed previous tokens in VRAM, so we only compute current queries to cached keys and values tensor.</p> <p></p> <p>As you can see, KV-Cache only works with the last query and doesn't involve the previous query, making the dot product calculation more efficient (note that its dimension is mostly 1).</p>"},{"location":"AI/model/llama2/#swiglu-activation-function","title":"SwiGLU Activation Function","text":"<p>SwiGLU is an extension of the Swish activation function with \\(\\beta = 1\\), also known as SiLU (Sigmoid Linear Unit), and combines elements from the GLU (Gated Linear Unit) activation function. Based on the SwiGLU paper by Shazeer, this activation function outperforms other activation functions like GLU, Bilinear, GeGLU, and ReGLU.</p> <p>The SiLU function, also referred to as Swish, can be defined as:</p> \\[ \\text{SiLU}(x) = x \\left(\\frac{1}{1 + e^{-x}}\\right) \\] <p>GLU, on the other hand, is a neural network layer that performs a component-wise product of two linear transformations of the input, with one transformation applied with a Sigmoid function:</p> \\[ \\text{GLU}(x) = \\sigma(xW + b_1) \\otimes (xV + b_2) \\] <p>For a feed-forward network (FFN) layer with GLU, we have:</p> \\[ \\text{FFNGLU}(x, W, V, W_2) = (\\sigma(xW) \\otimes xV) W_2 \\] <p>To use SwiGLU in an FFN layer, simply replace the Sigmoid function \\(\\sigma\\) in FFNGLU with SiLU:</p> \\[ \\text{FFNSwiGLU}(x, W, V, W_2) = (\\text{SiLU}(xW) \\otimes xV) W_2 \\] <p>In the paper, the authors reduce the second dimension of matrices \\(\\bf{W}\\) and \\(\\bf{V}\\), as well as the first dimension of \\(\\bf{W_2}\\), by a factor of \\(\\frac{2}{3}\\) to maintain constant computational cost.</p> <p>However, the exact reason why SwiGLU outperforms other activation functions is not explicitly defined in the paper.</p> <p></p>"},{"location":"AI/model/llama2/#appendix","title":"Appendix","text":""},{"location":"AI/model/llama2/#rmsnorm-code","title":"RMSNorm Code","text":"<pre><code>class RMSNorm(nn.Module):\n    def __init__(self, config):\n        super(RMSNorm, self).__init__()\n        self.eps = config.rms_norm_eps\n        self.weight = nn.Parameter(torch.ones(config.embedding_size))\n\n    def forward(self, x: torch.Tensor):\n        denom = torch.sqrt(x.pow(2).mean(-1, keepdim=True) + self.eps)\n        return ((self.weight * x) / denom).type_as(x)\n</code></pre>"},{"location":"AI/model/llama2/#rope","title":"RoPE","text":"<pre><code>class RoPE(nn.Module):\n    def __init__(self, head_dim:int, config):\n        super(RoPE, self).__init__()\n        assert head_dim % 2 == 0, \"Dimension must be even (divisible by 2)\"\n        theta = 1 / config.rope_theta ** (torch.arange(0, head_dim, 2).float() / head_dim)\n        self.register_buffer(\"theta\", theta)\n\n    @torch.no_grad()\n    def forward(self, x: torch.Tensor):\n        device = x.device\n        self.theta = self.theta.to(device)\n        m = torch.arange(x.size(1), device=device)\n        frequencies = torch.outer(m, self.theta)\n        frq_complex = torch.exp(1j * frequencies)\n        x_complex = torch.view_as_complex(x.reshape(*x.shape[:-1], -1, 2))\n        freq = frq_complex.unsqueeze(0).unsqueeze(2)\n        x_rotated = x_complex * freq\n        x_rope = torch.stack((x_rotated.real, x_rotated.imag), dim=-1)\n        x_rope = torch.flatten(x_rope, start_dim=-2)\n        return x_rope.type_as(x)\n</code></pre>"},{"location":"AI/model/llama2/#scaled-dot-product","title":"Scaled-dot Product","text":"<pre><code>def ScaledDotProduct(Q: torch.Tensor, K: torch.Tensor, V: torch.Tensor, mask: torch.Tensor = None):\n    scores = torch.matmul(Q, K.transpose(-2, -1)) / (Q.size(-1) ** 0.5)\n    if mask is not None:\n        mask = mask.unsqueeze(1)\n        scores = scores.masked_fill(mask == 0, -torch.inf)\n    scores = F.softmax(scores, dim=-1)\n    scores = torch.matmul(scores, V)\n    return scores\n</code></pre>"},{"location":"AI/model/llama2/#grouped-query-attention","title":"Grouped Query Attention","text":"<pre><code>class GroupedQuery(nn.Module):\n    def __init__(self, config):\n        super(GroupedQuery, self).__init__()\n        assert config.n_q_heads % config.n_kv_heads == 0, (\n            f\"{RED}Query heads ({config.n_q_heads}) is not divisible by key and value heads ({config.n_kv_heads}), \"\n            f\"which will result in a non-integer number of groups. {END}\"\n        )\n        self.n_q_heads = config.n_q_heads\n        self.n_kv_heads = config.n_kv_heads\n        self.n_groups = config.n_q_heads // config.n_kv_heads\n        self.head_dim = config.embedding_size // self.n_q_heads\n\n        self.q_proj = nn.Linear(config.embedding_size, self.n_q_heads * self.head_dim, bias=config.bias)\n        self.k_proj = nn.Linear(config.embedding_size, self.n_kv_heads * self.head_dim, bias=config.bias)\n        self.v_proj = nn.Linear(config.embedding_size, self.n_kv_heads * self.head_dim, bias=config.bias)\n        self.out_proj = nn.Linear(self.head_dim* self.n_q_heads, config.embedding_size, bias=config.bias_out)\n\n        self.cache_k = torch.zeros(config.max_batch, config.max_seq_len, self.n_kv_heads, self.head_dim)\n        self.cache_v = torch.zeros(config.max_batch, config.max_seq_len, self.n_kv_heads, self.head_dim)\n\n        self.rope = RoPE(self.head_dim, config)\n\n    def forward(self, x: torch.Tensor, mask: torch.Tensor = None, start_pos:int = 0, use_rope:bool=True,):\n        batch, seq_len, _ = x.size()\n\n        K = self.k_proj(x).view(batch, seq_len, self.n_kv_heads, self.head_dim).transpose(1,2)\n        V = self.v_proj(x).view(batch, seq_len, self.n_kv_heads, self.head_dim).transpose(1,2)\n        Q = self.q_proj(x).view(batch, seq_len, self.n_q_heads, self.head_dim).transpose(1,2)\n\n        if use_rope:\n            K = self.rope(K)\n            Q = self.rope(Q)\n\n        if use_cache and start_pos is not None:\n            self.cache_k[:batch, start_pos:start_pos+seq_len] = K\n            self.cache_v[:batch, start_pos:start_pos+seq_len] = Q\n\n            K = self.cache_k[:batch_size, 0:start_pos+seq_len]\n            V = self.cache_v[:batch_size, 0:start_pos+seq_len]\n\n        K = torch.repeat_interleave(K, self.n_groups, dim=1)\n        V = torch.repeat_interleave(V, self.n_groups, dim=1)\n\n        attn = ScaledDotProduct(Q, K, V, mask).transpose(1,2)\n        output = attn.contiguous().view(batch, seq_len, -1)\n        return self.out_proj(output)\n</code></pre>"},{"location":"AI/model/llama2/#swiglu","title":"SwiGLU","text":"<pre><code>class SwiGLU(nn.Module):\n    def __init__(self, config):\n        super(SwiGLU, self).__init__()\n\n    def sigmoid(self, x: torch.Tensor):\n        return 1 / (1 + torch.exp(-x * 1))\n\n    def forward(self, x: torch.Tensor):\n        return x * self.sigmoid(x)\n</code></pre>"},{"location":"AI/model/llama2/#feed-forward","title":"Feed Forward","text":"<pre><code>class FeedForward(nn.Module):\n    def __init__(self, config):\n        super(FeedForward, self).__init__()\n        self.fc1 = nn.Linear(config.embedding_size, config.intermediate_dim, bias=config.bias_out)\n        self.fc2 = nn.Linear(config.embedding_size, config.intermediate_dim, bias=config.bias_out)\n        self.fc3 = nn.Linear(config.intermediate_dim, config.embedding_size, bias=config.bias_out)\n        self.silu = nn.SiLU()\n\n    def forward(self, x: torch.Tensor):\n        x1 = self.silu(self.fc1(x))\n        x2 = self.fc2(x)\n        x = x1 * x2\n        return self.fc3(x)\n</code></pre>"},{"location":"AI/model/llama2/#decoder","title":"Decoder","text":"<pre><code>class Decoder(nn.Module):\n    def __init__(self, config):\n        super(Decoder, self).__init__()\n        self.RMSNorm = RMSNorm(config)\n        self.GQA = GroupedQuery(config)\n        self.FFN = FeedForward(config)\n\n    def forward(self, x: torch.Tensor, mask: torch.Tensor, pos_emb:bool = True):\n        x1 = x\n        x = self.RMSNorm(x)\n        x = self.GQA(x, mask, pos_emb)\n\n        x2 = x1 + x\n        x = self.RMSNorm(x2)\n        x = self.FFN(x)\n\n        return x2 + x\n</code></pre>"},{"location":"AI/model/llama2/#llama-2_1","title":"LLAMA-2","text":"<pre><code>class Model(nn.Module):\n    def __init__(self, config):\n        super(Model, self).__init__()\n        self.token_embedding = nn.Embedding(config.vocab_size, config.embedding_size)\n        self.layers = nn.ModuleList([\n            Decoder(config) for _ in range(config.n_layers)\n        ])\n        self.RMSNorm = RMSNorm(config)\n        self.fc_out = nn.Linear(config.embedding_size, config.vocab_size, bias=config.bias_out)\n\n    def forward(self, tokens, mask: torch.Tensor = None):\n        x = self.token_embedding(tokens)\n        for layer in self.layers:\n            x = layer(x, mask, False)\n        x = self.RMSNorm(x)\n        return self.fc_out(x)\n</code></pre>"},{"location":"AI/model/u2_net/","title":"U<sup>2</sup>-NET","text":"<p>Paper PDF : https://arxiv.org/pdf/2005.09007.pdf</p> <p>U<sup>2</sup>-Net or U2-Net or U-shaped Net is a U-Net like architecture. U2-Net is a two-level nested U-structure architecture that is designed for salient object detection (SOD). The architecture allows the network to go deeper, attain high resolution, without significantly increasing the memory and computation cost. This is achieved by a nested U-structure: on the bottom level, with a novel ReSidual U-block (RSU) module, which is able to extract intra-stage multi-scale features without degrading the feature map resolution; on the top level, there is a U-Net like structure, in which each stage is filled by a RSU block </p> <p></p>"},{"location":"AI/model/u2_net/#residual-u-block-rsu-l","title":"Residual U-Block (RSU-L)","text":"<p>RSU-L used to capture intra-stage multi-scale features. The structure of RSU-L <code>(C<sub>in</sub>, M, C<sub>out</sub>)</code> is shown in Fig. 1, where <code>L</code> is the number of layers in the encoder, <code>C<sub>in</sub>, C<sub>out</sub></code>denote input and output channels, and <code>M</code> denotes the number of channels in the internal layers of RSU.</p> <p>Three components of RSU-L : 1. Input convolutional layers, this step convert a feature map <code>(H \u00d7 W \u00d7 C<sub>in</sub>)</code> to intermediate map, this is a plain convolutional layer for local feature extraction. This step consists of convolutional layer with 3x3 filter size, Batch Normalization, and ReLU activation.</p> <ol> <li> <p>Encoder (downsampling) - Decoder (upsampling) U-Net like. In this step, the input is the output of step one and learns to extract and encode the multi-scale contextual information. The <code>L</code> letter in RSU-L refers to the depth of architecture (shown in Fig. 2 [L = 7, it's mean RSU-7]).  Larger <code>L</code> leads to deeper residual U-block (RSU), more pooling operations, larger range of receptive fields and richer local and global features. The output of downsampling at each level will be saved for skip connections, and concatenate in decoder for the better output. Same as downsampling, the decoder use progressive upsampling, to avoid loss of detail caused by direct upsampling with large scales.</p> </li> <li> <p>The Add layers fuse local features (output of step one) and the multi-scale features (output of step two) to produce the output.</p> </li> </ol>"},{"location":"AI/model/u2_net/#u2-net-architecture","title":"U<sup>2</sup>-Net Architecture","text":"<p>The U2-Net architecture is like U-Net but consists of Residual U-Block (RSU-L) at each stage, while U-Net use convolutional block. U<sup>2</sup>-Net is a nested U-structured with U<sup>n</sup>-Net formulation (n = 2). U2-Net mainly consists of three parts : a six stages encoder (some say last of them is a bridge), a five stages decoder, and saliency map fusion module attached with the decoder stages and the bridge stage.</p> <p><code>I : Input Channels</code></p> <p><code>M : Intermediate Channels</code></p> <p><code>O : Output Channels</code></p> <p></p> <p>In picture above, U2-Net has 2 different values of <code>I, M, and O</code>,  but the structure of the RSU-L stage remains consistent throughout the network. <code>RSU-7, RSU-6, RSU-5, RSU-4, RSU-4F</code> are the encoders and types of RSU-L blocks used with different input parameters. Than, the 2 others <code>RSU-4F</code> are bridge and first decoder, the last three RSU-L <code>RSU-4, RSU-5, RSU-6, RSU-7</code> serve as decoders blocks. The last part, all of the outputs from bridge and decoders are concatenated to generate the final output using <code>sigmoid</code> activation function to classify.</p>"},{"location":"AI/model/u_net/","title":"U-NET","text":"<p>Paper PDF : https://arxiv.org/pdf/1505.04597.pdf</p> <p></p> <p>U-Net is an architecture developed by Olaf Ronneberger, Philipp Fischer, and Thomas Brox for Biomedical image segmentation. They won the ISBI (International Symposium on Biomedical Imaging) cell tracking challenge 2015 in New York.</p>"},{"location":"AI/model/u_net/#u-net-architecture","title":"U-Net Architecture","text":"<p>It is named as \"U-Net\" cause it has U-shape network architecture. U-Net architecture consists of three parts :  contracting path or encode (left side), expansive path or decode (right side), and skip connection.</p>"},{"location":"AI/model/u_net/#contracting-path-or-encoder","title":"Contracting Path or Encoder","text":"<p>The Contracting Path or Encoder acts as a feature extractor. The Encoder consists of two convolutional layers with downsampling using a 3x3 filter size, ReLU activation, and a 2x2 max pooling operation. The Encoder step is repeated four times, with the number of features increasing by a factor of two at each step (64, 128, 256, 512). In this step, the output of the last convolutional layer in each Encoder cycle is transferred over the skip connection.</p>"},{"location":"AI/model/u_net/#skip-connections","title":"Skip Connections","text":"<p>Skip connections are used to retain spatial information because the Encoder reduces the spatial information from the input. Skip connections involve concatenating the feature maps from the Encoder to the output of the corresponding Transposed Convolutional layer. This process occurs within the same step of the architecture.</p>"},{"location":"AI/model/u_net/#bridge","title":"Bridge","text":"<p>Bridge in U-Net refers to the middle part of the architecture that connects the encoder and de coder. It consists of two 3x3 convolutions with 1024 number of filters, where each convolution is followed by a ReLU activation function.</p>"},{"location":"AI/model/u_net/#expansive-path-or-decoder","title":"Expansive Path or Decoder","text":"<p>Expansive path or decoder is responsible for upsampling the feature maps and generating the final output. Decoder uses transposed convolutional layers (also known as deconvolution layers). Decoder consist of 2x2 transposed convolutional and concatenate with the feature maps on skip connections. After that, two 3x3 convolutions are used, where each convolution is followed by a ReLU activation function. The output of the last decoder passes through a 1x1 convolution with sigmoid activation. The sigmoid activation function gives the segmentation mask representing the pixel-wise classification.</p>"},{"location":"AI/tokenizer/bpe/","title":"Byte-Pair Encoding","text":"<p>Paper PDF: https://arxiv.org/pdf/1508.07909</p> <p>Byte-Pair Encoding (BPE) was introduced by Sennrich et al. in 2016. The problem addressed in this paper relates to the limitations of traditional Neural Machine Translation (NMT) models when dealing with out-of-vocabulary (OOV) words, which can be challenging for agglutinative and compound words.</p> <p>Imagine we have the following two words in a trained tokenizer:</p> word<sub>1</sub> word<sub>2</sub> foot ball <p>If the word <code>football</code> appears in our dataset during the training process, the tokenizer would treat it as <code>&lt;unk&gt;</code> (unknown) tokens, as it does not exist in the vocabulary.</p> <p>To address this issue, Sennrich et al. proposed using byte-pair encoding (BPE). BPE allows vocabulary representation based on subwords with a fixed size. It replaces the most frequent byte pair with an unused byte.</p> <p>Byte-pair encoding works as follows:</p> <ul> <li>Represent each word as a sequence of characters and add a special character at the end of each word.</li> <li>Count all character pairs.</li> <li>Replace the most frequent character pair with a new character (e.g., replace the pair ('C', 'B') with 'CB').</li> <li>Repeat iteratively until the desired vocabulary size (<code>vocab_size</code>) is reached.</li> </ul> <pre><code>import re, collections\n\ndef get_stats(vocab):\n    pairs = collections.defaultdict(int)\n    for word, freq in vocab.items():\n        symbols = word.split()\n        for i in range(len(symbols) - 1):\n            pairs[symbols[i], symbols[i+1]] += freq\n    return pairs\n\ndef merge_vocab(pair, v_in):\n    v_out = {}\n    bigram = re.escape(' '.join(pair))\n    p = re.compile(r'(?&lt;!\\S)' + bigram + r'(?!\\S)')\n    for word in v_in:\n        w_out = p.sub(''.join(pair), word)\n        v_out[w_out] = v_in[word]\n    return v_out\n\nvocab = {'l o w &lt;/w&gt;': 5, \n         'l o w e r &lt;/w&gt;': 2, \n         'n e w e s t &lt;/w&gt;': 6,\n         'w i d e s t &lt;/w&gt;': 3}\n\nnum_merges = 10\nfor i in range(num_merges):\n    pairs = get_stats(vocab)\n    best = max(pairs, key=pairs.get)\n    vocab = merge_vocab(best, vocab)\n    print(best)\n</code></pre> <p>The output after performing bi-gram and <code>vocab_size = num_merges</code> 10,</p> <ol> <li><code>('e', 's')</code> \u2192 n e w es t , w i d es t </li> <li><code>('es', 't')</code> \u2192 n e w est , w i d est </li> <li><code>('est', '&lt;/w&gt;')</code> \u2192 n e w est, w i d est</li> <li><code>('l', 'o')</code> \u2192 lo w , lo w e r </li> <li><code>('lo', 'w')</code> \u2192 low , low e r </li> <li><code>('n', 'e')</code> \u2192  ne w est</li> <li><code>('ne', 'w')</code> \u2192 new est</li> <li><code>('new', 'est&lt;/w&gt;')</code> \u2192 newest</li> <li><code>('low', '&lt;/w&gt;')</code> \u2192 low</li> <li><code>('w', 'i')</code> \u2192 wi d est</li> </ol> <p>GPT-2 uses Unicode (e.g., UTF-8) rather than characters. First, the string is encoded with UTF-8, converting it to byte-level. This means each character (or symbol) is represented as one or more bytes, depending on the character's Unicode representation. The entire process then works the same as described above.</p>"},{"location":"maths/preface/","title":"Mathematics","text":"<p>Explore mathematical foundations essential for artificial intelligence and robotics, including probability, linear algebra, and Lie theory.</p>"},{"location":"maths/preface/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Preface</li> <li>Probability<ul> <li>Introduction to Probability</li> <li>Set Theory</li> <li>Binomial and Multinomial Distribution</li> <li>Conditional Distribution</li> <li>Laws of Total Probability</li> <li>Bayes' Theorem</li> <li>Independence</li> <li>Random Variables</li> <li>Bernoulli Distribution</li> <li>Binomial to Normal Distribution</li> <li>Binomial to Poisson Distribution</li> <li>Geometric Distribution</li> <li>Exponential Distribution</li> <li>Poisson Process</li> <li>Function of Random Variables</li> <li>Joint Distribution</li> <li>Theory of Expectation</li> <li>Variance and Standard Deviation</li> <li>Markov's Inequality</li> <li>Law of Large Numbers</li> <li>Moment Generating Function</li> <li>Covariance and Correlation</li> <li>Tail Sum</li> <li>Proof of Central Limit Theorem </li> </ul> </li> <li>Linear Algebra<ul> <li>Singular Value Decomposition</li> <li>Frobenius Inner Product</li> </ul> </li> <li>Optimization<ul> <li>Least Squares</li> <li>Non-Linear Least Squares</li> <li>Approximation of Hessian</li> <li>Optimization Procedure<ul> <li>Gradient-Descent</li> <li>Newton-Rapshon</li> <li>Gauss-Newton</li> <li>Levenberg Marquardt</li> </ul> </li> </ul> </li> <li>Lie Theory<ul> <li>Preface</li> <li>Lie Groups</li> <li>Lie Algebra</li> <li>Adjoint</li> </ul> </li> </ul>"},{"location":"maths/algebra/svd/","title":"Singular Value Decomposition (SVD)","text":"<p>Any matrix \\(\\in \\mathbb{R}^{n\\times m}\\) can be decomposed into three new matrices:</p> \\[ SVD(A) = U\\Sigma V^T\\\\ \\] <p>where,</p> <ul> <li>\\(A\\) = input n x m matrix</li> <li>\\(U\\) = orthogonal matrix (m x m), left singular values</li> <li>\\(\\Sigma\\) = diagonal singular values matrix (m x n)</li> <li>\\(V\\) = orthogonal matrix (n x n), right singular values</li> </ul>"},{"location":"maths/algebra/svd/#orthogonal-matrix","title":"Orthogonal Matrix","text":"<p>A matrix is orthogonal if its rows and columns are orthonormal vectors.</p> \\[ Q^TQ = QQ^T = I, \\text{where } Q^T = Q^{-1} \\] <p>A vector is considered orthonormal if it has a magnitude of 1 and a dot product (\\(\\cdot\\)) of 0 with other vectors.</p> <p>Example of a rotation matrix:</p> \\[ R = \\begin{bmatrix} \\cos \\theta &amp; -\\sin \\theta \\\\ \\sin \\theta &amp; \\cos \\theta \\end{bmatrix} \\] <p>The rotation matrix is orthogonal because \\(R R^T = I\\) and \\(R^T = R^{-1}\\).</p>"},{"location":"maths/algebra/svd/#singular-values","title":"Singular Values","text":"<p>Singular values are essentially the square roots of the eigenvalues (\\(\\lambda_1, \\lambda_2, \\lambda_3, ..., \\lambda_n\\)) of \\(A^TA\\), so the singular values are:</p> \\[ \\sigma_1 = \\sqrt\\lambda_1, \\sigma_2 = \\sqrt\\lambda_2, \\sigma_3 = \\sqrt\\lambda_3, ..., \\sigma_n = \\sqrt\\lambda_n \\] <p>The matrix \\(A^TA\\) is symmetric and of size \\(n \\times n\\). The diagonal matrix \\(\\Sigma\\) contains the singular values \\(\\sigma_n\\) arranged in descending order and all are \\(\\geq 0\\). </p> <p>Non-commutative of Matrix Multiplication</p> <p>\\(AB \\neq BA\\), so in the context of SVD \\(A^TA\\neq AA^T\\)</p>"},{"location":"maths/algebra/svd/#rank-matrix","title":"Rank Matrix","text":"<p>The rank of a matrix is the number of linearly independent rows or columns.</p> <p>Example:</p> \\[ \\begin{align*} A &amp;= \\begin{bmatrix} 1&amp;2&amp;3\\\\ 4&amp;5&amp;6\\\\ 7&amp;8&amp;9\\\\ \\end{bmatrix}, &amp;R_2=R_2-4R_1\\\\ A &amp;= \\begin{bmatrix} 1&amp;2&amp;3\\\\ 0&amp;-3&amp;-6\\\\ 7&amp;8&amp;9\\\\ \\end{bmatrix}, &amp;R_3 = R_3-7R_1\\\\ A &amp;= \\begin{bmatrix} 1&amp;2&amp;3\\\\ 0&amp;-3&amp;-6\\\\ 0&amp;-6&amp;-12\\\\ \\end{bmatrix}, &amp;R_2 = \\frac{R_2}{R_3}\\\\ A &amp;= \\begin{bmatrix} 1&amp;2&amp;3\\\\ 0&amp;1&amp;2\\\\ 0&amp;-6&amp;-12\\\\ \\end{bmatrix}, &amp;R_3=R_3+6R3\\\\ A &amp;= \\begin{bmatrix} 1&amp;2&amp;3\\\\ 0&amp;1&amp;2\\\\ 0&amp;0&amp;0\\\\ \\end{bmatrix} \\end{align*} \\] <p>Thus, the rank of matrix \\(A\\) is 2 (the number of non-zero rows or columns).</p>"},{"location":"maths/algebra/svd/#how-to","title":"How To","text":"<ol> <li>Compute \\(A^TA\\) (which is symmetric). The eigenvectors of a symmetric matrix are orthogonal. To obtain the matrix \\(V^T\\), find the eigenvectors of \\(A^TA\\).</li> <li>Compute the eigenvalues (\\(\\lambda\\)) by solving the equation \\(\\text{det}(A^TA - \\lambda I) = 0\\), which gives the eigenvalues \\(\\lambda_1, \\lambda_2, ..., \\lambda_n\\).</li> <li>Compute the eigenvectors (\\(v\\)) corresponding to the eigenvalues \\(\\lambda_{1 }\\). To ensure the eigenvectors are normalized, divide each element of the eigenvector by \\(\\sqrt{v_1^2 + v_2^2 + \\dots + v_n^2}\\).</li> <li>Compute the singular values \\(\\sigma_i = \\sqrt{\\lambda_i}\\).\u200b</li> <li>Repeat steps 1-3 with \\(AA^T\\) to obtain the matrix \\(U\\).</li> </ol>"},{"location":"maths/lie_theory/adjoint/","title":"Adjoint","text":"<p>Adjoint Action [1]</p> <p>In Lie theory, tangent vectors at different points on the Lie group manifold \\(\\mathcal{M}\\) belong to different tangent spaces.  To \"transform\" a tangent vector from one tangent space to another, we use the adjoint action do that transformation on Lie algebra. The adjoint action acts on the Lie algebra of the Lie group, rather than directly on the Lie group elements. Mathematically, the adjoint action is denoted as :</p> \\[ \\mathsf{Adj}_g : \\mathfrak{m} \\to \\mathfrak{m}, X \\mapsto \\mathsf{Adj}_g(X)=gXg^{-1} \\] <p>where \\(g \\in \\mathcal{M}\\) is an element of Lie groups \\(\\mathcal{M}\\), and \\(X \\in \\mathfrak{m}\\) is a element of Lie algebra of \\(\\mathcal{M}\\).</p>"},{"location":"maths/lie_theory/adjoint/#references","title":"References","text":"<p>[1] A micro Lie theory for state estimation in robotics </p>"},{"location":"maths/lie_theory/lie_algebra/","title":"Lie Theory for SE(3) and SO(3)","text":""},{"location":"maths/lie_theory/preface/","title":"Preface","text":"<p>This page should for Lie Theory in big capture</p>"},{"location":"maths/optimization/approx_hessian/","title":"Approximation Hessian \\(H=J^TJ\\)","text":"<p>The loss function \\(E\\) is a nonlinear, differentiable, and smooth function,   allowing us to use Taylor expansion to approximate the nonlinear function  \\(E\\).</p> <p>Taylor Series:</p> \\[ F(x+\\Delta x)=F(x)+\\frac{1}{1!}F'(x)\\Delta x+\\frac{1}{2!}F''(x)\\Delta x^2+\\cdots \\] <p>Thus,</p> \\[ y(x)=f(x; s)\\\\ r_i = y_i - f(x_i; s)\\\\ \\] <p>where \\(f(x; s)\\) is a nonlinear function, \\(r_i\\) is the residual, \\(y_i\\) is the target, and \\(s\\) is the state vector containing \\(( t_x, t_y, \\theta)\\)  which we aim to optimize. We apply a first-order Taylor expansion to compute changes in the state.</p> \\[ f(x_i; s') = \\underbrace{f(x_i; s)}_{y_i-r_i} + \\frac{\\partial f}{\\partial s}(s'-s)=y_i \\] <p>To satisfy \\(f(x_1; s') = y_i\\) we have \\(\\frac{\\partial f}{\\partial s}(s'-s) = r_i\\). Substituting \\(s\\), we get :</p> \\[ \\frac{\\partial f}{\\partial t_x}\\Delta t_x+\\frac{\\partial f}{\\partial t_y}\\Delta t_y+\\frac{\\partial f}{\\partial \\theta}\\Delta \\theta =r_1\\\\ \\frac{\\partial f}{\\partial t_x}\\Delta t_x+\\frac{\\partial f}{\\partial t_y}\\Delta t_y+\\frac{\\partial f}{\\partial \\theta}\\Delta \\theta =r_2\\\\ \\;\\;\\;\\;\\;\\;\\vdots\\;\\;\\;\\;\\;+\\;\\;\\;\\;\\;\\;\\vdots \\;\\;\\;\\;\\;\\;\\;+ \\;\\;\\;\\;\\;\\vdots\\;\\;\\;=\\;\\vdots\\\\ \\frac{\\partial f}{\\partial t_x}\\Delta t_x+\\frac{\\partial f}{\\partial t_y}\\Delta t_y+\\frac{\\partial f}{\\partial \\theta}\\Delta \\theta =r_n \\] <p>This can be simplified as follows:</p> \\[ \\begin{matrix} x=x_1\\\\ \\vdots\\\\ x=x_n \\end{matrix} \\begin{bmatrix} \\frac{\\partial f}{\\partial t_x} &amp; \\frac{\\partial f}{\\partial t_y}&amp; \\frac{\\partial f}{\\partial \\theta}\\\\ \\vdots&amp;\\vdots&amp;\\vdots\\\\ \\frac{\\partial f}{\\partial t_x} &amp; \\frac{\\partial f}{\\partial t_y}&amp; \\frac{\\partial f}{\\partial \\theta}\\\\ \\end{bmatrix} \\begin{bmatrix} \\Delta t_x\\\\ \\Delta t_y\\\\ \\Delta \\theta \\end{bmatrix} = \\begin{bmatrix} r_1\\\\ \\vdots\\\\ r_n\\\\ \\end{bmatrix} \\] <p>Thus,</p> \\[ J \\Delta s=r \\] <p>Since \\(J\\) is not a square matrix, it is non-invertible. To solve this equation, we multiply both sides by \\(J^T\\), yeilding :</p> \\[ (J^TJ)\\Delta s=J^Tr\\\\ \\Delta s = (J^TJ)^{-1}J^Tr \\]"},{"location":"maths/optimization/approx_hessian/#references","title":"References","text":"<ul> <li>METHODS FOR NON-LINEAR LEAST SQUARES PROBLEMS</li> <li>Nonlinear Least Squares</li> </ul>"},{"location":"maths/optimization/gauss_newt/","title":"Gauss-Newton","text":""},{"location":"maths/optimization/gauss_newt/#gauss-newton","title":"Gauss-Newton","text":"\\[ x_{i+1} = x_i + (J_{f(x)}^TJ_{f(x)})^{-1}\\nabla_{f(x)} \\]"},{"location":"maths/optimization/grad_descent/","title":"Gradient-Descent","text":""},{"location":"maths/optimization/grad_descent/#gradient-descent","title":"Gradient-Descent","text":"\\[ x_{i+1} = x_i + \\lambda\\nabla_{f(x)} \\]"},{"location":"maths/optimization/lm/","title":"Levenberg Marquardt","text":""},{"location":"maths/optimization/lm/#levenberg-marquardt","title":"Levenberg-Marquardt","text":"\\[ x_{i+1} = x_i + (\\nabla^2_{f(x_i)}+\\lambda \\; \\text{diag}(\\nabla^2_{f(x_i)}))^{-1}\\nabla_{f(x)} \\]"},{"location":"maths/optimization/lsqrt/","title":"Least Squares","text":""},{"location":"maths/optimization/newt_rapshon/","title":"Newton-Rapshon","text":""},{"location":"maths/optimization/newt_rapshon/#newton-rapshon","title":"Newton-Rapshon","text":"\\[ x_{i+1} = x_i + (\\nabla^2_{f(x_i)})^{-1}\\nabla_{f(x)} \\]"},{"location":"maths/optimization/non_lsqrt/","title":"Non-linear Least Square","text":""},{"location":"maths/probability/bayes_theorem/","title":"Bayes' Theorem","text":"<p>Conditional probability describes the likelihood of an event occurring given that another event has already occurred. Bayes Theorem is the \"inverse\" of this relationship, allowing us to update the probability of an event based on new evidence.</p> \\[ P(B|A) = \\frac{P(A|B)P(B)}{P(A)} \\] <p>By substituting \\(P(A)\\) from the laws of total probability, the equation becomes :</p> \\[ P(B|A) = \\frac{P(A|B)P(B)}{P(A \\cap B) + P(A \\cap B^c)} \\] <p>I took examples from this blog. </p> <p>Given information :</p> <ul> <li>Total people: 100</li> <li>Men: 40</li> <li>Not men: 60</li> <li>Men who wear pink: 5</li> <li>Men who do not wear pink: 35</li> <li>Not men who wear pink: 20</li> <li>Not men who do not wear pink: 40</li> </ul> <p>Thus, the probability of a person being a man is \\(P(\\text{man}) = \\frac{40}{100} = 0.4\\) and the probability of a person wearing pink is \\(P(\\text{pink}) = \\frac{25}{100} = 0.25\\). To calculate the conditional probability that a man wears pink, note that \\(P(\\text{man} \\cap \\text{pink}) \\neq P(\\text{man}) \\times P(\\text{text})\\) because the events are not independent event. Then,</p> \\[ P(\\text{man} \\cap \\text{pink}) = \\frac{5}{100} = 0.05 \\\\ P(\\text{pink}|\\text{man}) = \\frac{P(\\text{pink} \\cap \\text{man})}{P(\\text{man})} = \\frac{0.5}{0.4} = 0.125 \\] <p>Bayes' theorem provides the \"inverse\" of the conditional probability \\(P(A|B)\\), allowing us to find \\(P(B|A)\\). In this case, \\(P(\\text{man}|\\text{pink})\\) represents the probability that a person who wears pink is a man:  </p> \\[ P(\\text{man}|\\text{pink})=\\frac{P(\\text{pink}|\\text{man})P(\\text{man})}{P(\\text{pink})} = \\frac{0.4 \\times 0.125}{0.25} = 0.2 \\]"},{"location":"maths/probability/bernouli/","title":"Bernoulli Distribution","text":"<p>A Bernoulli distribution is a distribution with two possible outcomes: the event happens or does not happen. A random variable \\(\\mathbf{X}\\) in a Bernoulli distribution can take two values:</p> \\[ \\mathbf{X} = \\{0, 1\\} \\] <p>where 0 means the event does not happen, and 1 means the event does happen.</p> <p>Thus,</p> \\[ P(\\mathbf{X} = 1) = p \\\\ P(\\mathbf{X} = 0) = q = 1 - p  \\] <p>where \\(p\\) indicates the probability of success (or occurrence of the event), and \\(1 - p\\) is the probability of failure (or non-occurrence).</p>"},{"location":"maths/probability/bernouli/#bernoulli-rightarrow-binomial","title":"Bernoulli \\(\\rightarrow\\) Binomial","text":"<p>When we conduct \\(n\\) independent Bernoulli trials \\((B_1, B_2, B_3, \\dots, B_n)\\), each with the same probability of success \\(p\\), the distribution of the sum of successes follows a Binomial Distribution.</p> <p>Let \\(\\mathbf{X} =\\) total number of successes \\(= B_1 + B_2 + \\dots + B_n\\), where \\(B_i \\sim \\text{Bernoulli}(p)\\).</p> <p>Then,</p> \\[ \\mathbf{X} \\sim \\text{Binomial}(n, p) \\\\ P(\\mathbf{X} = k) = \\binom{n}{k} p^k q^{n - k} \\] <p>where \\(n\\) and \\(p\\) are the parameters representing the number of trials and the probability of success, respectively.</p>"},{"location":"maths/probability/binom_dist/","title":"Binomial Distribution and Multinomial Distribution","text":"<p>This is useful when calculating the probability of drawing 5 cards out of 52 with 10 independent trials. Use the Binomial Distribution if there are only 2 possible outcomes (Bernoulli trials) in each trial (success and failure), e.g., if we want all 5 cards to be hearts. Use the Multinomial Distribution if there are more than 2 possible outcomes, e.g., if we want 3 hearts, 1 spade, and 1 diamond, which involve 3 possible outcomes (hearts, spades, and diamonds).</p>"},{"location":"maths/probability/binom_dist/#the-binomial","title":"The Binomial","text":"<p>For a recall, to calculate the number of samples <code>r</code> out of <code>n</code> when order doesn't matter and w/o replacement we use \\(\\binom {n}{r}\\),  which is the Binomial Coefficient. Binomial coefficent is calculated using the following equation: </p> \\[ \\binom{n}{\\underbrace{n-k, k}_{\\text{2-groups}}}=\\binom{n}{k}=\\frac{n!}{(n-r)!r!} \\] <p>To expand the expression of \\(n\\)-th order polynomial function, we use Binomial Theorem:</p> \\[ (x+y)^n = \\sum^n_{k=0} \\binom{n}{k}x^k y^{n-k} \\] <p>This leads us to Pascal's Triangle:</p> \\[ \\begin{matrix} (x+y)^0 &amp;&amp;&amp;&amp;&amp;&amp;&amp;1&amp;&amp;&amp;&amp;&amp;&amp;\\\\ (x+y)^1 &amp;&amp;&amp;&amp;&amp;&amp;1&amp;&amp;1&amp;&amp;&amp;&amp;&amp;\\\\ (x+y)^2 &amp;&amp;&amp;&amp;&amp;1&amp;&amp;2&amp;&amp;1&amp;&amp;&amp;&amp;\\\\ (x+y)^3 &amp;&amp;&amp;&amp;1&amp;&amp;3&amp;&amp;3&amp;&amp;1&amp;&amp;&amp;\\\\ (x+y)^4 &amp;&amp;&amp;1&amp;&amp;4&amp;&amp;6&amp;&amp;4&amp;&amp;1&amp;&amp;\\\\ (x+y)^5 &amp;&amp;1&amp;&amp;5&amp;&amp;10&amp;&amp;10&amp;&amp;5&amp;&amp;1&amp;\\\\ (x+y)^6 &amp;1&amp;&amp;6&amp;&amp;15&amp;&amp;20&amp;&amp;15&amp;&amp;6&amp;&amp;1\\\\ \\end{matrix} \\] <p>We can notice that as \\(n\\) increases in the Binomial Theorem, it starts to converge to the normal distribution.</p> <p>In Binomial Distribution, we model the probability of the number of event successes in a fixed number of independent trials with identical probability distributions (IID) for each trial. The probability of \\(k\\) successes out of \\(n\\) trials is given by :</p> \\[ P(A = k) = \\binom{n}{k}p^k(1-p)^{n-k} \\] <p>where \\(p\\) and \\(1-p\\) are probabilities of success and failure in a single trial, respectively.</p>"},{"location":"maths/probability/binom_dist/#the-multinomial","title":"The Multinomial","text":"<p>Whereas the Binomial Distribution handles only 2 possible outcomes, the Multinomial Distribution handles more than 2 possible outcomes, or categorical outcomes. Therefore, the multinomial distribution is a generalization of the binomial distribution. In the multinomial case, we divide our samples into \\(m\\) groups, whereas in the binomial case, there are only 2 groups. The following equation gives us the Multinomial Coefficient.</p> \\[ \\binom{n}{\\underbrace{n_1, n_2, n_3, ..., n_m}_{\\text{m-groups}}}=\\frac{n!}{n_1! \\cdot n_2! \\cdot n_3! \\cdots n_m!} \\] <p>with constraint \\(n_1 + n_2 + n_3 + \\cdots + n_m = n\\)</p> <p>Proof</p> <p>Fun Fact</p> <p>Steve Bruton said, \"it's pretty simple\" when he explain the proof, that's why I love his videos \ud83d\ude02</p> \\[ \\require{cancel} \\begin{align*} \\binom{n}{n_1, n_2, \\dots, n_m} &amp;= \\binom{n}{n_1} \\binom{n - n_1}{n_2} \\binom{n - n_1 - n_2}{n_3} \\cdots \\binom{n - n_1 - n_2 - \\dots - n_{m-1}}{n_m} \\\\ &amp;= \\frac{n!}{n_1! \\cancel{(n - n_1)!}} \\cdot \\frac{\\cancel{(n - n_1)!}}{n_2! \\cancel{(n - n_1 - n_2)!}} \\cdot \\frac{\\cancel{(n - n_1 - n_2)!}}{n_3! \\cancel{(n - n_1 - n_2 - n_3)!}} \\cdots \\frac{\\cancel{(n - n_1 - n_2 - \\dots - n_{m-1})!}}{n_m! (0)!} \\end{align*} \\] <p>The Binomial Theorem handles only 2 variables \\(x\\) and \\(y\\), whereas the Multinomial Theorem handles more than 2 variables \\(x_1, x_2, x_3, \\cdots, x_m\\). To expand the polynomial with more than 2 variables \\(&gt;2\\), we can use Multinomial Theorem. The equation is quite similar to the Binomial Theorem, with a sum over all the \\(n_m\\) terms and products \\(x_i \\in \\mathbb{Z}^{+}\\) and \\(n\\in\\mathbb{Z}^{0+}\\) , using multinomial coefficient.</p> \\[ (x_1 + x_2 + x_3 + \\cdots + x_m)^n = \\sum_{\\substack{(n_1, n_2, \\cdots n_m) : \\\\n_1 + n_2 + \\cdots + n_m = n}} \\binom{n}{n_1, n_2, \\dots, n_m} x_1^{n_1} \\cdot x_2^{n_2} \\cdots x_m^{n_m} \\] <p>The probability of multinomial samples works on the same principle as the binomial case, involving a sequence of \\(n\\) independent trials with identical probability distributions (IID). The probability is given by:</p> \\[ P(X_1 = n_1, X_2 = n_2, \\dots, X_m = n_m) = \\binom{n}{n_1, n_2, \\dots, n_m} p_1^{n_1} \\cdot p_2^{n_2} \\cdots p_m^{n_m} \\] <p>where \\(\\sum_{i=1}^m n_i=n\\)</p>"},{"location":"maths/probability/binomial_normal/","title":"Binomial to Normal Distribution","text":"<p>Given \\(n\\) as the number of Bernoulli trials and \\(p\\) as the probability of success, we have:</p> \\[ P(\\mathbf{X} = 1) = p \\\\ P(\\mathbf{X} = 0) = q = 1 - p  \\] <p>If \\(n\\) is large and \\(n \\cdot p \\cdot q\\) is not too small, the distribution approaches a Normal Distribution:</p> \\[ \\mathbf{X} \\sim \\text{Binomial}(n, p) \\rightarrow \\mathbf{X} \\sim \\mathcal{N}(np, \\sqrt{npq}) \\] <p>where \\(np = \\mu\\) (mean), and \\(npq = \\sigma^2\\) (variance). The standard deviation is \\(\\sigma\\), and we can compute the probability using the cumulative distribution function (CDF) of the normal distribution.</p> <p>The probability density function (PDF) of the normal distribution is:</p> \\[ f(x) = \\frac{1}{\\sqrt{2\\pi} \\sigma} e^{-\\frac{(x - \\mu)^2}{2\\sigma^2}} \\] <p>To calculate the probability of a specific random value \\(\\mathbf{X}\\) over the interval \\([a, b]\\) using the CDF, we have:</p> \\[ P(a \\leq \\mathbf{X} \\leq b) = \\int_a^b f(x) \\, dx = \\int_a^b \\frac{1}{\\sqrt{2\\pi} \\sigma} e^{-\\frac{(x - \\mu)^2}{2\\sigma^2}} \\, dx \\] <p>It is easier to compute this for the standard normal distribution \\(\\mathcal{N}(\\mu = 0, \\sigma = 1)\\), also called the z-distribution. To standardize \\(\\mathbf{X}\\), a random variable with any \\(\\mu\\) and \\(\\sigma\\), to mean 0 and standard deviation 1, we compute the z-score \\(Z\\) corresponding to \\(\\mathbf{X}\\):</p> \\[ Z = \\frac{\\mathbf{X} - \\mu}{\\sigma} \\] <p>This equation shifts the mean of \\(\\mathbf{X}\\) to 0 and scales the distribution to have \\(\\sigma = 1\\). The standard normal PDF is:</p> \\[ \\phi(z) = \\frac{1}{\\sqrt{2\\pi}} e^{-\\frac{z^2}{2}} \\] <p>and the CDF of the standard normal distribution is:</p> \\[ \\Phi(z) = \\int_{-\\infty}^z \\frac{1}{\\sqrt{2\\pi}} e^{-\\frac{z^2}{2}} \\, dz \\] <p>You can compute \\(P(Z \\leq \\text{z-score})\\) using the z-table.</p>"},{"location":"maths/probability/binomial_poisson/","title":"Binomial to Poisson Distribution","text":"<p>Given that \\(n\\) is the number of Bernoulli trials and \\(p\\) is the probability of success, we have:</p> \\[ P(\\mathbf{X} = 1) = p \\\\ P(\\mathbf{X} = 0) = q = 1 - p \\] <p>If \\(n \\to \\infty\\), \\(p \\to 0\\), and \\(n \\cdot p\\) or \\(n \\cdot q\\) remains constant, the distribution approaches the Poisson Distribution.</p> \\[ \\mathbf{X} \\sim \\text{Binomial}(n, p) \\rightarrow \\mathbf{X} \\sim \\text{Poisson}(\\lambda) \\] <p>where \\(\\lambda = n \\cdot p\\) is the parameter for the Poisson Distribution.</p> <p>Let \\(\\lambda = np\\), \\(p = \\frac{\\lambda}{n}\\), and \\(\\mathbf{X} \\sim \\text{Binomial}(n, p)\\).</p> \\[ \\begin{align*} P(\\mathbf{X} = k) &amp;= \\binom{n}{k} p^k (1 - p)^{n - k} \\\\ &amp;= \\frac{n!}{k!(n - k)!} \\left( \\frac{\\lambda}{n} \\right)^k \\left( 1 - \\frac{\\lambda}{n} \\right)^{n - k} \\\\ &amp;= \\frac{\\lambda^k}{k!} \\frac{n!}{(n - k)!} \\left( \\frac{\\lambda}{n} \\right)^k \\left( 1 - \\frac{\\lambda}{n} \\right)^{n - k} \\\\ &amp;= \\frac{\\lambda^k}{k!} \\frac{n(n - 1)(n - 2) \\cdots (n - k + 1)}{n^k} \\left( 1 - \\frac{\\lambda}{n} \\right)^{n - k} \\end{align*} \\] <p>As \\(n\\) approaches a large number of trials, \\(n \\to \\infty\\), we have:</p> \\[ \\lim_{n \\to \\infty} \\left( 1 - \\frac{\\lambda}{n} \\right)^n = e^{-\\lambda} \\] \\[ \\lim_{n \\to \\infty} \\left( 1 - \\frac{1}{n} \\right) \\left( 1 - \\frac{2}{n} \\right) \\cdots \\left( 1 - \\frac{k + 1}{n} \\right) = 1 \\] \\[ \\lim_{n \\to \\infty} \\left( 1 - \\frac{\\lambda}{n} \\right)^{-k} = 1 \\] <p>Thus, we obtain the Poisson distribution:</p> \\[ P(\\mathbf{X} = k) = \\frac{\\lambda^k e^{-\\lambda}}{k!} \\]"},{"location":"maths/probability/chebyshev_ieq/","title":"Chebyshev's Inequality","text":"<p>While Markov's Inequality only deals with means, Chebyshev's Inequality deals with both the mean and variance.</p> <p>Let \\(\\mathbf{X}\\), and define \\(\\mathbf{Y} = (\\mathbf{X} - E(\\mathbf{X}))^2\\). Since \\(\\mathbf{Y}\\) is a non-negative random variable, we apply Markov's inequality to \\(\\mathbf{Y}\\). For any \\(a &gt; 0\\), we have:</p> \\[ \\begin{aligned} E(\\mathbf{Y}) &amp;= (\\mathbf{X} - E(\\mathbf{X}))^2 = \\text{Var}(\\mathbf{X}) \\\\ P(|\\mathbf{X} - E(\\mathbf{X})| \\geq a) &amp;= P((\\mathbf{X} - E(\\mathbf{X}))^2 \\geq a^2) \\quad \\text{let} \\ a^2 = b \\\\ &amp;= P(\\mathbf{Y} \\geq b) \\leq \\frac{E(\\mathbf{Y})}{b} \\\\ P(|\\mathbf{X} - E(\\mathbf{X})| \\geq a) &amp;\\leq \\frac{\\text{Var}(\\mathbf{X})}{a^2} \\end{aligned} \\] <p>Chebyshev's Inequality bounds the probability that \\(\\mathbf{X}\\) deviates from the mean by more than \\(a\\) standard deviations.</p>"},{"location":"maths/probability/clf/","title":"Central Limit Theorem","text":"<p>As large \\(n\\) experiments with \\(\\mathbf{X}_1, \\mathbf{X}_2, \\mathbf{X}_3, \\cdots, \\mathbf{X}_n\\) as i.i.d. random variables are conducted, the sample mean will converge to the expected value. This leads to the Central Limit Theorem, regardless of the distribution of \\(\\mathbf{X}_i\\)'s.</p> <p>With the sample mean:</p> \\[ \\bar{\\mathbf{X}}_n = \\frac{1}{n}\\sum_{i=1}^n \\mathbf{X}_i \\sim \\mathcal{N}(\\mu, \\frac{\\sigma^2}{n}) \\] <p>Proof</p> <p>The distribution of the normalized sum is:</p> \\[ \\begin{align*} S_n &amp;= \\sum_{i=1}^n \\mathbf{X}_i \\\\ NS_n &amp;= \\frac{S_n}{\\sigma \\sqrt{n}} \\end{align*} \\] <p>Proof Goal:  The distribution of \\(NS_n\\) approaches the standard normal distribution \\(\\mathcal{N}(0,1)\\) as \\(n \\to \\infty\\).</p> \\[ \\lim_{n \\to \\infty} P(NS_n \\leq z) = \\Phi(z) \\] <p>where \\(\\Phi(z)\\) is the cumulative distribution function (CDF) of the standard normal distribution. The moment-generating function \\(m(t)\\) for \\(\\mathcal{N}(0,1)\\) is:</p> \\[ m(t) = e^{\\frac{t^2}{2}} \\] <p>Taylor Expansion of \\(m(t)\\):</p> \\[ m(t) = \\underbrace{m(0)}_{=1} + \\underbrace{tm'(0)}_{=0} + \\underbrace{\\frac{t^2}{2}m''(0)}_{\\frac{t^2}{2}} + \\underbrace{\\cdots}_{\\mathcal{E}(t^3)} \\] <p>If \\(\\mathbf{Y} = b\\mathbf{X}\\), then \\(m_{\\mathbf{Y}} = m_{\\mathbf{X}}(bt)\\), so:</p> \\[ \\begin{align*} m_{\\mathbf{Z}}(t) &amp;= m_{S_n}\\left(\\frac{t}{\\sigma \\sqrt{n}}\\right) \\\\ &amp;= \\left[m\\left(\\frac{t}{\\sigma \\sqrt{n}}\\right)\\right]^n \\end{align*} \\] <p>where:</p> \\[ \\begin{align*} m\\left(\\frac{t}{\\sigma \\sqrt{n}}\\right) &amp;= 1 + \\frac{1}{2}\\sigma^2\\left(\\frac{t^2}{\\sigma^2 n}\\right) + \\mathcal{E}\\left(\\frac{t^3}{\\sigma^3 n^{3/2}}\\right) \\\\ &amp;= 1 + \\frac{1}{2}\\left(\\frac{t^2}{n}\\right) + \\mathcal{E}_n(\\cdots) \\end{align*} \\] <p>Now, take the limit as \\(n \\to \\infty\\) of \\(m_{\\mathbf{Z}}(t)\\):</p> \\[ \\begin{align*} \\lim_{n \\to \\infty} m_{\\mathbf{Z}}(t) &amp;= \\lim_{n \\to \\infty} \\left(1 + \\frac{1}{2}\\left(\\frac{t^2}{n}\\right) + \\mathcal{E}_n\\right) \\\\ &amp;= \\lim_{n \\to \\infty} \\left(1 + \\frac{t^2}{2n}\\right)^n \\\\ &amp;= e^{\\frac{t^2}{2}}, \\quad \\text{since} \\quad \\lim_{n \\to \\infty} \\left(1 + \\frac{a}{n}\\right)^n = e^a \\end{align*} \\] <p>This proves that the moment-generating function of \\(\\mathcal{N}(0,1)\\) is \\(e^{\\frac{t^2}{2}}\\).</p>"},{"location":"maths/probability/conditional_probs/","title":"Conditional Probability","text":"<p>If \\(A\\) and \\(B\\) two events in a random experiment, the probability that \\(A\\) occurs given \\(B\\) has occured, assuming \\(B\\) has non-zero probability, is defined as the conditional probability</p> \\[ P(A|B) = \\frac{P(A \\cap B)}{P(B)} \\]"},{"location":"maths/probability/cov_corr/","title":"Covariance and Correlation","text":"<p>Covariance and correlation describe the relationship between two random variables. Covariance is a measure of how two random variables change together. Correlation is a standardized measure of the strength and direction of the linear relationship between two variables.</p> \\[ \\begin{align*} \\text{Cov}(\\mathbf{X},\\mathbf{Y}) &amp;= E\\left[(\\mathbf{X}-E(\\mathbf{X}))(\\mathbf{Y}-E(\\mathbf{Y}))\\right] \\\\ &amp;= E\\left[(\\mathbf{X}-\\mu_\\mathbf{X})(\\mathbf{Y}-\\mu_\\mathbf{X})\\right] \\end{align*} \\]"},{"location":"maths/probability/cov_corr/#properties","title":"Properties","text":"\\[ \\require{cancel} \\begin{align*} \\text{Cov}(\\mathbf{X},\\mathbf{Y}) &amp;= E\\left[(\\mathbf{X}-\\mu_\\mathbf{X})(\\mathbf{Y}-\\mu_\\mathbf{X})\\right] \\\\ &amp;= E(\\mathbf{X}\\mathbf{Y}) - \\mu_\\mathbf{X}E(\\mathbf{Y}) - \\cancel{\\mu_\\mathbf{Y}E(\\mathbf{X})} + \\cancel{\\mu_\\mathbf{X}\\mu_\\mathbf{Y}} \\\\ &amp;= E(\\mathbf{X}\\mathbf{Y}) - \\mu_\\mathbf{X}E(\\mathbf{Y}) \\\\ &amp;= E(\\mathbf{X}\\mathbf{Y}) - E(\\mathbf{X})E(\\mathbf{Y}) \\end{align*} \\] <p>When \\(\\mathbf{X}\\) and \\(\\mathbf{Y}\\) are independent, then \\(\\text{Cov}(\\mathbf{X},\\mathbf{Y}) = 0\\).</p> \\[ \\begin{align*} \\text{Var}(\\mathbf{X}) &amp;= \\text{Cov}(\\mathbf{X},\\mathbf{X}) \\\\ \\text{Var}(\\mathbf{X}+\\mathbf{Y}) &amp;= \\text{Var}(\\mathbf{X}) + \\text{Var}(\\mathbf{Y}) + 2\\text{Cov}(\\mathbf{X},\\mathbf{Y}) \\end{align*} \\]"},{"location":"maths/probability/cov_corr/#correlation-of-mathbfx-and-mathbfy","title":"Correlation of \\(\\mathbf{X}\\) and \\(\\mathbf{Y}\\)","text":"<ul> <li>A correlation of +1 indicates a perfect positive linear relationship.</li> <li>A correlation of -1 indicates a perfect negative linear relationship.</li> <li>A correlation of 0 implies no linear relationship.</li> </ul> \\[ \\begin{align*} \\text{Cor}(\\mathbf{X},\\mathbf{Y}) &amp;= \\frac{\\text{Cov}(\\mathbf{X},\\mathbf{Y})}{\\sigma(\\mathbf{X})\\sigma(\\mathbf{Y})} \\\\ &amp;= \\frac{\\sigma_{\\mathbf{X}\\mathbf{Y}}}{\\sigma_{\\mathbf{X}}\\sigma_{\\mathbf{Y}}} \\\\ \\text{Cor}(a\\mathbf{X}+b, c\\mathbf{Y}+d) &amp;= \\text{Cor}(\\mathbf{X}, \\mathbf{Y}) \\end{align*} \\] <p>The Caveat</p> <p>While independent variables always have zero covariance and zero correlation, the reverse is not true: zero covariance or zero correlation does not imply independence.</p>"},{"location":"maths/probability/exp_dist/","title":"Exponential Distribution","text":"<p>The exponential distribution describes the interval time \\(t\\) between events. It is commonly used to model lifetimes. Given the random variable \\(\\mathbf{T}\\) as the time, we have:</p> \\[ \\mathbf{T} \\sim \\text{Exp}(\\lambda) \\] <p>where \\(\\lambda\\) is rate of events.</p> \\[ f(x) = \\lambda e^{-\\lambda x} \\] <p>To compute the probability using the CDF of the exponential distribution, we get:</p> \\[ \\begin{align*} F(a) = P(\\mathbf{T}\\leq a)&amp;=\\int_0^a f(x) \\; dx \\\\ &amp;= -e^{-\\lambda x} \\Big|_0^a\\\\ &amp;= e^{-0\\lambda} - e^{-a\\lambda} \\\\ &amp;= 1-e^{-a\\lambda} \\\\ F(a, b) = P(a \\leq \\mathbf{T}\\leq b)&amp;=\\int_a^b f(x) \\; dx \\\\ &amp;= -e^{-\\lambda x} \\Big|_a^b\\\\ &amp;= e^{-a\\lambda} - e^{-b\\lambda}  \\end{align*} \\] <p>One of the key properties of the exponential distribution is its memoryless property, which states that for \\(\\mathbf{T} \\sim \\text{Exp}(\\lambda)\\) :</p> \\[ \\begin{align*} P(\\mathbf{T}&gt;t+s | \\mathbf{T}&gt;s) &amp;= \\frac{P(\\mathbf{T}&gt;s+t \\cap \\mathbf{T}&gt;t)}{P(\\mathbf{T}&gt;s)}\\\\ &amp;=\\frac{P(\\mathbf{T}&gt;s+t)}{P(\\mathbf{T}&gt;s)}\\\\ &amp;=\\frac{e^{-\\lambda s}e^{-\\lambda t}}{e^{-\\lambda s}}\\\\ &amp;=e^{-\\lambda t}\\\\ &amp;=P(\\mathbf{T}&gt;t)\\\\ \\end{align*} \\] <p>This property means that the probability of an event occurring in the future does not depend on any past information. However, in real-world scenarios, the probability in the future may depend on past information. For example, the lifetimes of bulbs may not \"forget\" past times, and as the lifetimes approach the average, the past information still has an influence.</p> <p>To address this, we use the Hazard Rate. The hazard or failure rate is defined for non-repairable populations with instantaneous time.</p> \\[ \\begin{align*} P(\\mathbf{T} \\leq t+dt | \\mathbf{T}&gt;t) &amp;= 1-P(\\mathbf{T} &gt; t+dt | \\mathbf{T}&gt;t) \\\\ &amp;= 1-P(\\mathbf{T}&gt;dt) \\\\ &amp;= 1-e^{-\\lambda dt} \\\\ &amp;= 1-\\left[1-\\lambda dt + \\frac{1}{2}\\lambda^2dt^2-\\cdots\\right]\\\\ &amp;\\approx \\lambda \\; dt \\\\ P(\\mathbf{T} \\leq t+dt) &amp;= \\lambda P(\\mathbf{T}&gt;t)\\; dt \\end{align*} \\]"},{"location":"maths/probability/expected/","title":"Theory of Expectation","text":"<p>Expectation is the \"center of mass\" or weighted average of the probability distribution. If \\(\\mathbf{X}\\) is a discrete random variable with probability \\(P(x)\\), then the expectation is denoted by \\(E[\\mathbf{X}]\\). To compute the expectation of \\(E[\\mathbf{X}]\\), it is defined as:</p> <ul> <li>Discrete: \\(E[\\mathbf{X}] = \\sum_{\\text{all }k} x_k P(\\mathbf{X} = x_k) = \\mu\\)</li> <li>Continuous: \\(E[\\mathbf{X}] = \\int_{-\\infty}^{\\infty} x f(x) \\, dx\\)</li> </ul>"},{"location":"maths/probability/expected/#properties-of-expectation","title":"Properties of Expectation","text":"<ul> <li>\\(E(\\mathbf{X} + \\mathbf{Y}) = E(\\mathbf{X}) + E(\\mathbf{Y})\\)</li> <li>If \\(\\mathbf{X}\\) and \\(\\mathbf{Y}\\) are independent, then \\(E(\\mathbf{X}\\mathbf{Y}) = E(\\mathbf{X}) E(\\mathbf{Y})\\)</li> <li> <p>The expectation of a function of a random variable \\(\\mathbf{Y} = g(\\mathbf{X})\\) is:</p> \\[ \\begin{aligned} E(\\mathbf{Y}) = E(g(\\mathbf{X})) &amp;= \\sum_x g(x) P(x), \\quad \\text{if discrete random variable} \\\\ E(\\mathbf{Y}) = E(g(\\mathbf{X})) &amp;= \\int_{-\\infty}^{\\infty} g(x) f(x) \\, dx, \\quad \\text{if continuous random variable} \\\\ E(g(\\mathbf{X}) h(\\mathbf{Y})) &amp;= E(g(\\mathbf{X})) E(h(\\mathbf{Y})) \\end{aligned} \\] </li> </ul>"},{"location":"maths/probability/func_random/","title":"Function of Random Variables","text":"<p>A random variabel \\(\\mathbf{X}\\) with a function \\(g(\\cdot)\\) applied to it results in a new random variable \\(\\mathbf{Y} = g(\\mathbf{X})\\). The probability density function (PDF) of the distribution cannot be applied directly to \\(g(\\cdot)\\), instead, it must be derived using the cumulative distribution function (CDF), which results in a new CDF.</p> <p>Given random variable \\(\\mathbf{X}\\) with normal distribution \\(\\mathbf{X} \\sim \\mathcal{N}(\\mu, \\sigma^2)\\), and a function \\(g(\\mathbf{X}) = a\\mathbf{X}+b\\). We have:</p> \\[ \\mathbf{Y} = a\\mathbf{X}+b \\\\ \\] <p>The CDF of \\(\\mathbf{Y}\\), donated by \\(F_\\mathbf{Y}\\):</p> \\[ \\begin{align*} F_\\mathbf{Y}(y) = P(\\mathbf{Y} &lt; y) &amp;= P(a\\mathbf{X}+b)\\\\ &amp;= P(\\mathbf{X} &lt; \\frac{y-b}{a})\\\\ &amp;= F_\\mathbf{X}(\\frac{y-b}{a}) \\end{align*} \\] <p>To obtain the PDF, take the derivative of the CDF:</p> \\[ \\begin{align*} f_\\mathbf{y}(y) &amp;= \\frac{d}{dy} F_\\mathbf{X}\\left(\\frac{y-b}{a}\\right)\\\\ &amp;= \\frac{1}{a} f_\\mathbf{X}\\left(\\frac{y-b}{a}\\right) \\end{align*} \\] <p>Thus,</p> \\[ \\mathbf{Y} \\sim \\mathcal{N}(a\\mu+b, a^2\\sigma^2) \\] <p>Example :</p> <p>Given a random variable \\(\\mathbf{X}\\) with standart normal distribution \\(\\mathbf{X} \\sim \\mathcal{N}(0, 1)\\), and the function \\(g(\\mathbf{X}) = \\mathbf{X}^2\\). The CDF of \\(\\mathbf{Y}\\) is:</p> \\[ \\begin{align*} F_\\mathbf{Y}(y)=P(\\mathbf{Y} &lt; y)&amp;=P(\\mathbf{X}^2 &lt; y)\\\\ &amp;= P(-\\sqrt{y} &lt; \\mathbf{x} &lt; \\sqrt{y})\\\\ &amp;= \\Phi(\\sqrt{y}) - \\Phi(-\\sqrt{y}) \\\\ \\end{align*} \\] <p>Then, the PDF of \\(\\mathbf{Y}\\) is:</p> \\[ \\begin{align*} f_\\mathbf{Y}(y)&amp;=\\frac{d}{dy} F_\\mathbf{Y}(y)\\\\ &amp;= \\Phi'(\\sqrt{y})\\cdot \\frac{y^{-\\frac{1}{2}}}{2} - \\Phi'(-\\sqrt{y})\\cdot \\frac{y^{-\\frac{1}{2}}}{2}\\\\ &amp;= y^{-\\frac{1}{2}} \\Phi'(\\sqrt{y})\\\\ &amp;= y^{-\\frac{1}{2}} f_\\mathbf{X}(\\sqrt{y})  \\end{align*} \\] <p>where PDF of \\(f_\\mathbf{X}\\) is :</p> \\[ f_\\mathbf{X}(x)=\\frac{e^{-\\frac{x^2}{2}}}{\\sqrt{2\\pi}} \\] <p>Subtitute \\(f_\\mathbf{X}\\) to \\(f_\\mathbf{Y}\\),</p> \\[ f_\\mathbf{Y}(y) = \\frac{y^{-\\frac{1}{2}}e^{-\\frac{x^2}{2}}}{\\sqrt{2\\pi}} \\]"},{"location":"maths/probability/gamma_dist/","title":"Gamma Distribution","text":"<p>The exponential distribution computes the probability of the interval time between a single event. The Gamma distribution is used for calculating the probability of the interval time for the \\(r\\)-th arrivals. The probability density function (PDF) of the Gamma distribution is:</p> \\[ f(t, r, \\lambda) = \\frac{e^{-\\lambda t} \\lambda^r t^{r-1}}{\\Gamma(r)}  \\] <p>where \\(\\Gamma(r)=(r-1)!\\), and \\(\\lambda\\) is rate. Denote \\(T_r\\) as the random time for the \\(r\\)-th arrival, and \\(I\\) as the single event interval time: </p> \\[ T_r = I_1 + I_2 + I_3 + \\cdots + I_r \\\\ T_r \\sim \\text{Gamma}(r, \\lambda)  \\] <p>The cumulative distribution function (CDF) of the Gamma distribution for  \\(r &gt; 0\\) :</p> \\[ P(T_r &gt; t) = P(N_t \\leq r-1) = \\sum_{k=0}^{r-1} \\frac{e^{-\\lambda t}(\\lambda t)^t}{k!} \\] <p>where \\(T_r\\) is the continuous time interval for the \\(r\\)-th arrival, and \\(N_t\\) is the number of Poisson events that occur over the time interval \\(t\\).</p>"},{"location":"maths/probability/geo_dist/","title":"Geometric Distribution","text":"<p>The geometric distribution tells us how likely the first success is given a sequence of \\(n\\) trials of independent Bernoulli events with probability \\(p\\). he formula for the Probability Mass Function (PMF) of the random variable \\(\\mathbf{X}\\) is :</p> \\[ \\mathbf{X} \\sim \\text{Geometric}(p) \\] <p>Since this calculates the probability of the first success occurring on the \\(n^th\\) trials, the previous trials (before the \\(n^th\\)) must be failures. By the independence of the trials, the probability of this event is:</p> \\[ \\begin{align*} P(\\mathbf{X} = n) &amp;= P(X_0 = 0 \\cap X_1 = 0 \\cap \\cdots \\cap X_{n-1} = 0 \\cap X_n = 1)\\\\ &amp;= P(X_0 = 0) \\cdot P(X_1 = 0) \\cdots P(X_{n-1} = 0) \\cdot P(X_n = 1)\\\\ P(\\mathbf{X} = n)&amp;=(1-p)^{n-1}p \\end{align*} \\]"},{"location":"maths/probability/independence/","title":"Independence","text":"<p>Two events are classified as independent if the occurrence of one has no effect on the occurrence of the other. Given events \\(A\\) and \\(B\\), if they are independent, then \\(P(A\\cap B) = P(A) \\cdot P(B)\\)</p> <p>Thus, </p> \\[ P(A|B) = P(A) \\\\ P(B|A) = P(B) \\] <p>Proof </p> <p>We can use conditional probability to prove this. The event \\(A\\) is independent if its conditional probability is equal to  \\(P(A)\\).</p> \\[ P(A|B) = \\frac{P(A \\cap B)}{P(B)} = \\frac{P(A)\\cdot P(B)}{P(B)} = P(A)\\\\ P(B|A) = \\frac{P(A \\cap B)}{P(A)} = \\frac{P(A)\\cdot P(B)}{P(A)} = P(B) \\] <p>So, when events \\(A\\) and \\(B\\) are independent, knowing that \\(B\\) occurred does not change the probability of \\(B\\), and vice versa.</p> <p>Let say we want to toss die and coin and calculate the probability of getting both a 5 on the die and a head on the coin. The result of the coin toss does not influence the outcome of the die roll, and vice versa.</p> <p>The sample spaces for each event are:</p> \\[ \\Omega_A = \\{H, T\\}\\\\ \\Omega_B = \\{1, 2, 3, 4, 5, 6 \\} \\] <p>The probability of each event is:</p> \\[ P(A) = \\frac{1}{2} \\\\ P(B) = \\frac{1}{6} \\] <p>The probability of both events happening is:</p> \\[ P(A\\cap B) = \\frac{1}{2} \\cdot \\frac{1}{6} = \\frac{1}{12} \\]"},{"location":"maths/probability/intro_probs/","title":"Introduction to Probablity","text":"<p>Probability measures how likely an event \\(A\\) can happen. It is symbolized by \\(P(A)\\). To compute the probability, we can use the following equation : </p> \\[ P(A) = \\frac{\\text{Number of event } A \\text{ can happen }}{\\text{Total number of possible outcomes}} \\] <p>Example: If we roll a die and want to measure how likely side 3 (event \\(A\\)) will show up, there are 6 possible outcomes (1, 2, 3, 4, 5, 6).</p> \\[ P(A) = \\frac{1}{6} \\approx 0.1667 \\] <p>This is only one sample. To calculate total number of possible outcomes, we can use this formula : </p> <p>Where \\(n\\) is the number of unique items to choose and \\(r\\) is the number of being chosen.</p> <p>In permutation, order is important. For example, 1234 is different with 4321, as in case of a PIN-based lock. Otherwise in combination, order not important, so 1234 is the same as 4321.</p> <p>Replacement means that the same items can be chosen more than once. No replacement means that the same item cannot be selected more then once.</p> Order Matters Replacement Formula Example Yes Yes \\(n^r\\) Rolling 2 dice for 10 times and order matters (side 1 &amp; 3 is different from 3 &amp; 1), each roll is independent, \\((6 \\times 6)^{10}\\) Yes No \\({}_{n}P_r = \\frac{n!}{(n-r)!}\\) Choosing 3 books from 10 books in a specific order, without putting any back, \\(\\frac{10!}{7!}\\) No Yes \\({}_{n+r-1}C_r = \\binom {n+r-1}{r} = \\frac{(n+r-1)!}{(n-1)!r!}\\) Selecting 3 scoops of ice cream flavors from 5 flavors, where can pick same flavor more than once, \\(\\binom {7}{4}\\) No No \\({}_{n}C_r=\\binom {n}{r}=\\frac{n!}{(n-r)!r!}\\) Choosing 3 books from a shelf of 10 without regard to order and without replacement, \\(\\binom {10}{3}\\) <p>How can that be?</p> <ul> <li>Permutation with replacement, when we have 2 dice, we have 36 choices one time. When we throw them 10 times, each time we still have 36 choices.</li> <li>Permutation without replacement, when choosing 3 books from 10, so the number of ways to choose all 10 books is 10!, because the number of available choices decreasws each time. But remember permutation care about the order, so we devided with (10-3)!.</li> <li>Combinations without replacement, if we are choosing 2 books (maths and physics) from 10 books where the order doesn't matter, we have \\(\\frac{10!}{8!}\\) possible choices. So, we have 4 possible choices; maths &amp; physics, maths &amp; maths, physics &amp; physics, physics &amp; maths. Imagine the order matters, like first math book and then physics book, so there is only one choice. Then we can reduce the permutation w/o replacement by changing formula with multiply it to \\(\\frac{1}{r!}\\) to erase the copies from permutation.</li> <li>Combinations with replacement, this blog makes it easy to understand the intuitive behind \\(n+r-1\\). That blog explains by counting the actions. In example, there are 5 different ice cream flavors (A, B, C, D, E) and we take 3 scoops. We want all 3 scoops to be of the flavor C. Imagine starting from A, we skip A coz we want 3 of C, count 1. Then, we are in B, skip again, count 2. Now, arrive at C, scoop it, count 3, remember we need 3 of C, right now we only have one C so we need to scoop it 2 more, the count becomes 5. Then we skip C and move to D, count 6. We skip D and move to E, count 7. It is same value as \\(n+r-1\\), where <code>n = 5</code> and <code>r = 3</code>, giving us 7, same as I illustrated before.</li> </ul> <p>Info</p> <p>Most of this section refered to Review of Probability Theory by Maleki and Do, A First Course in Probability by Sheldon Ross, and Probability Bootcamp by Steve Bruton</p>"},{"location":"maths/probability/joint_dist/","title":"Joint Distribution","text":"<p>The joint distribution describes the probability of two or more random variables occurring simultaneously.  Joint distribution of \\(\\mathbf{X}\\) and \\(\\mathbf{Y}\\) in discrete case, defined as :</p> \\[ P(\\mathbf{X}=x, \\mathbf{Y}=y) = P(\\mathbf{X}=x)P(\\mathbf{Y}=y) \\] <p>then, </p> <ul> <li>\\(P(\\mathbf{X}=x, \\mathbf{Y}=y) \\ge 0\\)</li> <li>\\(\\sum_{x,y} P(\\mathbf{X}=x, \\mathbf{Y}=y)=1\\)</li> <li>The CDF of joint distribution are \\(P[(x,y)\\in A] = \\int_A f(x, y) \\; dxdy\\)</li> </ul> <p>Each individual distribution within the joint distribution is called the marginal distribution:</p> <ul> <li>\\(P(\\mathbf{X}=x) =\\sum_y P(\\mathbf{X}=x)\\)</li> <li>\\(P(\\mathbf{Y}=Y) =\\sum_x P(\\mathbf{Y}=y)\\)</li> </ul> <p>Both called marginal distribution of \\(\\mathbf{X}\\) and \\(\\mathbf{Y}\\), and the marginal density is defined as:</p> <ul> <li>\\(f_\\mathbf{X}(x) = \\int_{-\\infty}^{\\infty} f(x,y) \\; dy\\)</li> <li>\\(f_\\mathbf{Y}(y) = \\int_{-\\infty}^{\\infty} f(x,y) \\; dx\\)</li> </ul> <p>where \\(f(x,y)\\) is the joint PDF. The conditinal distributions of \\(\\mathbf{X}\\) and \\(\\mathbf{Y}\\), </p> \\[ P(\\mathbf{X}=x|\\mathbf{Y}=y)=\\frac{P(x, y)}{P_\\mathbf{Y}(y)} \\] <p>and</p> \\[ f_{\\mathbf{Y}|\\mathbf{X}}(y|x) =\\frac{f(x,y)}{f_\\mathbf{X}(x)} \\]"},{"location":"maths/probability/joint_dist/#independence-of-joint-probability","title":"Independence of Joint Probability","text":"<p>Independence of joint probability same as single probability. Multiple random variables \\(X_1, X_2, X_3, \\cdots X_n\\) are independent, if for all \\((x_1, x_2, x_3, \\cdots x_n)\\in \\mathbb{R}^n\\).</p> <ul> <li> <p>If \\(X_1, X_2, X_3, \\cdots X_n\\) are discrete, then </p> \\[ P(X_1=x_1, X_2=x_2, X_3=x_3, \\cdots X_n=x_n) = P(X_1=x_1)P(X_2=x_2)P(X_3=x_3)\\cdots P(X_n=x_n) \\] </li> <li> <p>If \\(X_1, X_2, X_3, \\cdots X_n\\) are continous, then</p> \\[ f(X_1=x_1, X_2=x_2, X_3=x_3, \\cdots X_n=x_n) = f(X_1=x_1)f(X_2=x_2)f(X_3=x_3)\\cdots f(X_n=x_n) \\] </li> <li> <p>If \\(X_1, X_2, X_3, \\cdots X_n\\) are independent and identically distribute (IID), then they have same CDF, the same means, and the same variances</p> </li> </ul>"},{"location":"maths/probability/large_num/","title":"Law of Large Numbers","text":"<p>Let \\(\\mathbf{X}_1, \\mathbf{X}_2, \\mathbf{X}_3, \\cdots, \\mathbf{X}_n\\) be a sequence of independent random variables with \\(E(\\mathbf{X}) = \\mu\\) and \\(\\text{Var}(\\mathbf{X}) = \\sigma^2\\). The Law of Large Numbers states that, as \\(n\\) becomes large, repeated experiments will result in values that are close to the expected value.</p> <p>The sample mean, defined as</p> \\[ \\mathbf{X}_n = \\frac{1}{n} \\sum_{i=1}^n \\mathbf{X}_i, \\] <p>will converge to \\(\\mu\\) as \\(n \\rightarrow \\infty\\).</p>"},{"location":"maths/probability/large_num/#proof","title":"Proof:","text":"<p>We want to show that \\(P(|\\mathbf{X}_n - \\mu| &gt; \\epsilon) \\rightarrow 0\\) as \\(n \\rightarrow \\infty\\). Since the \\(\\mathbf{X}_i\\)'s are independent:</p> \\[ \\begin{aligned} E(\\mathbf{X}_n) &amp;= \\frac{1}{n} \\sum_{i=1}^n E(\\mathbf{X}_i) = \\mu, \\\\ \\text{Var}(\\mathbf{X}_n) &amp;= \\frac{1}{n^2} \\sum_{i=1}^n \\text{Var}(\\mathbf{X}_i) = \\frac{\\sigma^2}{n}, \\\\ \\text{as } n &amp;\\rightarrow \\infty, \\text{Var}(\\mathbf{X}_n) \\rightarrow 0, \\\\ P(|\\mathbf{X}_n - \\mu| &gt; \\epsilon) &amp;\\leq \\frac{\\text{Var}(\\mathbf{X}_n)}{\\epsilon^2} \\\\ &amp;= \\frac{\\sigma^2}{n\\epsilon^2} \\rightarrow 0, \\quad \\text{as } n \\rightarrow \\infty. \\end{aligned} \\] <p>Thus, we have shown that \\(P(|\\mathbf{X}_n - \\mu| &gt; \\epsilon) \\rightarrow 0\\) as \\(n \\to \\infty\\), completing the proof.</p>"},{"location":"maths/probability/lebesgue/","title":"Lebesgue Measure","text":"<p>Lebesgue measure plays a role in handling the Dirac delta function (\\(\\delta\\)-function) in the context of the Central Limit Theorem (CLT), particularly when working with continuous random variables and their distributions. The Dirac delta function is a probability distribution that is concentrated at a single point, and it leads to a discontinuity in the distribution.</p>"},{"location":"maths/probability/markov_ieq/","title":"Markov's Inequality","text":"<p>Markov's inequality is used to check if \\(\\mathbf{X}\\) is a non-negative random variable. If $\\mathbf{X} \\geq 0 ), then:</p> \\[ P(\\mathbf{X} \\geq a) \\leq \\frac{E(\\mathbf{X})}{a} \\] <p>Let \\(\\mathbf{X}\\) be any positive discrete random variable, so we can write:</p> \\[ \\begin{aligned} E(\\mathbf{X}) &amp;= \\sum_x x P(\\mathbf{X} = x) \\\\ &amp;\\geq \\sum_{x \\geq a} x P(\\mathbf{X} = x) \\\\ &amp;\\geq \\sum_{x \\geq a} a P(\\mathbf{X} = x) \\\\ &amp;= a P(\\mathbf{X} \\geq a) \\end{aligned} \\] <p>Thus, Markov's inequality gives us the result:</p> \\[ P(\\mathbf{X} \\geq a) \\leq \\frac{E(\\mathbf{X})}{a} \\]"},{"location":"maths/probability/moment_func/","title":"Moment Generating Function","text":"<p>The moment generating function (MGF), denoted as \\(m(t)\\), provides insight into the characteristics of a distribution and has a similar form to a Taylor series. It captures the distribution's properties up to the \\(n\\)-order. The MGF uniquely determines the cumulative distribution function (CDF) of a random variable \\(\\mathbf{X}\\). For a random variable \\(\\mathbf{X}\\), the MGF is given by:</p> \\[ m(t) =  \\begin{cases} \\sum_x e^{tx} P(\\mathbf{X}=x), &amp;\\mathbf{X} \\text{ discrete}\\\\ \\\\ \\underbrace{\\int_{-\\infty}^\\infty e^{tx} f(x) \\; dx}_{\\text{Laplace T-form of PDF}}, &amp;\\mathbf{X} \\text{ continous} \\end{cases} \\]"},{"location":"maths/probability/moment_func/#moments-of-a-distribution","title":"Moments of a Distribution","text":"<p>The \\(n\\)-th moment of a distribution can be derived from the derivatives of the MGF evaluated at \\(t=0\\):</p> \\[ \\begin{matrix} n-\\text{order} &amp; \\text{Moment} &amp; \\text{Expression}\\\\ 1-\\text{st} &amp; \\text{Mean} &amp; E(\\mathbf{X})=\\mu\\\\ 2-\\text{nd} &amp; \\text{Variance} &amp; E[(\\mathbf{X}-\\mu)^2]=\\sigma^2\\\\ 3-\\text{th} &amp; \\text{Skweness} &amp; E\\left[\\left(\\frac{\\mathbf{X}-\\mu}{\\sigma}\\right)^3\\right]\\\\ 4-\\text{th} &amp; \\text{Kurtosis} &amp; E\\left[\\left(\\frac{\\mathbf{X}-\\mu}{\\sigma}\\right)^4\\right] = \\frac{E(\\mathbf{X}^4)}{\\sigma}\\\\ \\vdots &amp; \\vdots &amp; \\vdots \\\\ n-th &amp; \\text{\"n-th moments\"} &amp; E(\\mathbf{X}^n) \\end{matrix} \\]"},{"location":"maths/probability/moment_func/#properties-of-the-moment-generating-function","title":"Properties of the Moment Generating Function","text":"<p>Let \\(\\mathbf{X}\\) and \\(\\mathbf{X}\\) be independent random variables, and corresponding moment generating functions \\(m_\\mathbf{X}\\) and \\(m_\\mathbf{Y}\\).</p> <p>Define \\(\\mathbf{Z} = \\mathbf{X} +\\mathbf{Y}\\), then</p> \\[ m_\\mathbf{z}(t) = m_\\mathbf{X}(t) m_\\mathbf{Y}(t) \\] <p>Proof with aim \\(m_\\mathbf{Z}(t) = m_\\mathbf{X}(t) + \\mathbf{Y}(t)\\),</p> \\[ \\begin{align*} m_\\mathbf{z}(t) &amp;= E(e^{t\\mathbf{Z}})=E(E^{t(\\mathbf{X}+\\mathbf{y})})\\\\ &amp;= E(e^{t\\mathbf{X}})e^{t\\mathbf{Y}}\\\\ &amp;= E(e^{t\\mathbf{X}})E(e^{t\\mathbf{Y}})\\\\ &amp;= m_\\mathbf{X}(t) m_\\mathbf{Y}(t) \\end{align*} \\] <p>Example :</p> <p>The probability mass function (PMF) of a random variable \\(\\mathbf{X}\\sim \\text{Poisson}(\\lambda)\\) with discrete random variable \\(\\mathbf{X}\\),</p> \\[ P(\\mathbf{X}=x) = \\frac{\\lambda^xe^{-\\lambda}}{x!} \\] <p>then, the \\(m(t)\\) is :</p> \\[ \\begin{align*} m(t)&amp;=\\sum_x e^{tx}\\frac{\\lambda^xe^{-\\lambda}}{x!}\\\\ &amp;=e^{-\\lambda} \\sum_x \\frac{(e^t\\lambda)^x}{x!}\\\\ &amp;= e^{-\\lambda}e^{\\lambda e^t}\\\\ &amp;= e^{\\lambda\\left(e^t-1\\right)}\\\\ \\end{align*} \\] <p>Compute \\(E(\\mathbf{X}), E(\\mathbf{X}^2),\\cdots ,E(\\mathbf{X}^n)\\) by take differentiating \\(m(t)\\),</p> \\[ \\begin{align*} m(t) &amp;= e^{\\lambda\\left(e^t-1\\right)} \\\\ m'(t)&amp;= e^{\\lambda\\left(e^t-1\\right)} \\cdot \\lambda e^t\\\\ m''(t)&amp;= e^{\\lambda\\left(e^t-1\\right)} (\\lambda e^t)^2 + e^{\\lambda\\left(e^t-1\\right)} (\\lambda e^t)  \\end{align*} \\] <p>To calculate \\(E(\\mathbf{X}^n)\\), set \\(t=0\\) in the \\(n\\)-th derivative of \\(m(t)\\),</p> \\[ \\begin{align*} E(\\mathbf{X}) &amp;= m'(0) = \\lambda \\\\ E(\\mathbf{X}^2) &amp;= m''(0) = \\lambda^2 + \\lambda \\\\ \\end{align*} \\] <p>The variance is given by:</p> \\[ \\begin{align*} \\text{Var}(\\mathbf{X}) &amp;= E(\\mathbf{X}^2) - (E(\\mathbf{X}))^2\\\\ &amp;= \\lambda^2 + \\lambda - \\lambda\\\\ &amp;= \\lambda \\end{align*} \\] <p>Proof</p> <p>Proof Goals : aim to show \\(E(\\mathbf{X}^n) = \\frac{d^n}{d^nt}m(t)\\)</p> <p>For continuous random variables, the moment generating function is:</p> \\[ \\begin{align*} m(t) &amp;= \\int_{-\\infty}^\\infty e^{tx} f(x) \\; dx \\\\ \\end{align*} \\] <p>The derivatives of of \\(m(t)\\) are :</p> \\[ \\begin{align*} m'(t) &amp;= \\int_{-\\infty}^\\infty x e^{tx} f(x) \\; dx \\\\ m''(t) &amp;= \\int_{-\\infty}^\\infty x^2 e^{tx} f(x) \\; dx \\\\ \\vdots &amp; \\quad \\quad \\quad \\quad \\vdots \\\\ \\frac{d^n}{d^nt}m(t) &amp;= \\int_{-\\infty}^\\infty x^n e^{tx} f(x) \\; dx \\end{align*} \\] <p>Substituting \\(t=0\\) into these derivatives, we get the moments:</p> \\[ \\begin{align*} m'(0) &amp;= \\int_{-\\infty}^\\infty x f(x) \\; dx = E(\\mathbf{X})\\\\ m''(0) &amp;= \\int_{-\\infty}^\\infty x^2 f(x) \\; dx = E(\\mathbf{X}^2)\\\\ \\vdots &amp; \\quad \\quad \\quad \\quad \\quad \\vdots \\\\ \\frac{d^n}{d^nt}m(0) &amp;= \\int_{-\\infty}^\\infty x^n f(x) \\; dx = E(\\mathbf{X}^n) \\end{align*} \\] <p>This concludes the proof for the moments of a continuous random variable.</p>"},{"location":"maths/probability/poisson_proccess/","title":"Poisson Proccess","text":"<p>The Poisson distribution is a distribution of the number of events that occur within a given time interval \\(t\\). PThe probability mass function (PMF) of the Poisson distribution is:</p> \\[ P(\\mathbf{X}=k)=\\frac{\\lambda^ke^{-k}}{k!} \\] <p>where \\(\\lambda\\) is the expected number of events over the time interval, or the rate times the time interval.</p> <p>A Poisson process is a process that determines the distribution of the time elapsed between the \\((n-1)\\)-th and \\(n\\)-th event. To calculate this, we use the exponential distribution with mean \\(1/\\lambda\\).</p> <p>Poisson process has the following properties:</p> <ul> <li>The number of events that occur in different time intervals are independent.</li> <li>The distribution of the number of events that occur in a given interval depends only on the length of the interval, not the location in the time domain.</li> <li>The probability of two events occurring at the exact same time is 0.</li> </ul> <p>Example, If the rate is 5 orders per hour, compute the probability of the number of events in a 2-hour interval. This is a Poisson distribution with mean  \\(\\lambda \\times t\\), given \\(\\lambda = 5\\) and \\(t=2\\) :</p> \\[ \\mathbf{X}(2) \\sim \\text{Poisson}(10) \\] <p>Then, the probability of receiving 8 orders in 2 hours is:</p> \\[ P(\\mathbf{X}=8) = \\frac{10^8e^{-10}}{8!} \\approx 0.1126 \\] <p>To compute the probability of the time interval between order arrivals, we use the exponential distribution. The average time between intervals is:</p> \\[ \\text{E}(T) = \\frac{1}{\\lambda} = 0.2 \\text{ hour} \\] <p>Next, we compute the probability that the next order arrives in the next 15 minutes using the CDF of the exponential distribution:</p> \\[ 15 \\text{ minutes} = \\frac{15}{60} =0.25 \\text{ hour}\\] <p>Thus, the probability is:</p> \\[ P(T \\leq 0.25) = 1-e^{-5\\cdot 0.25} \\approx 0.7135 \\]"},{"location":"maths/probability/random_var/","title":"Random Variables","text":"<p>A random variable (\\(\\mathbf{X}\\)) is a function that assigns a numerical value to each outcome of an event in a sample space, quantifying a specific characteristic of the outcomes.</p> \\[ \\mathbf{X} : \\Omega \\rightarrow \\mathbb{R} \\] <p>This is read as: the function \\(\\mathbf{X}\\) maps outcomes from the sample space \\(\\Omega\\) to real numbers \\(\\mathbb{R}\\), where each outcome \\(\\omega \\in \\Omega\\) is represented by \\(\\omega\\).</p> <ul> <li>Continuous Random Variables: Take values within a continuous range (uncountably infinite), e.g., the lifetime of a transistor.</li> <li>Discrete Random Variables: Take values within a discrete (countable) range, e.g., the number of coin flips resulting in heads.</li> </ul>"},{"location":"maths/probability/random_var/#probability-of-random-variables","title":"Probability of Random Variables","text":"<p>The probability of a random variable \\(P(\\mathbf{X})\\) is a function that defines the distribution associated with the random variable. For this, we use the Probability Mass Function (PMF) for discrete variables and the Probability Density Function (PDF) for continuous variables. To calculate probabilities, we need:</p> <ol> <li>Specific values or ranges for \\(\\mathbf{X}\\).</li> <li>The probability of each value or range for \\(\\mathbf{X}\\).</li> </ol>"},{"location":"maths/probability/random_var/#the-importance-of-random-variables","title":"The Importance of Random Variables","text":"<ol> <li>Summarize probabilities through \\(P(\\mathbf{X})\\) without calculating the probability of each outcome in an \\(n\\)-trial experiment individually.</li> <li>Model random processes with the PDF, enabling us to hypothesize about the distribution.</li> <li>Simplify visualization and computation for values within the PDF.</li> <li>Construct new functions based on \\(\\mathbf{X}\\), such as \\(\\mathbf{X}^2\\), \\(E(\\mathbf{X})\\) (expected value), and \\(Var(\\mathbf{X})\\) (variance).</li> </ol>"},{"location":"maths/probability/set_theory/","title":"Set Theory","text":"<p>In this blog, we donated probability of event \\(A\\) by \\(P(A)\\). </p> <ol> <li>The set of all possible outcomes or sample space of random experiment donates by \\(\\Omega\\). Our probability \\(P(A)\\) map from subsets of \\(\\Omega\\) to \\(\\mathbb{R}\\), where it valued with \\([0,1] \\in \\mathbb{R}\\).  Each outcome of experiment \\(\\omega \\in \\Omega\\) encapsulates all information at the end of specific experiment.  </li> <li> <p>Event space \\(\\Sigma : A\\) is the set of all outcomes of experiment takes. \\(\\Sigma\\) is subset of \\(\\Omega\\).</p> </li> <li> <p>Properties of \\(P\\), \\(\\Sigma\\) has to stisfy three of these properties:</p> <ul> <li>\\(P(\\Omega) = 1\\)</li> <li>If \\(A\\subset\\Omega\\) then \\(P(A) \\ge 0\\)</li> <li>If \\(A_i\\) and \\(A_j\\) are disjoint events, then \\(A_i \\cap A_j = \\emptyset\\) with \\(i\\neq j\\). Disjoint means \\(A_i\\) and \\(A_j\\) are separate.</li> </ul> </li> </ol> <p>Those three of properties are known as Axioms of Probability. Then, </p> \\[ P : \\Sigma \\rightarrow [0, 1] \\] <p>Other Properties : </p> <ul> <li>If \\(A_i\\) and \\(A_j\\) are separate, \\(P(A_i\\cup A_j) = P(A_i) + P(A_j)\\)</li> <li>If \\(A_i\\) and \\(A_j\\) are not separate and independent, \\(P(A_i \\cap A_j) = P(A_i) \\times P(A_j)\\)</li> <li>\\(P(A_i \\cup A_j) = P(A_i) + P(A_j) - P(A_i \\cap A_j)\\)</li> <li>\\(A^c = 1-P(A)\\)</li> <li>If \\(A\\) is empty set, then \\(P(A) = P(\\emptyset)=0\\)</li> <li>If \\(A \\subseteq B\\), then \\(P(A) \\leq P(B)\\)</li> </ul> <p>Example : If we throw 3 coin flips. The sample space we have is :</p> \\[ \\Omega = \\{ HHH, HHT, HTH, HTT, THH, THT, TTH, TTT\\} \\] <p>There are 8 possible outcomes, with <code>H is head</code> and <code>T is tail</code>.</p> <p>We take 2 events where \\(A\\) and \\(B\\) are independent, the set of outcomes where first flip is a head \\(\\{HHH, HHT, HTH, HTT\\}\\), donated by \\(A\\).The set of outcomes where second flip is a tail \\(\\{HTH, HTT, TTH, TTT\\}\\), donated by \\(B\\). So,</p> \\[ P(A) = \\frac{4}{8} = \\frac{1}{2}\\\\ P(B) = \\frac{4}{8} = \\frac{1}{2} \\] <ul> <li>Every outcomes in both \\(A\\) and \\(B\\), \\(P(A \\cap B) = P(A) \\times P(B)\\)</li> </ul> \\[ P(A \\cap B) = \\{HHH, HTT\\} = \\frac{1}{2} \\times \\frac{1}{2} = \\frac{1}{4} \\] <ul> <li>Every outcomes in \\(A\\) or \\(B\\), \\(P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\)</li> </ul> \\[ P(A \\cup B) = \\{HHH, HHT, HTH, HTT, TTH, TTT\\} = \\frac{1}{2} + \\frac{1}{2} - \\frac{1}{4} = \\frac{3}{4} \\] <ul> <li>Every outcomes are not in \\(A\\), \\(A^c = 1-P(A)\\)</li> </ul> \\[ A^c = \\{THH, THT, TTH, TTT\\} = 1 - \\frac{1}{2} = \\frac{1}{2} \\] <p>Info</p> <p>Most of this section refered to Review of Probability Theory by Maleki and Do, A First Course in Probability by Sheldon Ross, and Probability Bootcamp by Steve Bruton</p>"},{"location":"maths/probability/tail_sum/","title":"Tail Sum","text":"<p>If \\(\\mathbf{X}\\) is a non-negative random variable, then:</p> <ul> <li> <p>For discrete:</p> \\[ E(\\mathbf{X}) = \\sum_{k=1}^n P(\\mathbf{X}=k) \\] </li> <li> <p>For continuous:</p> \\[ E(\\mathbf{X}) = \\int_0^{\\infty} P(\\mathbf{X}&gt;k) \\, dt \\] </li> </ul> <p>Example :</p> \\[ E(\\mathbf{X}) = \\sum_{k=1}^n P(\\mathbf{X}=k) = \\sum_{k=0}^n k P(\\mathbf{X}=k) \\] \\[ \\begin{matrix} P(\\mathbf{X} \\ge 1) &amp; P_1 + P_2 + P_3 + \\cdots + P_{n-1} + P_n \\\\ P(\\mathbf{X} \\ge 2) &amp; \\quad + P_2 + P_3 + \\cdots + P_{n-1} + P_n \\\\ P(\\mathbf{X} \\ge 3) &amp; \\quad \\quad + P_3 + \\cdots + P_{n-1} + P_n \\\\ \\vdots &amp; \\vdots \\\\ P(\\mathbf{X} \\ge n-1) &amp; \\quad \\quad \\quad \\quad + P_{n-1} + P_n \\\\ P(\\mathbf{X} \\ge n) &amp; \\quad \\quad \\quad \\quad \\quad + P_n \\\\ \\end{matrix} \\] \\[ P(\\mathbf{X} \\ge k) = 1 - P(\\mathbf{X} \\leq k) \\]"},{"location":"maths/probability/total_probs/","title":"Law of Total Probability","text":"<p>Given \\(B_1, B_2, B_3, \\cdots\\) be a partition of \\(\\Omega\\), so that \\(\\Omega = \\bigcup_{i=1}^n B_i\\). The total probability of an event \\(A\\), donated by \\(P(A)\\), can be found by summing the probabilities over each part of the partition. This is analogous to finding the total area of a country by summing the areas of its provinces.</p> \\[ P(A) = \\sum_{i=1}^n P(A \\cap B_i) = \\sum_{i=1}^n P(A|B_i)P(B_i) \\] <p>Proof</p> <p>Since \\(B_i\\) is a partition of \\(\\Omega\\), we have</p> \\[ \\Omega = \\bigcup_{i=1}^n B_i \\\\ \\begin{align*} A &amp;= A \\cap \\Omega\\\\ &amp;= A \\cap \\left(\\bigcup_i B_i \\right)\\\\ &amp;=\\bigcup_i(A \\cap B_i) \\end{align*} \\] <p>By the third axiom of probability (additivity),</p> \\[ \\begin{align*} P(A) &amp;= P\\left(\\bigcup_i(A \\cap B_i)\\right) \\\\ &amp;= \\sum_i P(A\\cap B_i) \\\\ &amp;= \\sum_i P(A|B_i)P(B_i) \\end{align*}\\\\ \\] <p>To make this more intuitive, let\u2019s consider an illustration from Steve's video.</p> <p>Based on the illustration, we have</p> \\[ P(A) = P(A \\cap B) + P(A \\cap B^c) \\] <p>Using the definition of conditional probability, this equation becomes</p> \\[ P(A) = P(A|B)P(B) + P(A|B^c)P(B^c) \\] <p>This is easier to understand intuitively. Since \\(A\\) overlap with \\(B_1\\) and \\(B_2\\), it means \\(A \\cap B\\). Where the entire left area of \\(B\\) is \\(B^c\\), so the total area of left area is \\(A \\cap B^c\\).</p>"},{"location":"maths/probability/var_std/","title":"Variance and Standard Deviation","text":"<p>The mean \\(\\mu\\) is defined as the center of mass of the distribution, the variance \\(\\sigma^2\\) is the average of squared differences from the mean \\(\\mu\\), and the standard deviation \\(\\sigma\\) tells us how spread out the distribution is.</p> <p>If we apply a function \\(g(\\cdot)\\) to \\(\\mathbf{X}\\), with \\(g(\\mathbf{X}) = \\mathbf{X}^2\\), then:</p> \\[ \\begin{aligned} \\mathbf{Y} &amp;= \\mathbf{X}^2 \\\\ E(\\mathbf{Y}) &amp;= \\int_{-\\infty}^{\\infty} x^2 f(x) \\, dx \\end{aligned} \\] <p>If \\(\\mathbf{X}\\) and \\(\\mathbf{Y}\\) are independent, then:</p> \\[ \\text{Var}(\\mathbf{X} + \\mathbf{Y}) = \\text{Var}(\\mathbf{X}) + \\text{Var}(\\mathbf{Y}) \\] <p>Let the random variable \\(\\mathbf{X}\\) follow a normal distribution:</p> \\[ \\mathbf{X} \\sim \\mathcal{N}(\\mu, \\sigma^2) \\] <p>Then, the PDF of the normal distribution is:</p> \\[ f(x) = \\frac{1}{\\sqrt{2\\pi} \\sigma} e^{-\\frac{(x - \\mu)^2}{2 \\sigma^2}} \\] <p>where \\(\\mu\\) is \\(E(\\mathbf{X})\\) and \\(\\sigma^2\\) is the variance of \\(\\mathbf{X}\\).</p> <p>To compute \\(\\text{Var}(\\mathbf{X})\\), we have:</p> \\[ \\begin{aligned} \\text{Var}(\\mathbf{X}) &amp;= E((\\mathbf{X} - \\mu)^2) \\\\ &amp;= E(\\mathbf{X}^2) - [E(\\mathbf{X})]^2 \\end{aligned} \\] <p>Proof:</p> \\[ \\begin{aligned} \\text{Var}(\\mathbf{X}) &amp;= E((\\mathbf{X} - \\mu)^2) \\\\ &amp;= E(\\mathbf{X}^2 - 2\\mu \\mathbf{X} + \\mu^2) \\\\ &amp;= E(\\mathbf{X}^2) - E(2\\mu \\mathbf{X}) + E(\\mu^2) \\\\ &amp;= E(\\mathbf{X}^2) - 2\\mu E(\\mathbf{X}) + \\mu^2 \\\\ &amp;= E(\\mathbf{X}^2) - \\mu^2 \\end{aligned} \\]"},{"location":"maths/probability/var_std/#example","title":"Example:","text":"<p>Given \\(T \\sim \\text{Exp}(\\lambda)\\), where the PDF is \\(f(t) = \\lambda e^{-\\lambda t}\\), the mean is:</p> \\[ \\begin{aligned} E(T) &amp;= \\int_0^\\infty t f(t) \\, dt \\\\ &amp;= \\int_0^\\infty t \\lambda e^{-\\lambda t} \\, dt \\\\ &amp;= \\left[ -t e^{-\\lambda t} \\right]_0^\\infty + \\int_0^\\infty e^{-\\lambda t} \\, dt \\\\ &amp;= 0 - \\frac{1}{\\lambda} \\left[ e^{-\\lambda t} \\right]_0^\\infty \\\\ &amp;= \\frac{1}{\\lambda} \\end{aligned} \\] <p>Variance:</p> \\[ \\begin{aligned} \\text{Var}(T) &amp;= E(T^2) - [E(T)]^2 \\end{aligned} \\] <p>To compute \\(E(T^2)\\), we have:</p> \\[ \\begin{aligned} E(T^2) &amp;= \\int_0^\\infty t^2 \\lambda e^{-\\lambda t} \\, dt \\\\ &amp;= \\frac{2}{\\lambda^2} \\end{aligned} \\] <p>Then:</p> \\[ \\begin{aligned} \\text{Var}(T) &amp;= \\frac{2}{\\lambda^2} - \\frac{1}{\\lambda^2} \\\\ &amp;= \\frac{1}{\\lambda^2} \\end{aligned} \\] <p>Standard Deviation:</p> \\[ \\sigma(T) = \\sqrt{\\frac{1}{\\lambda^2}} = \\frac{1}{\\lambda} \\] <p>Median:</p> \\[ \\begin{aligned} F(t) &amp;= \\int_0^t f(t) \\, dt \\\\ &amp;= 1 - e^{-\\lambda t} = \\frac{1}{2} \\end{aligned} \\] <p>Then, we solve \\(e^{-\\lambda t} = \\frac{1}{2}\\), which gives:</p> \\[ t = \\frac{\\ln(2)}{\\lambda} \\] <p>Thus, the median is:</p> \\[ \\text{Median}(T) = \\frac{\\ln(2)}{\\lambda} \\]"},{"location":"robotics/preface/","title":"Robotics","text":"<p>This section focuses on the fundamentals of robotics, covering nonlinear control systems, sensor fusion methods, and slam techniques.</p>"},{"location":"robotics/preface/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Preface</li> <li>Equation of Motion<ul> <li>Quadcopter</li> </ul> </li> <li>Nonlinear Control<ul> <li>Introduction to Nonlinear Systems</li> <li>Phase Plane Analysis</li> <li>Geometric Control on SE(3)</li> </ul> </li> <li>Sensor Fusion<ul> <li>Kalman Filter</li> <li>Extended Kalman Filter</li> </ul> </li> <li>SLAM<ul> <li>Point-to-Point Iterative Closest Point</li> <li>Point-to-Line Iterative Closest Point</li> <li>Pose-Graph</li> </ul> </li> <li>system Indentification<ul> <li>WyNDA</li> </ul> </li> </ul>"},{"location":"robotics/eq_of_motion/quadcopter/","title":"Quadrotor Dynamics","text":"<p>In this tutorial we will derived quadrotor model by using Newtonian mechanics and ZYX Euler Angles convention, Langragian mechanics (soon \ud83d\ude42), and Hamiltonian mechanics (soon \ud83d\ude42).</p>"},{"location":"robotics/eq_of_motion/quadcopter/#newtonian-euler","title":"Newtonian - Euler","text":"\\[ \\zeta = \\left [ x \\; y \\; z \\right ]^T \\in \\mathbb{R}^3\\\\ \\eta = \\left [ \\phi \\; \\theta \\; \\psi \\right ]^T \\in \\mathbb{R}^3\\\\ \\nu = \\left [ u \\; v \\; w \\right ]^T \\in \\mathbb{R}^3\\\\ \\omega = \\left [ p \\; q \\; r \\right ]^T \\in \\mathbb{R}^3\\\\ \\textbf{m}_B = \\left [ m_x \\; m_y \\; m_z \\right ]^T \\in \\mathbb{R}^3\\\\ \\textbf{f}_B = \\left [ f_x \\; f_y \\; f_z \\right ]^T \\in \\mathbb{R}^3 \\] <p>Where \\(\\zeta\\) and \\(\\eta\\) are linear and angular velocity from inertial frame to body frame, respectively. \\(\\nu\\) and \\(\\omega\\) are linear and angular velocity from body frame to inertial frame. \\(\\textbf{f}_B\\) and \\(\\textbf{m}_B\\) are total forces and moments.</p>"},{"location":"robotics/eq_of_motion/quadcopter/#mathematical-model","title":"Mathematical Model","text":"\\[ \\dot{\\zeta} = R \\cdot \\nu \\\\ \\dot{\\eta} = T^{-1} \\cdot \\omega    \\] <p>where \\(T\\) is a angular velocity transformation matrix from body frame to inertial frame,</p> \\[ T = \\begin{bmatrix} 1 &amp; 0 &amp; -\\sin(\\theta) \\\\ 0 &amp; \\cos(\\phi) &amp; \\sin(\\phi)\\sin(\\theta) \\\\ 0 &amp; \\sin(\\phi) &amp; \\cos(\\phi)\\cos(\\theta) \\end{bmatrix} \\] \\[ T^{-1} = \\begin{bmatrix} 1 &amp; \\sin(\\phi)\\tan(\\theta) &amp; \\cos(\\phi) \\\\ 0 &amp; \\cos(\\phi) &amp; -\\sin(\\theta) \\\\ 0 &amp; \\frac{\\sin(\\phi)}{\\cos(\\theta)} &amp; \\frac{\\cos(\\phi)}{\\cos(\\theta)} \\end{bmatrix} \\] <p>and \\(R\\) is a Euler rotation matrix,</p> \\[ R = \\begin{bmatrix} \\cos\\psi \\cos\\theta &amp; \\cos\\psi \\sin\\theta \\sin\\phi - \\sin\\psi \\cos\\phi &amp; \\cos\\psi \\sin\\theta \\cos\\phi + \\sin\\psi \\sin\\phi \\\\ \\sin\\psi \\cos\\theta &amp; \\sin\\psi \\sin\\theta \\sin\\phi + \\cos\\psi \\cos\\phi &amp; \\sin\\psi \\sin\\theta \\cos\\phi - \\cos\\psi \\sin\\phi \\\\ -\\sin\\theta &amp; \\cos\\theta \\sin\\phi &amp; \\cos\\theta \\cos\\phi \\end{bmatrix} \\]"},{"location":"robotics/eq_of_motion/quadcopter/#moments","title":"Moments","text":"\\[ \\textbf{m}_B = I\\cdot \\dot{\\omega} + \\omega \\times (I\\cdot\\omega_B) \\\\ \\textbf{m}_B = \\tau_B - \\text{g}_a \\\\ I\\cdot \\dot{\\omega} + \\omega \\times (I\\cdot\\omega_B) = \\tau_B - \\text{g}_a  \\] <p>so,</p> \\[ \\dot{\\omega} =  I^{-1}(\\tau_B - \\omega \\times (I \\cdot \\omega)) \\] <p>where \\(I\\) is a  inertia matrix, assume the quadrotor has a symmetric structure, so that </p> \\[ I = \\begin{bmatrix} I_{xx} &amp; 0 &amp; 0\\\\ 0 &amp; I_{yy} &amp; 0\\\\ 0 &amp; 0 &amp; I_{zz} \\end{bmatrix} \\in \\mathbb{R}^{3\\times3} \\] <p>and \\(\\tau_B\\)</p> \\[ \\tau_B = \\begin{bmatrix}  kl(\\omega_{m,4}^2 - \\omega_{m,2}^2)\\\\ kl(\\omega_{m,3}^2 - \\omega_{m,1}^2)\\\\ b(\\omega_{m,1}^2 + \\omega_{m,4}^2 - \\omega_{m,1}^2-\\omega_{m,3}^2) \\end{bmatrix} \\]"},{"location":"robotics/eq_of_motion/quadcopter/#forces","title":"Forces","text":"\\[ \\textbf{f}_B = m(\\omega \\times \\nu + \\dot{\\nu}) \\\\ \\textbf{f}_B = - mgR^T + \\textbf{T}_m \\\\ m(\\omega \\times \\nu + \\dot{\\nu}) = - mgR^T + \\textbf{T}_m \\] <p>so, </p> \\[ \\dot{\\nu} = - g R^T + \\frac{\\text{T}_B}{m}-\\omega \\times \\nu \\] <p>given \\(\\textbf{T}_B\\)</p> \\[ \\textbf{T}_B = \\begin{bmatrix} 0\\\\ 0\\\\ k\\sum_{i=1}^4 \\omega_{m,i} \\end{bmatrix} \\]"},{"location":"robotics/eq_of_motion/quadcopter/#state-space-model","title":"State-Space Model","text":"<p>Given state vector :</p> \\[ \\textbf{x} = \\begin{bmatrix} \\eta &amp; \\omega &amp; \\nu &amp; \\zeta \\end{bmatrix}^T \\in \\mathbb{R}^{12} \\] \\[ \\begin{aligned} \\dot\\phi  &amp;=  p +r[\\cos\\phi\\tan\\theta]+[\\sin\\phi\\tan\\theta] \\\\ \\dot\\theta  &amp;= q[\\cos\\phi]-r[\\sin\\phi]\\\\ \\dot\\psi &amp;= r \\frac{\\cos\\phi}{\\cos\\theta}+q\\frac{\\sin\\phi}{\\cos\\theta}\\\\\\ \\dot{p} &amp;= \\frac{I_{yy}-I_{zz}}{I_{xx}}rq+\\frac{\\tau_x}{I_{xx}}\\\\ \\dot{q} &amp;= \\frac{I_{zz}-I_{xx}}{I_{yy}}pr+\\frac{\\tau_y}{I_{yy}}\\\\ \\dot{r} &amp;= \\frac{I_{xx}-I_{yy}}{I_{zz}}pq+\\frac{\\tau_z}{I_{zz}}\\\\ \\dot{u} &amp;= rv+qw+g[\\sin\\theta]\\\\ \\dot{v} &amp;= pw+ru-g[\\sin\\phi\\cos\\theta]\\\\ \\dot{w} &amp;= qu+pv-g[\\cos\\theta\\cos\\phi]\\\\ \\dot{x} &amp;= u[\\cos\\psi \\cos\\theta] - v[\\cos\\psi \\sin\\theta \\sin\\phi - \\sin\\psi \\cos\\phi] + w[\\cos\\psi \\sin\\theta \\cos\\phi + \\sin\\psi \\sin\\phi]\\\\ \\dot{y} &amp;= u[\\sin\\psi \\cos\\theta] + v[\\sin\\psi \\sin\\theta \\sin\\phi + \\cos\\psi \\cos\\phi] - w[\\sin\\psi \\sin\\theta \\cos\\phi - \\cos\\psi \\sin\\phi]\\\\ \\dot{z} &amp;= u[-\\sin\\theta] + v[\\cos\\theta \\sin\\phi]  w[\\cos\\theta \\cos\\phi] \\end{aligned} \\]"},{"location":"robotics/nonlinear_control/geom_quadcopter/","title":"Geometric Control of Quadrotor on SE(3)","text":"<p>This page is under construction</p> <p>Nonlinear dynamics naturally evolve on non-flat spaces, and controlling them using flat-space representations often introduces singularities and global instability. For systems like quadcopters, whose dynamics lie on the manifold \\(SE(3)\\), geometric control offers a framework to design controllers that intrinsically respect the manifold\u2019s structure. </p> <p>Euler angle-based controllers exhibit singularities (gimbal lock) when representing complex rotational maneuvers. Quaternion-based controllers can avoid singularities, but they represent attitude by double-covering the configuration of special orthogonal group \\(SO(3)\\). Geometric control, based on Lie theory, avoids complexities, discontinuities, and ambiguities [1].</p> <p>Although quadcopters are underactuated systems with four inputs and six degrees of freedom, geometric control achieves asymptotic tracking of a subset of outputs, such as position or attitude, while maintaining stability in other degrees of freedom [1].</p> <p>Info</p> <p>This page focuses on derivation of the error equations from [1] and providing some intuition behind them. We don't explain the dynamics of quadcopters here; for that, you can refer to Quadcopter Dynamics for details on quadcopter equations of motion.</p> <p>Quadcopters equations of motion in short,  </p> \\[ \\begin{gather} \\dot{x} = v \\\\ \\dot{v} = gz_W-\\frac{f}{m}Rz_B \\\\ \\dot{R} = R \\hat{\\Omega} \\\\ J\\dot{\\Omega} + \\Omega \\times J \\Omega = M \\\\ \\end{gather} \\] <p>where :</p> <ul> <li>\\(m \\in \\mathbb{R}\\) is the total mass  </li> <li>\\(J \\in \\mathbb{R}^{3 \\times 3}\\) is the inertia matrix with respect to the body-fixed frame  </li> <li>\\(R \\in SO(3)\\) is the rotation matrix from the body frame to the inertial frame</li> <li>\\(\\dot{x}\\) is the position derivative (velocity) in the inertial frame</li> <li>\\(\\dot{v}\\) is the acceleration in the inertial frame</li> <li>\\(\\hat{\\Omega}\\) is the skew-symmetric matrix of angular velocity \\(\\Omega\\) </li> <li>\\(f\\) is the total thrust force</li> <li>\\(M\\) is the moment vector applied to the body-fixed frame</li> <li>\\(z_W\\) is z-axis in inertial reference frame</li> <li>\\(z_B\\) is z-axis in body frame</li> </ul> Lie Algebra \\(\\mathfrak{g}\\) \\(\\leftrightharpoons\\) Euclidean Space \\(\\mathbb{R}\\) <ul> <li>Hat map \\((\\hat{\\cdot}) : \\mathbb{R}^3 \\rightarrow \\mathfrak{so}(3)\\) for mapping vector in \\(\\mathbb{R}^3\\) to lie algebra of \\(SO(3)\\).</li> <li>Vee map \\(({\\cdot}^\\vee) : \\mathfrak{so}(3) \\rightarrow \\mathbb{R}^3\\) is the inverse of hat map.</li> </ul> <p>Lie Theory for robotics explain more here.</p>"},{"location":"robotics/nonlinear_control/geom_quadcopter/#the-error-functions","title":"The Error Functions","text":"<p>Lee, et. al use multiple controller to achieve asymptotic output tracking of both attitude and position; attitude control, position control, and velocity control.  Complex flight maneuver can be defined by specifying a concatenation of flight modes together with conditions for switching between them.</p>"},{"location":"robotics/nonlinear_control/geom_quadcopter/#attitude-error","title":"Attitude Error","text":"<p>This type of control mode requires desired attitude \\(R_d(t) \\in SO(3)\\) and current attitude \\(R(t) \\in SO(3)\\) are function of time, where represented as \\(R_d\\) and \\(R\\) for simplified the derivation. Then, they choose the error function on \\(SO(3) \\times SO(3)\\) as follows :</p> \\[ \\begin{align} \\Gamma(R, R_d) = \\frac{1}{2}\\mathrm{tr} \\left[I_3-R_d^TR \\right]  \\end{align} \\] <p>\\(R_d^TR\\) is relative attitude that transforms a vector from the current frame to the desired frame.  If current attitude \\(R\\) align to \\(R_d\\) it makes \\(R_d^TR\\) equals the identity matrix \\(I\\), and the error function \\(\\Gamma(R, R_d)\\) becomes zero. </p> How \\(R_d^TR=I\\)? <p>This follows from the fundamental axiom of groups, which states that the product of an element and its inverse is the identity element: </p> \\[ AA^{-1}=I \\] <p>For \\(R \\in SO(3)\\), where \\(R^{-1}=R^T\\) because of rotation matrices are orthogonal. Therefore, the product of a rotation matrix and its inverse is:</p> \\[ R^{-1}R=R^TR=I \\] <p>So, if \\(R_d=R\\) it will leads to identity. </p> <p>Analyze Eq. (5), </p> \\[ \\begin{align} \\Gamma(R, R_d) &amp;= \\frac{1}{2}\\left[\\mathrm{tr}(I_3)-\\mathrm{tr}(R_d^TR)\\right]\\\\ &amp;= \\frac{1}{2}\\left[ 3-1-2\\cos(\\theta) \\right]\\\\ &amp;= 1-\\cos(\\theta)\\\\ \\end{align} \\] <p>where \\(\\theta\\) is angle of rotation. The function \\(\\Gamma\\) is locally positive definite \\((\\Gamma \\ge 0)\\) when relative angle less than \\(180^\\circ\\). </p> <ul> <li>The \\(\\cos(\\theta) \\in [\u22121, 1]\\) for \\(\\theta \\in [0, \\pi]\\).</li> <li>\\(\\Gamma(R, R_d)=0\\), if \\(\\theta=0^\\circ\\). </li> <li>\\(\\Gamma(R, R_d) &gt; 0\\), for \\(0^\\circ &lt; \\theta &lt; 180^\\circ\\).</li> </ul> Why exclude \\(\\theta = 180^\\circ\\)? <p>Based on [2] (Chapter 11), we can take attitude error \\(e_R\\) by take derivative of error function \\(\\Gamma \\in SO(3) \\times SO(3)\\)  with variation of rotation matrix expressed as \\(\\partial R = R\\hat{\\omega}\\) for \\(\\omega \\in \\mathbb{R}^3\\). Then, the variational derivative when dealing with variation of rotation expressed as follows :</p> \\[ \\begin{align} D_R\\Gamma(R, R_d) \\cdot \\partial R  \\end{align} \\] <p>By using \\(\\frac{\\partial}{\\partial X} \\mathrm{tr}(XA) = A^T\\) [3]</p> \\[ \\begin{align} D_R \\Gamma(R, R_d) = \\frac{\\partial \\Gamma (R, R_d)}{\\partial R} = -\\frac{1}{2}R_d  \\end{align} \\] <p>Then, apply Frobenius inner product for both \\(D_R \\Gamma\\) and \\(\\partial R\\)  , \\(\\left&lt; A, B \\right&gt; = \\mathrm{tr}(A^TB)\\)</p> \\[ \\begin{align} \\left&lt; D_R\\Gamma(R, R_d), \\partial R \\right&gt; &amp;= \\mathrm{tr}\\left(\\left( -\\frac{1}{2}R_d \\right)^T \\partial R \\right) \\\\ &amp;= \\mathrm{tr}\\left(-\\frac{1}{2}R_d^T \\partial R \\right) \\\\ &amp;= -\\frac{1}{2} \\mathrm{tr}\\left(R_d^T \\partial R \\right) \\\\ &amp;= -\\frac{1}{2} \\mathrm{tr}\\left(R_d^T R\\hat{\\omega} \\right) \\\\ \\end{align} \\] <p>Use property of hat map, \\(-\\frac{1}{2}\\mathrm{tr}\\left(\\hat{x}\\hat{y}\\right) = x^Ty = x\\cdot y\\), where \\((\\cdot)\\) is a vector dot product.  To construct the skew-symmetric, we can use \\(\\hat{a} = \\frac{1}{2}(A-A^T)\\) for \\(A \\in  G\\) where \\(G\\) is Lie groups, </p> \\[ \\begin{align} \\left&lt; D_R\\Gamma(R, R_d), \\partial R \\right&gt; &amp;= -\\frac{1}{2}\\cdot \\frac{1}{2} \\mathrm{tr}\\left(\\left(R_d^T R \\right)\\hat{\\omega} \\right) \\\\ &amp;= -\\frac{1}{2} \\cdot \\frac{1}{2}\\mathrm{tr}\\left(\\left(R_d^T R - \\left(R_d^T R\\right)^T \\right)\\hat{\\omega} \\right) \\\\ &amp;= \\frac{1}{2} \\left( -\\frac{1}{2} \\mathrm{tr}\\left(\\left[R_d^T R - R^TR_d\\right]\\hat{\\omega}\\right) \\right) \\\\ &amp;= \\frac{1}{2}\\left(R_d^T R - R^TR_d\\right)^\\vee \\cdot \\omega \\\\ \\end{align} \\] <p>Then, rotation error \\(e_R \\in \\mathbb{R}^3\\) expressed as follows :</p> \\[ \\begin{align} e_R = \\frac{1}{2}\\left(R_d^T R - R^TR_d\\right)^\\vee  \\end{align} \\] Related to geodesic distance on \\(SO(3)\\) <p>Geodesic distance in the special orthogonal group \\(SO(3)\\) [4] is given by:</p> \\[ \\begin{align} d_{\\text{geo}}(R, R_d) = ||\\log(R_d^TR)||_F  \\end{align} \\] <p>Where logarithm of \\(R \\in SO(3)\\) is defined as:</p> \\[ \\begin{equation} \\log R = \\begin{cases}     0 &amp; \\text{if} &amp; \\theta = 0 \\\\     \\frac{\\theta}{2 \\sin (\\theta)} [R - R^T] &amp;\\text{if}&amp;\\theta \\neq 0 \\end{cases}  \\end{equation} \\] <p>with \\(\\theta = \\cos^{-1} \\left( \\frac{\\mathrm{tr}(R) - 1}{2} \\right)\\).</p> <p>Starting from Eq.(20), we derive the geodesic distance, where \\(||\\cdot||_F\\) is Frobenius norm.</p> \\[ \\begin{align} \\log (R_d^TR) = \\frac{\\theta}{2 \\sin (\\theta)} [R_d^TR - R^TR_d]  \\end{align} \\] <p>Subtitute Eq.(22) to Eq.(20), where \\(||A||_F = \\sqrt{\\left&lt; A, A\\right&gt;} = \\sqrt{\\mathrm{tr}(A^TA)}\\)</p> \\[ \\begin{align} d_{\\text{geo}}(R, R_d) &amp;= \\sqrt{\\mathrm{tr}\\left[\\log(R_{d}^{T}R)^{T}\\log(R_{d}^{T}R)\\right]} \\\\ &amp;= \\sqrt{\\mathrm{tr}\\left[\\left(\\frac{\\theta}{2\\sin(\\theta)}\\left(R_{d}^{T}R - R^{T}R_{d}\\right)\\right)^{T} \\frac{\\theta}{2\\sin(\\theta)}\\left(R_{d}^{T}R - R^{T}R_{d}\\right)\\right]} \\\\ &amp;= \\frac{\\theta}{2\\sin(\\theta)} \\sqrt{\\mathrm{tr}\\left[\\left(\\left(R_{d}^{T}R - R^{T}R_{d}\\right)\\right)^{T} \\left(R_{d}^{T}R - R^{T}R_{d}\\right)\\right]} \\\\ \\end{align} \\] <p>Since the Frobenius norm is always non-negative, the minus sign \\(\\mathrm{tr}[\\hat{x}\\hat{y}] = -2x \\cdot y\\) is irrelevant. Frobenious norm take \\(\\sqrt{\\|\\cdot \\|^2}\\) [5] for rotation matrix makes minus sign irrelevant.</p> \\[ \\begin{align} d_{\\text{geo}}(R, R_d) = \\frac{\\theta}{\\sin(\\theta)}\\left\\|\\left(R_d^TR - R^TR_d\\right)^\\vee \\right\\| \\\\ \\end{align} \\] <p>From dynamics of quadrotor we can get \\(\\dot{R} = R\\hat{\\Omega}\\) and \\(\\dot{R}_d = R_d\\hat{\\Omega}_d\\). To compare angular velocity we have to calculate in same tangent space either \\(\\mathsf{T}_RSO(3)\\) or \\(\\mathsf{T}_{R_d}SO(3)\\).  Thus, the different of time derivative of rotation \\(R\\) and \\(R\\) equivalent to \\(R\\hat{e}_\\Omega\\).</p> \\[ \\begin{align} \\dot{R} - \\dot{R}_d(R_d^TR) &amp;= R\\hat{\\Omega} -R_d\\hat{\\Omega}_dR_d^TR \\\\ &amp;= R\\hat{\\Omega} -(RR^T)R_d\\hat{\\Omega}_dR_d^TR \\\\ &amp;= R\\hat{\\Omega} - R(R^TR_d\\hat{\\Omega}_dR_d^TR)^\\hat \\\\ \\end{align} \\] <p>Where \\(RR^T=I\\). Then, re-arrange Eq. (29) to match with \\(R\\hat{e}_\\Omega\\).</p> \\[ \\begin{align} \\dot{R} - \\dot{R}_d(R_d^TR) = R(\\hat{\\Omega} - R^TR_d\\hat{\\Omega}_dR_d^TR)  \\end{align} \\] <p>Thus, we can get \\(\\hat{e}_\\Omega\\)</p> \\[ \\begin{align} \\hat{e}_\\Omega = \\hat{\\Omega} - R^TR_d\\hat{\\Omega}_dR_d^TR  \\end{align} \\] <p>In vector space \\(e_\\Omega \\in \\mathbb{R}^3\\), </p> \\[ \\begin{align} e_\\Omega = \\Omega - R^TR_d{\\Omega}_d  \\end{align} \\] Angular Velocity Error \\(e_\\Omega\\) from Lie Groups Adjoint Action <p>Since tangent \\(\\dot{R}\\in \\mathsf{T}_RSO(3)\\) and \\(\\dot{R}_d \\mathsf{T}_{R_d}SO(3)\\) are \"live\" on different tangent spaces, so we need \"transform\" one of them. Thanks to adjoint action, a distinguished operator on the Lie algebra, this transformation can be achieved.</p> <p>We have to \"transform\" \\(\\dot{R}_d\\) to \\(\\mathsf{T}_RSO(3)\\). The relative rotation \\(R_{rel}\\) of it expressed as \\(R^TR_d\\) to rotate the vector from \\(R_d\\)-frame to \\(R\\)-frame. Where \\(R_{rel}\\) is an element of \\(SO(3)\\), then</p> \\[ \\begin{align} \\mathsf{Adj}_{R_{rel}}\\left(\\hat{\\Omega}_d\\right)&amp;= R_{rel}\\hat{\\Omega}_d\\left(R_{rel}\\right)^{-1} \\in \\mathfrak{so}(3) \\\\ &amp;= \\widehat{R_{rel}\\Omega} \\\\ \\mathsf{Adj}_{R_{rel}} &amp;= R_{rel} \\end{align} \\] <p>So, we can applied directly to tangent vector, where \\(\\hat{\\Omega}, \\hat{\\Omega}_d \\in \\mathfrak{so}(3)\\) and \\(\\Omega, \\Omega_d \\in \\mathbb{R}^3\\)</p> \\[ \\begin{align} \\Omega_d = R^TR_d\\Omega_d \\in \\mathsf{T}_RSO(3)  \\end{align} \\] <p>Thus,</p> \\[ \\begin{align} e_\\Omega = \\Omega - R^TR_d\\Omega_d \\end{align} \\]"},{"location":"robotics/nonlinear_control/geom_quadcopter/#position-and-velocity-errors","title":"Position and Velocity Errors","text":"<p>Error on position control \\(e_p\\) pretty straightforward, we need desired position \\(p_d \\in \\mathbb{R}^3\\), current position \\(p_d \\in \\mathbb{R}^3\\),  desired linear velocity \\(\\dot{p}_d \\in \\mathbb{R}^3\\), and current velocity \\(v \\in \\mathbb{R}^3\\). </p> \\[ \\begin{align} e_p = p - p_d \\\\ e_v = v - \\dot{p}_d  \\end{align} \\]"},{"location":"robotics/nonlinear_control/geom_quadcopter/#control-law","title":"Control Law","text":"<p>Three different types of control modes derive different control law.  We derived thrust \\(f\\) and total moment \\(M\\) control law by using Eq. (2) and Eq. (4), respectively.  To recall those,</p> \\[ \\begin{align*} \\dot{v} = gz_W-\\frac{f}{m}Rz_B \\tag{2}\\\\ J\\dot{\\Omega} + \\Omega \\times J \\Omega = M \\tag{4}\\\\ \\end{align*} \\]"},{"location":"robotics/nonlinear_control/geom_quadcopter/#attitude-control","title":"Attitude Control","text":"<p>In this mode, it is possible to neglected translation equation of motion Eq. (2). Then, we need to define gain \\(k_R \\in \\mathbb{R}^{3}_+\\) for rotation and \\(k_\\Omega \\in \\mathbb{R}^3_+\\) for angular velocity. Chosen \\(f\\) and \\(M\\) input control :  </p> \\[ \\begin{align} M = -k_Re_R -k_\\Omega e_\\Omega + \\Omega \\times J\\Omega - J\\left( \\hat{\\Omega}R^TR_d\\Omega_d-R^TR_d\\dot{\\Omega}_d\\right)  \\end{align} \\] <p>Subtitute Eq. (38) to Eq. (4), </p> \\[ \\require{cancel} \\begin{align} J\\dot{\\Omega} + \\cancel{\\Omega \\times J \\Omega} &amp;= -k_Re_R -k_\\Omega e_\\Omega + \\cancel{\\Omega \\times J \\Omega} - J\\left( \\hat{\\Omega}R^TR_d\\Omega_d-R^TR_d\\dot{\\Omega}_d\\right) \\\\ J\\dot{\\Omega} &amp;= -k_Re_R -k_\\Omega e_\\Omega - J\\left( \\hat{\\Omega}R^TR_d\\Omega_d-R^TR_d\\dot{\\Omega}_d\\right)  \\end{align} \\] <p>Take derivative of time of angular velocity error \\(\\dot{e}_\\Omega\\) to analyze moments for quadcopter \\(M\\). </p> \\[ \\begin{align} \\dot{e}_\\Omega &amp;= \\frac{d}{dt} \\Omega-R^TR_d\\Omega_d \\\\ &amp;= \\dot{\\Omega}-\\dot{R}^TR_d\\Omega_d - R^T\\dot{R}_d\\Omega_d - RR_d^T\\dot{\\Omega}_d  \\\\  &amp;= \\dot{\\Omega}-(R\\hat{\\Omega})^TR_d\\Omega_d - R^T(R_d\\hat{\\Omega}_d)\\Omega_d - RR_d^T\\dot{\\Omega}_d \\\\  &amp;= \\dot{\\Omega}+\\hat{\\Omega}R^TR_d\\Omega_d - RR_d^T\\dot{\\Omega}_d \\\\  \\end{align} \\] <p>Note that \\(\\hat{\\Omega}^T=-\\hat{\\Omega}\\), \\(\\dot{R}=R\\hat{\\Omega}\\) and \\(\\hat{x}x = 0\\). Subtitute Eq. (40) to Eq. (44). It leads to,</p> \\[ \\begin{align} J\\dot{e}_\\Omega &amp;= J\\dot{\\Omega}+J \\left(\\hat{\\Omega}R^TR_d\\Omega_d - RR_d^T\\dot{\\Omega}_d\\right)   \\\\ J\\dot{e}_\\Omega &amp;= -k_Re_R -k_\\Omega e_\\Omega - J\\left( \\hat{\\Omega}R^TR_d\\Omega_d-R^TR_d\\dot{\\Omega}_d\\right) + J(\\hat{\\Omega}R^TR_d\\Omega_d - R^TR_d\\dot{\\Omega}_d)   \\\\ J\\dot{e}_\\Omega &amp;= -k_Re_R -k_\\Omega e_\\Omega \\\\ \\end{align} \\] <p>To find error attitude dynamics of \\(\\Gamma, e_R, e_\\Omega\\). We take time derivative of error configuration \\(\\Gamma\\).</p> \\[ \\Gamma(R, R_d) = \\frac{1}{2}\\mathrm{tr} \\left[I_3-R_d^TR \\right] \\\\ \\] <p>Terms \\(R_d^TR\\) is the function in time.  </p> \\[ \\begin{align} \\frac{d}{dt}(R_d^TR) &amp;= \\dot{R}^T_dR + R_d^T\\dot{R} \\\\ &amp;= \\left(R_d\\hat{\\Omega}_d\\right)^TR + R_d^TR\\hat{\\Omega} \\\\ &amp;= \\hat{\\Omega}_d^TR_d^T R + R_d^TR\\hat{\\Omega} \\\\ &amp;= -\\hat{\\Omega}_dR_d^T R + R_d^TR\\hat{\\Omega} \\end{align} \\] <p>Where \\(\\dot{R} = R\\hat{\\Omega}\\), \\(\\dot{R}_d = R_d\\hat{\\Omega}_d\\), and \\(-\\hat{A}=\\hat{A}^T\\). Simplified Eq. (53) as follows : </p> \\[ \\begin{align} \\frac{d}{dt}(R_d^TR) &amp;= R_d^TR\\left(\\hat{\\Omega}-R^TR_d\\hat{\\Omega}_dR_d^T R\\right)\\\\ &amp;= (R_d^TR)\\hat{e}_\\Omega \\end{align} \\] <p>Then, take the time derivative of \\(\\Gamma\\), </p> \\[ \\begin{align} \\dot{\\Gamma}(R, R_d) &amp;= -\\frac{1}{2}\\left( \\frac{d}{dt}(R_d^TR) \\right)\\\\ &amp;= -\\frac{1}{2}\\left((R_d^TR)\\hat{e}_\\Omega\\right)\\\\ \\end{align} \\] <p>Applied hat map property \\(\\mathrm{tr}\\left[ A\\hat{x}\\right] = -x^T\\left(A-A^T\\right)^\\vee\\) to Eq. 57. Thus, error attitude dynamics of \\(\\Gamma(R_d, R)\\) donated by :</p> \\[ \\begin{align} \\dot{\\Gamma}(R, R_d) &amp;= \\frac{1}{2}{e}_\\Omega^T\\left(R_d^TR-R^TR_d \\right)^\\vee\\\\ &amp;=e_R \\cdot {e}_\\Omega\\\\ \\end{align} \\] <p>Then, we need to find error attitude dynamics of \\(e_R\\). Given rotation error \\(e_R\\), </p> \\[ e_R = \\frac{1}{2}\\left(R_d^T R - R^TR_d\\right)^\\vee  \\] <p>The derivative of \\(e_R\\) as follows : </p> \\[ \\begin{align} \\dot{e}_R &amp;= \\frac{1}{2}\\left(\\frac{d}{dt}\\left(R_d^T R\\right) - \\frac{d}{dt}\\left(R^TR_d\\right)\\right)^\\vee \\\\ \\end{align} \\] <p>Subtitute Eq. (55) to Eq. (60). Note that \\(RR_d^T = \\left(\\frac{d}{dt}\\left(R_d^TR\\right)\\right)^T\\). </p> \\[ \\begin{align} \\dot{e}_R &amp;= \\frac{1}{2}\\left(\\frac{d}{dt}\\left(R_d^T R\\right) - \\left(\\frac{d}{dt}\\left(R_d^TR\\right)\\right)^T\\right)^\\vee \\\\ &amp;= \\frac{1}{2}\\left(R_d^TR\\hat{e}_\\Omega + \\hat{e}_\\Omega R^TR_d\\right)^\\vee \\end{align} \\] <p>Applied \\(\\hat{x}A + A^T \\hat{x} = ([\\mathrm{tr}[A]I-A]x)^\\wedge\\) to Eq. [62], and the hat map \\((\\cdot)^\\wedge\\) dissapear due to \\((\\hat{A})^\\vee = A\\) where \\(A \\in \\mathbb{R}^n\\).</p> \\[ \\begin{align} \\dot{e}_R &amp;= \\frac{1}{2}\\left(\\mathrm{tr}\\left[R^TR_d\\right]I-R^TR_d\\right)e_\\Omega \\\\ &amp;\\equiv C(R^TR)e_\\Omega \\end{align} \\] <p>Assume \\(R^TR_d = \\exp{\\hat{x}} \\in SO(3)\\) by using Rodrigues formuka for \\(x \\in \\mathbb{R}^3\\). Then, \\(\\|C(R^TR)\\|_2 \\leq 1\\) it occurs from eigenvalues of \\(\\left(C(\\exp{\\hat{x}})\\right)^T C(\\exp{\\hat{x}})\\). It eigenvalues is \\(\\cos^2(\\|x\\|), \\frac{1}{2}(1+\\cos(\\|x\\|))\\), and \\(\\frac{1}{2}(1+\\cos(\\|x\\|))\\) [1], which the three of them are less or equal to 1.</p> How are the eigenvalues like that? <p>I\u2019m not entirely sure how they compute the eigenvalues of \\(\\left(C(\\exp{\\hat{x}})\\right)^T C(\\exp{\\hat{x}})\\). So, it still a open question for me.</p>"},{"location":"robotics/nonlinear_control/geom_quadcopter/#position-control","title":"Position Control","text":""},{"location":"robotics/nonlinear_control/geom_quadcopter/#velocity-control","title":"Velocity Control","text":""},{"location":"robotics/nonlinear_control/geom_quadcopter/#references","title":"References","text":"<p>[1] Control of Complex Maneuvers for a Quadrotor UAV using Geometric Methods on SE(3) (v4) </p> <p>[2] Geometric control of mechanical systems </p> <p>[3] Matrix Cookbook </p> <p>[4] Axis\u2013angle Representation </p> <p>[5] Learning with 3D rotations, a hitchhiker\u2019s guide to SO(3) </p> <p>[6] A micro Lie theory for state estimation in robotics </p> <p>[7] Minimum snap trajectory generation and control for quadrotors </p> <p>[8] Control of Complex Maneuvers for a Quadrotor UAV using Geometric Methods on SE(3) (v3) </p>"},{"location":"robotics/nonlinear_control/intro/","title":"Introduction to Nonlinear Systems","text":"<p>Nonlinear control often involves an iterative process in the analysis and design of its systems.</p>"},{"location":"robotics/nonlinear_control/intro/#why-nonlinear-control","title":"Why Nonlinear Control?","text":"<ol> <li> <p>Improvement of Existing Control Systems</p> <ul> <li>Linear Control : It can only work on small changes in the stable point to keep the linear system valid. Large changes in the system make it unstable because the nonlinearity in the system cannot be controlled by a linear model.</li> <li>Nonlinear Control : It can operate on significant changes around the stable point.</li> </ul> </li> <li> <p>Hard Nonlinearities</p> <p>In Linear Control, the system model must be able to determine its linear function. However, in general, control systems have a discontinuous nature. This means that the system will experience a sudden change in state. This is what is called hard nonlinearities.</p> </li> <li> <p>Dealing with Model Uncertainties</p> <p>In the linear model, the system parameters are completely known. However, in fact, in the case of a control system, there is uncertainty in the parameters used in the system. Linear Control uses exact values for its parameters without considering measurement uncertainty, which can result in a decrease in the level of stability or even become unstable.</p> </li> <li> <p>Simplicity</p> <p>System models with nonlinearity are based on physical principles by modeling controlled processes. This is because the system to be controlled exhibits nonlinear characteristics related to the underlying physical principles.</p> </li> </ol>"},{"location":"robotics/nonlinear_control/intro/#nonlinear-system-behaviour","title":"Nonlinear System Behaviour","text":"<p>Nonlinear Control systems can be described in differential equations. If the system operates within small variations and the role of uncertainty is not too large, then the system can be estimated with a linear model.</p>"},{"location":"robotics/nonlinear_control/intro/#nonlinearities","title":"Nonlinearities","text":"<ul> <li>Inherent (Natural): uncertainty of the hardware or motion of the system</li> <li>Intentional (Artificial): uncertainty that is deliberately introduced into the control system</li> </ul>"},{"location":"robotics/nonlinear_control/intro/#linear-systems","title":"Linear Systems","text":"<p>Linear Time Invariant (LTI) :</p> \\[\\dot x = Ax \\\\ \\text{x = vector state} \\\\ \\text{A = coefficent matrix of system}\\] <p>Properties of LTI (Linear Time-Invariant) Systems:</p> <ol> <li> <p>The system has an equilibrium point if the matrix A is nonsingular (determinant value \\(\\neq\\) 0).</p> </li> <li> <p>The equilibrium point is stable if all eigenvalues of matrix A are negative real numbers.</p> </li> <li> <p>The transient response consists of the natural modes of the system. Transient response refers to the system's response to initial changes or disturbances. Natural modes are the patterns of vibration or oscillation that naturally arise from the system.</p> </li> <li> <p>Adding an external input \\(u(t)\\) to the LTI equation results in:</p> </li> </ol> \\[ \\dot x = Ax + Bu \\] <ul> <li>The response of the LTI system satisfies the principle of superposition.</li> <li>If the system input is bounded, then the output of the system is also bounded.</li> <li>If the system input is a sinusoidal wave, then the output will also be a sinusoidal wave.</li> </ul>"},{"location":"robotics/nonlinear_control/intro/#superposition-principle","title":"Superposition Principle","text":"<p>A system can satisfy the superposition principle if the system can exist in multiple states at any given time, and the state of the system at that time is the result of a linear combination of individual states.</p> \\[F(x_1 + x_2) = F(x_1) + F(x_2)\\\\ \\text{and}\\\\ F(ax) = aF(x),\\;a \\;\\text{is scalar}\\]"},{"location":"robotics/nonlinear_control/intro/#an-example-of-nonlinear-system-behaviour","title":"An Example Of Nonlinear System Behaviour","text":"<p>Model for Underwater Vehicle</p> \\[\\dot v + |v|v = u\\\\ \\dot v = u - |v|v\\\\ \\text{u = thrust on the propeller}\\\\ \\text{v = velocity of the R.O.V (remotely-operated underwater vehicle)}\\] <p>The equation \\(|v|v\\) represents the nonlinearity of the system. This equation states that the change in velocity \\(\\dot v\\) depends on the control parameter \\(u\\) and the quadratic term of the R.O.V velocity \\(|v|v\\), also known as the DRAG FORCE \\(F_D \\propto v^2\\).</p> <p>DRAG FORCE is the force that acts in the opposite direction to the relative motion of an object with respect to the surrounding fluid.</p> <p>Below is an experiment using the First-Order Euler Method:</p> \\[ y_{i+1} = y_i + \\Delta t \\cdot f(t_i, y_i);\\quad \\text{given}\\;t_0, \\; y_0 \\\\ y_{i+1} = \\text{output at the next time step}\\;(i+1) \\\\ y_{i} = \\text{output at time}\\;i \\\\ \\Delta t = \\text{time step} \\\\ f(t_i, y_i) = \\text{function determining the rate of change of y w.r.t t} \\] <p>In both graphs above, the system demonstrates that at high velocities, the coefficient of the \"drag effect\" produced by \\(|v|\\) becomes larger, causing the system to reach equilibrium faster compared to when no thrust u is applied (or when \\(t &gt; 5\\;s\\)), which takes longer to reach a velocity of 0.</p> <p>In the second graph, the thrust is increased tenfold. As mentioned earlier, at high velocities, the system will reach equilibrium faster compared to low velocities. However, when the thrust is increased tenfold from the first experiment where thrust = 1 unit step, the equilibrium velocity \\(v_s\\) is not ten times larger than in the first experiment.</p> <p>Nonlinear systems tend to exhibit more complex responses to large input changes and do not scale linearly as in linear systems. Changes in control u can trigger significant nonlinear effects on the system's response.</p> \\[ u=1 =&gt; 0 + |v_s|v_s = 1 =&gt; v_s = 1\\\\ u=10 =&gt; 0 + |v_s|v_s = 10 =&gt; v_s = \\sqrt{10} \\approx 3.16 \\]"},{"location":"robotics/nonlinear_control/intro/#some-common-nonlinear-systems-behaviours","title":"Some Common Nonlinear Systems Behaviours","text":""},{"location":"robotics/nonlinear_control/intro/#multiple-equilibrium-points","title":"Multiple Equilibrium Points","text":"<p>Equilibrium Point is a condition where the system undergoes no change over time.</p> <p>Example : \u200b In a nonlinear system \\(\\dot x = f(x)\\), where \\(f(x)\\) is a nonlinear function.</p> \\[\\dot x = -x + x^2\\] <p>Linearizing \\(\\dot x\\) around \\(\\dot x = 0\\):</p> \\[ 0 = -x + x^2\\\\ \\text{Obtained 2 equilibrium points : }\\\\ \\bar x = 0 \\quad \\text{and} \\quad \\bar x = 1\\] <p>For the linear system (\\(\\dot x = Ax\\)), we can obtain a linear system from the nonlinear system using First Order Taylor Expansion: \u200b \\(\\text{Taylor Expansion : }\\)</p> \\[f(x) = f(\\bar x) + f'(\\bar x) (x-\\bar x)+\\frac {1}{2!}f''(\\bar x)(x-\\bar x)^2 + ...\\] <p>So,</p> \\[f(x) = -x+x^2\\\\ f'(x)=-1+2x\\] <p>If \\(\\bar x = 0\\), then:</p> \\[f(0) = -(0) + 0^2 = 0\\\\ f'(0)=-1+2(0) = -1\\\\ f(x) = f(0) + f'(0) (x-0)\\\\ f(x) = 0 + -1(x-0)\\\\ f(x)=-x\\] <p>Thus obtained:</p> \\[\\dot x =  -x\\] <p>The solution to the above linear equation is:</p> \\[\\dot x = -x\\\\ \\frac{dx}{dt} = -x\\\\ \\frac{1}{x}\\;dx = - dt\\\\ \\int \\frac{1}{x}\\;dx = \\int -1\\;dt$\\\\ \\ln|x|=-t+C\\] <p>If \\(x(0)=x_0\\), then</p> \\[\\ln|x_0|=0+C\\\\ \\ln|x_0|=C\\] <p>Substitute \\(C\\) into the equation \\(\\ln|x|=-t+C\\),</p> \\[\\ln|x|=-t+\\ln|x_0|\\\\ \\ln|x|-\\ln|x_0|=-t\\\\ \\ln \\left|\\frac{x}{x_0}\\right| = -t\\\\ \\frac{x}{x_0} = \\pm e^{-t}\\] <p>so,</p> \\[x(t) = x_0e^{-t}\\] <p>If we directly use the response from the equation \\(\\dot x = -x+x^2\\), then:</p> \\[\\frac {dx}{-x+x^2} = dt\\\\ -\\frac {dx}{x(1-x)}= dt\\\\ \\int \\frac {dx}{x(1-x)} = \\int-1 dt\\\\ \\ln |x| - \\ln|1-x| = -t +C\\\\ \\ln \\left|\\frac{x}{1-x}\\right|=-t+C\\\\ \\frac{x}{1-x} = \\pm e^{-t+C}\\] <p>If \\(x(0) = x_0\\), then</p> \\[\\frac{x_0}{1-x_0} = \\pm e^{C}\\\\ \\ln \\left|\\frac{x_0}{1-x_0}\\right| = C\\] <p>Substitute the value of \\(C\\) into \\(\\frac{x}{1-x} = \\pm e^{-t+C}\\)</p> \\[\\frac{x}{1-x}=e^{-t+\\ln \\left|\\frac{x_0}{1-x_0}\\right|}\\\\ \\frac{x}{1-x}=e^{-t} \\cdot \\left(\\frac{x_0}{1-x_0}\\right)\\\\ x=e^{-t} \\cdot (1-x) \\cdot \\left(\\frac{x_0}{1-x_0}\\right)\\\\ x\\cdot(1-x_0)=e^{-t} \\cdot (1-x) \\cdot x_0\\\\ x\\cdot(1-x_0)=e^{-t}\\cdot x_0 - e^{-t}\\cdot x \\cdot x_0\\\\ x\\left(1-x_0\\right)+e^{-t}\\cdot x\\cdot x_0=e^{-t}x_0\\\\ x\\left(1-x_0+e^{-t}\\cdot x_0\\right)=e^{-t}x_0\\] <p>thus obtained,</p> \\[x(t)=\\frac{x_0e^{-t}}{1-x_0+x_0e^{-t}}\\] <p>In the graph of the linearized system \\(x(t)=x_0e^{-t}\\), regardless of its initial conditions, the system will eventually reach a stable state (\\(x = 0\\)) over time.</p> <p>In the graph of the nonlinear system without linearization \\(x(t)=\\frac{x_0e^{-t}}{1-x_0+x_0e^{-t}}\\), it can be observed that at time step 1, the system with an initial condition \\(&lt; 1\\) will reach the equilibrium point \\(x = 0\\), but for initial conditions \\(&gt; 1\\), the state \\(x\\) will tend towards infinity in a finite time, which is known as a finite escape time.</p> <p>The experiment above concludes that stability in nonlinear systems depends on their initial conditions.</p>"},{"location":"robotics/nonlinear_control/intro/#limit-cycles","title":"Limit Cycles","text":"<p>Limit Cycles are isolated closed trajectories that form periodic and regular motion over time. \"Isolated\" means that the trajectory does not intersect with other trajectories, and \"closed\" means that the trajectory is a closed path.</p> <p>Example:</p> <p>The Van der Pol Oscillator Equation is a second-order ordinary differential equation that models the oscillation of an electrical circuit in a vacuum tube. The Van der Pol equation is a non-conservative model, meaning that the system modeled can gain or lose energy over time. \\(\\(\\ddot x + \\mu (1-x^2) \\dot x + x = 0\\)\\) where: - \\(x\\): initial condition coordinate - \\(\\mu\\): damping strength (non-linearity)</p> <p>Li\u00e9nard Theorem can prove that the Van der Pol equation has Limit Cycles.</p> <p>Li\u00e9nard Equation:</p> \\[\\frac{d^2}{dt^2}x + F(x)\\frac{d}{dt}x+G(x) = 0 \\] <p>Li\u00e9nard Theorem:</p> <ol> <li> <p>\\(F\\) and \\(G\\) are continuous functions and their derivatives are also continuous \\(f,g \\in C^1(\\mathbb R)\\)</p> </li> <li> <p>\\(G\\) is an odd function, i.e., \\(G(-x)=-G(x)\\)</p> </li> <li> <p>\\(G(x) &gt; 0\\), for \\(x &gt; 0\\)</p> </li> <li> <p>\\(F\\) is an even function, i.e., \\(F(-x)=F(x)\\)</p> </li> <li> <p>\\(F(x)=\\int _0^x f(x)\\;dx\\), and</p> <ul> <li>\\(F(x) &lt; 0\\) for \\(0&lt;x&lt;a\\)</li> <li>\\(F(x) &gt; 0\\) for \\(x&gt;a\\)</li> <li>\\(F(0) = F(\\pm a) = 0\\)</li> </ul> </li> </ol> <p>If the Li\u00e9nard Equation satisfies these theorems, then the equation has a Stable Limit Cycle surrounding the origin point. The Van der Pol equation is an example of a Li\u00e9nard Equation.</p> <p>Applying the Li\u00e9nard Theorem to the Van der Pol Oscillator Equation with \\(\\mu &gt; 0\\):</p> <p>Based on the Li\u00e9nard Equation:</p> \\[F(x) = \\mu (1-x^2)\\\\ G(x) = x\\] <ol> <li> <p>\\(F\\) and \\(G\\) belong to the class \\(C^1\\) (continuously differentiable)</p> </li> <li> <p>\\(G(-x)=-x\\) so \\(G(x)\\) is an odd function</p> </li> <li> <p>\\(G(x) &gt; 0\\) if \\(x &gt; 0\\)</p> </li> <li> <p>\\(F(-x) = \\mu (1-(-x)^2) = \\mu (1-x^2) = F(x)\\), so \\(F(x)\\) is an even function</p> </li> <li> <p>\\(F(x) = \\mu \\int _0 ^x (1-x^2)\\;dx = \\mu (x-\\frac{1}{3}x^3)\\),</p> </li> </ol> <p>thus, roots are obtained as \\(x=0, x=-\\sqrt 3, x=\\sqrt 3\\)</p> <ul> <li> <p>\\(F(x) = \\mu (x-\\frac{1}{3}x^3) &lt; 0\\) for \\(0&lt;x&lt;\\sqrt 3\\)</p> </li> <li> <p>\\(F(x) = \\mu (x-\\frac{1}{3}x^3) &gt; 0\\) for \\(x&gt;\\sqrt 3\\)</p> </li> <li> <p>$F(0) = F\\left(-\\sqrt 3\\right) = F\\left(\\sqrt 3\\right) = 0 $</p> </li> </ul> <p>The Van der Pol Equation satisfies all the Li\u00e9nard theorem, so it can be concluded that the Van der Pol equation has a Stable Limit Cycle surrounding the origin.</p> <p>The Van der Pol equation can be written in 2 sets of First-Order ODE (state space system) with \\(y = \\dot x\\), thus</p> \\[\\dot x = y\\\\ \\dot y = \\ddot x = -x + \\mu (1-x^2)y\\] <p>The state space system equation is visualized in the code below.</p> <p>In the animation of the Van der Pol equation, there are limit cycles surrounding the origin point (0, 0) (equilibrium point).</p> <p>When the state has a small value, the damping factor \\(\\mu(1-x^2)\\) increases, causing the oscillation's amplitude to approach the limit cycles. Conversely, when the state has a large value, the damping factor decreases, causing the oscillation's amplitude to decrease until the state is around the limit cycles.</p> <p>This phenomenon occurs when the damping constant \\(\\mu &gt; 0\\). When \\(\\mu = 0\\), the Van der Pol equation becomes the equation of Simple Harmonic Motion \\(\\ddot x + x =0\\) (i.e., sine and cosine functions), and it becomes a linear equation (no limit cycles).</p>"},{"location":"robotics/nonlinear_control/intro/#bifurcations","title":"Bifurcations","text":"<p>Bifurcations are situations where small changes in the parameters of a system result in changes in the behavior (qualitative properties) of the system. Bifurcation values are the values of the system parameters that cause the system to transition from one type of behavior to another, such as from stability to another stability or to instability.</p> <p>Example:</p> <p>The undamped Duffing equation is a second-order ordinary differential equation given by:</p> \\[\\ddot x + \\alpha x + x^3 = 0\\] <p>where \\(\\alpha\\) is a changing parameter.</p> <p>Let \\(\\dot x = y\\), then</p> \\[\\begin{cases} \\dot{x} = y \\\\ \\dot{y} = -\\alpha x - x^3 \\end{cases} \\] <p>The fixed points of this equation are obtained when \\(\\dot{x} = 0\\) and \\(\\dot y=0\\), resulting in</p> \\[\\dot x = y\\\\ y = 0\\\\ \\dot{y} = -\\alpha x - x^3\\\\ -\\alpha x - x^3 = 0\\\\ -x(\\alpha + x^2) = 0\\\\ -x=0\\\\ x_1 = 0\\] <p>Next, we find the fixed points when \\(\\alpha &gt; 0, \\alpha = 0,\\) and \\(\\alpha &lt; 0\\),</p> <p>When \\(\\alpha &gt; 0\\),</p> \\[\\alpha + x^2 = 0\\\\ x^2=-\\alpha\\\\ x_2 = i\\sqrt \\alpha, x_3 = -i\\sqrt \\alpha\\] <p>Since \\(\\alpha + x^2\\) cannot be factored using real numbers, there is only 1 fixed point when \\(\\alpha &gt; 0\\), which is \\(x_1 = 0\\).</p> <p>When \\(\\alpha = 0\\),</p> \\[\\alpha + x^2 = 0\\\\ x^2=0\\\\ x_1 = 0\\] <p>The fixed point obtained is \\(x_1 = 0\\).</p> <p>When \\(\\alpha &lt; 0\\),</p> \\[\\alpha + x^2 = 0\\\\ x^2=-(-\\alpha)\\\\ x_2 = \\sqrt {-\\alpha}, x_3 = -\\sqrt {-\\alpha}\\] <p>Thus, 3 fixed points are obtained,</p> \\[ p_1 (0, 0) \\text{ for all values of} \\; \\alpha\\\\  p_{2,3} \\left( \\pm\\sqrt{-\\alpha}, 0 \\right) \\text{for} \\; \\alpha &lt; 0\\] <p>The Jacobian of 2 set first-order ODE undamped Duffing equation with \\(f(x,y)=(\\dot x, \\dot y)\\) is:</p> \\[ \\mathbb J(f(x,y))=\\begin{bmatrix} \\frac{\\partial \\dot{x}}{\\partial x} &amp; \\frac{\\partial \\dot{y}}{\\partial x} \\\\ \\frac{\\partial \\dot{x}}{\\partial y} &amp; \\frac{\\partial \\dot{y}}{\\partial y} \\end{bmatrix} = \\begin{bmatrix} 0 &amp; 1 \\\\ -a-3x^2 &amp; 0 \\end{bmatrix} \\] \\[ \\mathbb J_{(0,0)}= \\begin{bmatrix} 0 &amp; 1 \\\\ -a &amp; 0 \\end{bmatrix}\\\\ \\text {Tr } \\mathbb J_{(0,0)} = 0\\\\ \\det \\mathbb J_{(0,0)} = a\\\\ \\mathbb J_{\\left(\\sqrt{-\\alpha},0\\right)}= \\begin{bmatrix} 0 &amp; 1 \\\\ 2a &amp; 0 \\end{bmatrix} \\\\ \\text {Tr } \\mathbb J_{\\left(\\sqrt{-\\alpha},0\\right)} = 0\\\\ \\det \\mathbb J_{\\left(\\sqrt{-\\alpha},0\\right)} = -2a\\\\ \\mathbb J_{\\left(-\\sqrt{-\\alpha},0\\right)}= \\begin{bmatrix} 0 &amp; 1 \\\\ 2a &amp; 0 \\end{bmatrix}\\\\ \\text {Tr } \\mathbb J_{\\left(-\\sqrt{-\\alpha},0\\right)} = 0\\\\ \\det \\mathbb J_{\\left(-\\sqrt{-\\alpha},0\\right)} = -2a\\\\ p_1(0,0)\\text{ stable for }a&lt;0\\text{ and unstable for }a&gt;0\\\\ p_{2,3} \\left( \\pm\\sqrt{-\\alpha}, 0 \\right)\\text{ unstable for }a&lt;0\\]"},{"location":"robotics/nonlinear_control/intro/#chaos","title":"Chaos","text":"<p>Chaos, also known as the butterfly effect, is a phenomenon where nonlinear systems are sensitive to initial conditions. Small changes in initial conditions can lead to significant differences in the long-term behavior of the system, or in other words, initial conditions will diverge significantly from the final state.</p> <p>Example:</p> \\[\\ddot x + 0.1\\dot x + x^5 = 6 \\sin t\\] <p>With initial conditions: - For \\(x_1(0) = 2\\) and \\(\\dot{x}_1(0) = 3\\) - For \\(x_2(0) = 2.01\\) and \\(\\dot{x}_2(0) = 3.01\\)</p> <p>In this example, even a small difference in the initial conditions (\\(x_1\\) and \\(x_2\\)) leads to vastly different trajectories over time. This illustrates the sensitivity of chaotic systems to initial conditions, where tiny differences can lead to divergent behaviors.</p> <p>In the graph, it is evident that the plot of the initial condition \\(x_1\\) over time and the initial condition \\(x_2\\) over time exhibit only slight differences in the values of \\(x\\) for \\(t&lt;\\pm21 \\;s\\). However, for \\(t&gt;\\pm 21\\;s\\), the system displays chaotic behavior, and the values of \\(x(t)\\) for both initial conditions diverge significantly.</p> <p>Info</p> <p>Most of this section are my notes from Applied Nonlinear Systems by Jean-Jacques Slotine and Weiping Li .</p>"},{"location":"robotics/nonlinear_control/phase_plane/","title":"Phase Plane Analysis","text":"<p>Info</p> <p>Most of this section are my notes from Applied Nonlinear Systems by Jean-Jacques Slotine and Weiping Li .</p>"},{"location":"robotics/sensor_fusion/kf/","title":"Kalman Filter","text":"<p>The Kalman Filter is used for prediction and estimation of the state of a system. The Kalman filter requires two models: the state model and the observation model.</p> <ul> <li>State Model : A model that represents changes in the state of the system with respect to time.</li> <li>Observation Model : An equation/model that represents data measured, usually by sensors, providing external data about the robot and linking it to the system's state.</li> </ul>"},{"location":"robotics/sensor_fusion/kf/#multivariate-kalman-filter","title":"Multivariate Kalman Filter","text":"<p>The system state is represented as:</p> \\[ \\textbf{x} = \\begin{bmatrix} x \\\\ y \\end{bmatrix} \\] <p>Multivariate Kalman Filter produces outputs in the form of multivariate random variables and a covariance matrix, which is a square matrix representing the uncertainty of the states. The Covariance matrix in the Kalman Filter includes:</p> <ul> <li>\\(P_{n,n}\\): covariance matrix for estimation</li> <li>\\(P_{n+1,n}\\): covariance matrix for prediction</li> <li>\\(R_n\\): covariance matrix representing measurement uncertainty</li> <li>\\(Q\\): covariance matrix for process noise</li> </ul>"},{"location":"robotics/sensor_fusion/kf/#covariance","title":"Covariance","text":"<p>Covariance measures the correlation between two or more random variables.</p> <p></p> <p>Covariance between population \\(X\\) and \\(Y\\), with \\(N\\) data points:</p> \\[ COV(X, Y) = \\frac{1}{N}\\sum_{i=1}^N(x_i - \\mu_x)(y_i-\\mu_y) \\] <p>For a sample:</p> \\[ COV(X, Y) = \\frac{1}{N-1}\\sum_{i=1}^N(x_i - \\mu_x)(y_i-\\mu_y) \\]"},{"location":"robotics/sensor_fusion/kf/#covariance-matrix","title":"Covariance Matrix","text":"<p>The covariance matrix is a square matrix representing the covariance between each element of each state.</p> \\[ \\Sigma = \\begin{bmatrix}  \\sigma_{xx} &amp; \\sigma_{xy} \\\\ \\sigma_{yx} &amp; \\sigma_{yy} \\end{bmatrix} = \\begin{bmatrix}  \\sigma_{x}^2 &amp; \\sigma_{xy} \\\\ \\sigma_{yx} &amp; \\sigma_{y}^2 \\end{bmatrix} = \\begin{bmatrix}  VAR(x)&amp; COV(x,y) \\\\ COV(y,x) &amp; VAR(y) \\end{bmatrix} \\] <p>If \\(x\\) and \\(y\\) are uncorrelated, the off-diagonal elements of the matrix \\(\\Sigma\\) are zero.</p> <p>For a state \\(x\\) of dimension \\(1 \\times k\\):</p> \\[ COV(x) = E((x-\\mu_x)(x-\\mu_x)^T) \\] <p>Proof :</p> \\[ \\begin{align*} COV(x) &amp;= E \\left( \\begin{bmatrix} (x_1 -\\mu_{x_1})^2 &amp; (x_1-\\mu_{x_1})(x_2-\\mu_{x_2}) &amp; \\cdots &amp;(x_1-\\mu_{x_1})(x_k-\\mu_{x_k})\\\\ (x_2-\\mu_{x_2})(x_1 -\\mu_{x1}) &amp; (x_2-\\mu_{x_2})^2 &amp; \\cdots &amp;(x_2-\\mu_{x_1})(x_k-\\mu_{x_k})\\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ (x_k-\\mu_{x_k})(x_1 -\\mu_{x1}) &amp; (x_k-\\mu_{x_k})(x_2-\\mu_{x_2}) &amp; \\cdots &amp;(x_k-\\mu_{x_k})^2\\\\ \\end{bmatrix} \\right)\\\\ &amp;= E \\left( \\begin{bmatrix} (x_1 -\\mu_{x_1})\\\\ (x_2-\\mu_{x_2})\\\\ \\vdots \\\\ (x_k-\\mu_{x_k}) \\end{bmatrix}  \\begin{bmatrix}(x_1 -\\mu_{x_1})&amp;(x_2-\\mu_{x_2})&amp;\\cdots &amp; (x_k-\\mu_{x_k}) \\end{bmatrix} \\right)\\\\ &amp; = E((x_{1:k}-\\mu_{x_{i:k}})(x_{1:k}-\\mu_{x_{i:k}})^T) \\end{align*} \\] <p>Note :</p> <p>\\(E(v)\\) is the expectation or mean of the random variable.</p>"},{"location":"robotics/sensor_fusion/kf/#covariance-matrix-properties","title":"Covariance Matrix Properties","text":"\\[ \\begin{align} \\Sigma_{ii} = \\sigma_{ii}^2\\\\ tr(\\Sigma) = \\sum _{i=1}^n \\Sigma_{ii}\\geq 0\\\\ \\Sigma = \\Sigma^T\\\\ \\end{align} \\]"},{"location":"robotics/sensor_fusion/kf/#multivariate-gaussian-distribution","title":"Multivariate Gaussian Distribution","text":"\\[ p(x|\\mu, \\Sigma) = \\frac{1}{\\sqrt{(2\\pi)|\\Sigma|}}exp\\left (-\\frac{1}{2}(x-\\mu)^T \\Sigma^{-1}(x-\\mu)\\right ) \\]"},{"location":"robotics/sensor_fusion/kf/#state-equation","title":"State Equation","text":"<p>State Equation Used to make predictions based on existing estimates.</p> <p>\\(\\hat{x}_{n+1,n} = F\\hat{x}_{n,n} + G\\hat{u}_{n,n} +w_n\\)</p> <ul> <li>\\(\\hat{x}_{n+1,n}\\) : predicted state at \\(n+1\\)</li> <li>\\(\\hat{x}_{n,n}\\) : predicted state at \\(n\\)</li> <li>\\(u_n\\) : control input measured into the system</li> <li>\\(w_n\\) : noise, unmeasured input (called process noise)</li> <li>\\(F\\) : transition matrix </li> <li>\\(G\\) : control matrix (mapping the effect of \\(u_n\\) to the state variables)</li> </ul>"},{"location":"robotics/sensor_fusion/kf/#covariance-equation","title":"Covariance Equation","text":"<p>Measures the uncertainty of predictions made by the State Equation</p> <p>\\(P_{n+1,n} = FP_{n,n}F^T + Q\\)</p> <p>Proof :</p> <p>Using \\(COV(x) = E((x_{1:k}-\\mu_{x_{i:k}})(x_{1:k}-\\mu_{x_{i:k}})^T)\\), then \\(P_{n,n} = E((\\hat{x}_{n,n}-\\mu_{\\hat{x}_{n,n}})(\\hat{x}_{n,n}-\\mu_{\\hat{x}_{n,n}})^T)\\)</p> <p>From the state equation, \\(P_{n+1,n}\\) is derived as:</p> \\[ \\begin{align} P_{n+1,n} &amp;= E((\\hat{x}_{n+1,n}-\\mu_{\\hat{x}_{n+1,n}})(\\hat{x}_{n+1,n}-\\mu_{\\hat{x}_{+1,n}})^T)\\\\ &amp;= E \\left ( (F\\hat{x}_{n,n} + G\\hat{u}_{n,n} - F\\hat{\\mu_x}_{n,n} + G\\hat{u}_{n,n}) (F\\hat{x}_{n,n} + G\\hat{u}_{n,n} - F\\hat{\\mu_x}_{n,n} + G\\hat{u}_{n,n})^T \\right )\\\\ &amp;=E \\left(F(\\hat{x}_{n,n} - \\mu_{x_{n,n}}) (F(\\hat{x}_{n,n} - \\mu_{x_{n,n}}))^T\\right)\\\\ &amp;=E \\left(F(\\hat{x}_{n,n} - \\mu_{x_{n,n}}) (\\hat{x}_{n,n} - \\mu_{x_{n,n}})^T F^T\\right)\\\\ &amp;=FE \\left[(\\hat{x}_{n,n} - \\mu_{x_{n,n}}) (\\hat{x}_{n,n} - \\mu_{x_{n,n}})^T\\right]F^T\\\\ \\end{align} \\] <p>Thus, </p> \\[ \\begin{align} P_{n+1,n} &amp;= FP_{n,n}F^T \\end{align} \\]"},{"location":"robotics/sensor_fusion/kf/#observation-model","title":"Observation Model","text":"<p>\\(z_n = Hx_n+v_n\\)</p> <ul> <li>\\(z_n\\) : observation vector</li> <li>\\(H\\) : observation matrix</li> <li>\\(x_n\\) : true state</li> <li>\\(v_n\\) : random noise (called observation noise)</li> </ul> <p>For example, in the case of an ultrasonic distance sensor, where the system state is the distance \\(x_n\\) and the sensor output is the measured ToF \\(z_n\\)::</p> <p>\\(z_n = [\\frac{2}{c}]x_n + v_n\\)</p> <p>Where \\(c\\) is the speed of sound.</p>"},{"location":"robotics/sensor_fusion/kf/#observation-uncertainty","title":"Observation Uncertainty","text":"<p>\\(R_n = E(v_nv_n^T)\\)</p> <ul> <li>\\(R_n\\): covariance matrix for observation </li> <li>\\(v_n\\): observation error</li> </ul>"},{"location":"robotics/sensor_fusion/kf/#process-uncertainty","title":"Process Uncertainty","text":"<p>\\(Q_n = E(w_nw_n^T)\\)</p> <ul> <li>\\(Q_n\\): covariance matrix for process noise </li> <li>\\(w_n\\): process noise</li> </ul>"},{"location":"robotics/sensor_fusion/kf/#summary","title":"Summary","text":""},{"location":"robotics/sensor_fusion/kf/#kalman-gain","title":"Kalman Gain","text":"<p>Kalman Gain determines the weighting for the measurement model. It defines the influence of the measurement model on state estimation:</p> \\[ KG = \\frac{error_{estimate}}{error_{estimate} + error_{measurement}} \\] <ul> <li>If \\(error_{estimate} &gt; error_{measurement}\\), then \\(KG \\rightarrow 1\\) </li> <li>If \\(error_{estimate} &lt; error_{measurement}\\), then \\(KG \\rightarrow 0\\)</li> </ul> \\[ estimate_t = estimate_{t-1} + KG(measurement_t-estimate_{t-1}) \\]"},{"location":"robotics/sensor_fusion/kf/#error-on-estimation","title":"Error on Estimation","text":"\\[ E_{estimate_t} = [1-KG]E_{estimate_{t-1}} \\] <ul> <li>If \\(KG\\rightarrow1\\), the error on the estimation is large, resulting in a smaller \\(E_{estimate}\\). </li> <li>If \\(KG\\rightarrow0\\), the error on the estimation is small, maintaining the estimation error from time \\(t-1\\). Thus,</li> <li>\\(E_{estimate_t} &lt; E_{estimate_{t-1}}\\) </li> </ul> <p>Note: As the estimation variance decreases, it approaches the true value.</p>"},{"location":"robotics/sensor_fusion/kf/#references","title":"References","text":"<ul> <li>kalmanfilter.com</li> <li>Michel van Biezen - Kalman Filter Playlist</li> </ul>"},{"location":"robotics/slam/icp/","title":"Point to Point Iterative Closest Point","text":"<p>Given two point clouds, \\(P\\) and \\(Q\\):</p> \\[ P = \\left \\{ p_1, p_2, p_3, ..., p_n \\right \\}\\\\ Q = \\left \\{ q_1, q_2,q_3, ..., q_n \\right \\}\\\\ \\] <p>The goal is to find the optimal transformation \\((R, t)\\) that aligns the source point cloud \\(P\\) to the reference point cloud \\(Q\\) by minimizing the following error function :</p> \\[ E = \\underset{R,t} {\\mathrm{argmin}} \\sum_{i=1}^n \\left||Rp_i + t -q_i \\right||^2 \\] <p>where \\(E\\) is the loss function, \\(P\\) is the set of source points, and \\(Q\\) is the set of reference points. The objective of ICP is to determine the best transformation \\((R, t)\\) that aligns point cloud \\(P\\) to point cloud \\(Q\\).</p>"},{"location":"robotics/slam/icp/#closed-form-solution","title":"Closed-form Solution","text":"<p>Point to point ICP can solved by using Singular Value Decomposition. First, the centroids (center of mass) of point clouds \\(P\\) and \\(Q\\) are defined as:</p> \\[ \\mu_p = \\frac{1}{N_Q} \\sum_{n=1}^{N_Q} q_i\\\\ \\mu_q = \\frac{1}{N_P} \\sum_{n=1}^{N_P} p_i \\] <p>Let \\(Q'\\) and \\(P'\\) be the sets of points in \\(Q\\) and \\(P\\), respectively, with their centroids subtracted. This step removes any translation effects by shifting both point clouds to a common origin:</p> \\[ Q' = {Q_i-\\mu_q}=\\{Q'_i\\}\\\\ P' = {P_i-\\mu_p}=\\{P'_i\\}\\\\ \\] <p>Define the cross-covariance matrix \\(W\\) as follows:</p> \\[ W = \\sum_{i=1}^N q'_ip'^T_i = Q'^TP'\\\\ W = \\begin{bmatrix} cov(p_x,q_x) &amp; cov(p_x,q_y)\\\\ cov(p_y,q_x) &amp; cov(p_y,q_y) \\end{bmatrix} \\] <p>The cross-covariance matrix \\(W\\) provides information about how changes in coordinates in the \\(p\\) points correlate with changes in the \\(q\\) points. An ideal cross-covariance matrix would be an identity matrix, indicating no correlation between the x- and y-axes.</p>"},{"location":"robotics/slam/icp/#translation","title":"Translation","text":"<p>The translation vector \\(t\\) aligns the centroids of \\(P\\) and \\(Q\\) and can be derived by minimizing \\(E\\) with respect to \\(t\\):</p> \\[ \\frac{\\partial E}{\\partial t} = 2\\sum_{i=1}^n (q_i - Rp_i-t) = 0\\\\ t = q_i-Rp_i \\]"},{"location":"robotics/slam/icp/#rotation","title":"Rotation","text":"<p>The optimal rotation matrix \\(R\\) can be derived by focusing on minimizing the rotational alignment error when \\(t = 0\\). This minimization yields:</p> \\[ R= \\underset{R\\in SO(n)}{argmin}\\sum_{i=1}^n\\left\\|Rp_i - q_i \\right\\|^2 \\] <p>Expanding this norm gives:</p> \\[ \\begin{align*} \\left\\|Rp_i - q_i \\right\\|^2 &amp;= (Rp_i - q_i)^T(Rp_i - q_i) \\\\ &amp;= p_i^T R^T R p_i - q_i^T R p_i - p_i^T R^T q_i - q_i^T q_i \\\\ &amp;= p_i^T p_i - q_i^T R p_i - p_i^T R^T q_i - q_i^T q_i \\end{align*} \\] <p>Where \\(p_i^TR^Tq_i = \\left ( p_i^TR^Tq_i\\right)^T= q_i^TRp_i\\), then</p> \\[ \\begin{align*} \\underset{R\\in SO(d)}{\\mathrm{argmin}}\\sum_{i=1}^n \\left\\|Rp_i - q_i \\right\\|^2 &amp;=  \\underset{R\\in SO(d)}{\\mathrm{argmin}} \\sum _{i=n}^n (p_i^T p_i - 2q_i^T R p_i - q_i^T q_i) \\end{align*} \\] <p>Since \\(p_i^T p_i\\) and \\(q_i^T q_i\\) do not depend on \\(R\\), we simplify the objective to:</p> \\[ \\underset{R\\in SO(d)}{\\mathrm{argmax}}\\sum_{i=1}^nq_i^T R p_i \\] <p>Using the matrix trace property \\(tr(AB)=tr(BA)\\), and \\(PQ^T=W\\), we can rewrite the objective as:</p> \\[ \\begin{align*} \\sum_{i=1}^nq_i^T R p_i &amp;= \\text{tr}(Q^TRP)\\\\ &amp;= \\text{tr}(RPQ^T) \\\\ &amp;=\\text{tr}(RW) \\end{align*} \\] <p>Where \\(W\\) is a cross-covariance matrix, then perform the Singular Value Decomposition (SVD) of \\(W\\):</p> <p>$$ SVD(W) = U \\Sigma V^T $$ Subtitute \\(U \\Sigma V^T\\) to \\(tr(RW)\\)</p> \\[ \\text{tr}(RU\\Sigma V^T) = \\text{tr}(\\Sigma V^TRU) \\] <p>Define an orthogonal matrix \\(M =V^TRU\\). Therefore,</p> \\[ \\text{tr}(\\Sigma V^TRU) = \\text{tr}(\\Sigma M) \\] <p>By applying the Cauchy-Schwarz inequality :</p> \\[ \\text{tr}(\\Sigma M)= \\sum_{i=1}^r\\sigma_im_{ii}\\\\ \\left(\\sum_{i=1}^r\\sigma_im_{ii}\\right)^2 \\leq \\sum_{i=1}^r\\sigma_i^2  \\sum_{i=1}^r m_{ii}^2\\\\ \\sum_{i=1}^r\\sigma_im_{ii} \\leq \\sqrt{\\sum_{i=1}^r\\sigma_i^2  \\sum_{i=1}^r m_{ii}^2}\\\\ \\sum_{i=1}^r\\sigma_im_{ii} \\leq \\sum_{i=1}^r\\sigma_i^2 \\] <p>Since \\(M\\) is an orthogonal matrix, \\(m_{ii}^2 = |m_{ii}|\\leq1\\). Therefore, to obtain the maximum value, \\(m_{ii}\\) bernilai 1. should be 1. As explained earlier \\(M\\) is an orthogonal matrix, so \\(m_{ii}\\) equals 1 if \\(M = I\\)\u200b</p> \\[ M = I = V^TRU\\\\ R^T = V^TU\\\\ R = UV^T \\]"},{"location":"robotics/slam/icp/#references","title":"References","text":"<ul> <li>Sorkine-Hornung, O., &amp; Rabinovich, M. (2017). Least-squares rigid motion using svd. Computing, 1(1), 1-5. https://igl.ethz.ch/projects/ARAP/svd_rot.pdf</li> <li>Arun, K. S., Huang, T. S., &amp; Blostein, S. D. (1987). Least-Squares fitting of two 3-D point sets. IEEE Transactions on Pattern Analysis and Machine Intelligence, PAMI-9(5), 698\u2013700. https://doi.org/10.1109/tpami.1987.4767965</li> </ul>"},{"location":"robotics/slam/plicp/","title":"Point to Line Iterative Closest Point","text":"<p>Iterative Closest Point aims to align two point clouds \\(P\\) and \\(Q\\) by finding a rigid-body transformation \\((R, t)\\) applied to point cloud \\(P\\) and iteratively minimizes the error metric. Point to Point distance of vanilla ICP [1] uses Euclidean distance between correspondences points. Point to Line Iterative Closest Point (PLICP) is a variant of ICP with a difference in error metric. PLICP computes error metric by projecting distances of correspondence points to the normal vector of the target point cloud [2]. PLICP can be solved by an optimization process such as Gauss-Newton and Levenberg-Marquardt methods [3, 4]. </p>"},{"location":"robotics/slam/plicp/#error-metric","title":"Error Metric","text":"<p>The error metric of PLICP is expressed by:  </p> \\[ \\begin{align} E(\\mathbf{x}) = \\sum_i\\left[ (R(\\mathbf{x}_\\theta)p_i + t(\\mathbf{x}_x, \\mathbf{x}_y)-q_p)\\cdot n_{q,i}\\right]^2, \\text{for } R \\in SO(2), t \\in \\mathbb{R}^2 \\end{align} \\] <p>where :</p> <ul> <li>State \\(\\mathbf{x}(x, y, \\theta)\\) : Coordinates and rotation angle</li> <li>Rotation matrix (\\(R\\)) : Rotation matrix obtained from correspondences</li> <li>Translation vector (\\(\\mathbf{t}\\)) : Translation vector obtained from correspondences</li> <li>Source point cloud (\\(p\\)) : Source point cloud</li> <li>Target point cloud (\\(q\\)) : Target point cloud</li> <li>Normals vector of target point cloud (\\(n_q\\)) : Normals vector of the target point cloud</li> </ul> <p>Left terms in the bracket of Eq. (1) describe the distance of correspondence point  in  the transformed source point to target  point. The right terms describes projecting the distance to normals of target point.</p>"},{"location":"robotics/slam/plicp/#solution-by-optimization","title":"Solution by Optimization","text":"<p>We can minimize \\(E(\\mathbf{x})\\) by using optimization process. Minimizing \\(E(\\mathbf{x})\\) needs to compute Gradient and Hessian matrix of \\(E(\\mathbf{x})\\) at any parameters [4]. Given current initial guess \\(\\breve{\\mathbf{x}}\\) and perturbation of \\(\\mathbf{x}\\) donated by \\(\\Delta\\mathbf{x}\\).</p> <p>Let \\(e_{i}(\\mathbf{x})=\\left(\\boldsymbol{R}(\\mathbf{x}_{\\theta})p_{i}+t( \\mathbf{x}_{x},\\mathbf{x}_{y})-q_{i}\\right)\\cdot n_{q,i}\\), </p> \\[ \\begin{align} E(\\mathbf{x})=\\sum_{i}\\underbrace{e_{i}(\\mathbf{x})^{T}e_{i}( \\mathbf{x})}_{E_{i}} \\end{align} \\] <p>Thus, optimal parameters \\(\\mathbf{x}^{*}\\) expressed by :</p> \\[ \\begin{align} \\mathbf{x}^{*}=\\underset{\\mathbf{x}}{\\operatorname{argmin}}E(\\mathbf{x}) \\end{align} \\] <p>Eq. (2) can be approximated by using first-order Taylor expansion current initial guess \\(\\breve{\\mathbf{x}}\\) [5, 6]. </p> \\[ \\begin{align} e_{i}(\\breve{\\mathbf{x}}+\\Delta\\mathbf{x}) &amp;= e_{i}(\\breve{\\mathbf{x}}) + \\nabla e_{i}(\\breve{\\mathbf{x}})\\cdot \\Delta\\mathbf{x} \\\\  &amp;\\simeq e_{i}(\\breve{\\mathbf{x}}) + \\mathbf{J}_{i}\\Delta\\mathbf{x}  \\end{align} \\] <p>Substitute Eq. (5) to \\(e_i\\) in Eq. (2),  </p> \\[ \\begin{align} E_i(\\breve{\\mathbf{x}} + \\Delta\\mathbf{x}) &amp;\\simeq (e_i(\\breve{\\mathbf{x}}) + \\mathbf{J}_i \\Delta\\mathbf{x}^T)(e_i(\\breve{\\mathbf{x}}) + \\mathbf{J}_i \\Delta\\mathbf{x})\\\\ &amp;= \\underbrace{e_i^T e_i}_{\\mathbf{c}_i} + 2 \\underbrace{e_i^T \\mathbf{J}_j}_{\\mathbf{b}_i} \\Delta\\mathbf{x} + \\Delta\\mathbf{x}^T \\underbrace{\\mathbf{J}_i^T \\mathbf{J}_j}_{\\mathbf{H}_i} \\Delta\\mathbf{x} \\end{align} \\] <p>Rewrite error metric in Eq. (2) with Eq. (7) by using the same method in [13].</p> \\[ \\begin{align} \\mathbf{c} &amp;= \\sum_i \\mathbf{c}_i\\\\ \\mathbf{b} &amp;= \\sum_i \\mathbf{b}_i\\\\ \\mathbf{H} &amp;= \\sum_i \\mathbf{H}_i\\\\ E(\\breve{\\mathbf{x}} + \\Delta\\mathbf{x}) &amp;= \\mathbf{c} + 2\\mathbf{b}\\Delta\\mathbf{x} + \\Delta\\mathbf{x}^T\\mathbf{H} \\end{align} \\] <p>Thus, we can obtain \\(\\Delta\\mathbf{x}^*\\) by solving linear system  </p> \\[ \\begin{align} \\Delta\\mathbf{x}^* &amp;= -\\mathbf{H}^{-1}\\mathbf{b}\\\\ &amp;=-(\\mathbf{J}^T\\mathbf{J})^{-1}\\mathbf{b} \\end{align} \\] <p>Optimal rigid-body transformation \\(\\mathbf{x}^*\\) can be obtained by adding an initial guess \\(\\breve{\\mathbf{x}}\\) to computed perturbation \\(\\Delta\\mathbf{x}^*\\).</p> \\[ \\begin{align} \\mathbf{x}^* = \\breve{\\mathbf{x}} + \\Delta\\mathbf{x}^* \\end{align} \\] <p>In Eq. (13), \\(\\mathbf{J}\\) is a Jacobian of \\(e_i(\\mathbf{x})\\) and \\(\\mathbf{I}\\) is an identity matrix. Jacobian of \\(e_i(\\mathbf{x})\\) expressed by taking partial derivatives of \\(e_i(\\mathbf{x})\\) w.r.t parameters \\(\\mathbf{x}\\):</p> \\[ \\begin{align} \\mathbf{J} &amp;= \\left[ \\frac{\\partial e}{\\partial x} \\quad \\frac{\\partial e}{\\partial y} \\quad \\frac{\\partial e}{\\partial\\theta} \\right]\\\\ \\mathbf{J} &amp;= \\left[ n_{q,x} \\quad n_{q,y} \\quad n_{q,x}\\left(-q_x \\sin \\theta - q_y \\cos \\theta + n_{q,y}\\left(q_x \\cos \\theta - q_y \\sin \\theta\\right)\\right) \\right] \\end{align} \\]"},{"location":"robotics/slam/plicp/#references","title":"References","text":"<p>[1] Method for registration of 3-D shapes </p> <p>[2] Object modeling by registration of multiple range images </p> <p>[3] Numerical  Recipes  in C </p> <p>[4] ICP </p> <p>[5] Robust registration of 2D and 3D point sets </p> <p>[6] SLAM using ICP and graph optimization  considering  physical properties  of environment </p>"},{"location":"robotics/slam/pose_graph/","title":"Pose Graph SLAM","text":"<p>Given error function \\(e_{ij}(x)\\), which represent the error from node-\\(i\\) to node-\\(j\\),</p> \\[ \\begin{align} e_{ij}(x) = z_{ij}-\\hat{z}(x_i, x_j) \\end{align} \\] <p>Where \\(z\\) is the value from the measurement model (such as PLICP or ICP), \\(\\hat{z}\\) is the predicted value from the math model, and \\(x\\) represents the states. Assume the uncertainty on the sensor follows a Gaussian distribution.</p> \\[ \\begin{align} p(x)=\\frac{1}{\\sqrt{2\\pi^n|\\Sigma|}}\\exp\\left(-\\frac{1}{2}(x-\\mu)^T\\Omega(x-\\mu)\\right)\\sim \\mathcal{N}(\\mu, \\Sigma) \\end{align} \\] <p>\\(\\Omega = \\Sigma^{-1}\\) is the information matrix, so the error follows a multivariate normal distribution with mean \\(\\mu = \\hat{z}\\) and variance \\(\\Sigma\\). By applying the log-likelihood to \\(p(x)\\), the optimal state \\(x^*\\) can be obtained through Maximum Likelihood Estimation. The optimal \\(x\\) occurs when \\(\\text{ln}(p(x))\\) reaches its maximum value.</p> \\[ \\begin{align} x^*=\\text{argmax }p(x) = \\underset{x}{\\text{argmin }}e_{ij}^T\\Omega_{ij}e_{ij} \\end{align} \\] <p>Due to the cumulative error in the trajectory, which is not just an error at a single pose but rather a possibility that the error occurs at multiple poses, the error function is the sum of the errors at each pose.</p> \\[ \\begin{align} F(x) = e_{ij}^T\\Omega_ie_{ij}\\\\ x^*=\\underset{x}{\\text{argmin }} \\sum_{i,j}F(x_{ij}) \\end{align} \\] <p>The equation does not have a definitive solution due to the presence of a rotation matrix, which indicates a nonlinear equation. The problem can be solved using optimization and linearized using Taylor expansion.</p> \\[ \\begin{align} F_{ij}(x+\\Delta x)=e_{ij}(x+\\Delta x)^T\\Omega_{ij} e_{ij}(x+\\Delta x)^T \\end{align} \\] <p>By using the First-Order Taylor Expansion,</p> \\[ \\begin{align} e_{ij}(x+\\Delta x) = e_{ij}+J_{ij}\\Delta x \\end{align} \\] <p>Substitute into \\(F_{ij}(x + \\Delta x)\\),</p> \\[ \\begin{align} F_{ij}(x+\\Delta x) &amp;= (e_{ij}+J_{ij}\\Delta x)^T \\Omega_{ij}(e_{ij}+J_{ij}\\Delta x)\\\\ &amp;= (e_{ij}^T+(J_{ij}\\Delta x)^T)+(\\Omega_{ij}e_{ij}+\\Omega_{ij}J_{ij}\\Delta x)(\\\\ &amp;= (e_{ij}^T+\\Delta x^TJ_{ij}^T)(\\Omega_{ij}e_{ij}+\\Omega_{ij}J_{ij}\\Delta x)\\\\ &amp;= e_{ij}^T\\Omega_{ij}e_{ij}+e_{ij}^T\\Omega_{ij}J_{ij}\\Delta x + \\Delta{x}^TJ_{ij}^T\\Omega_{ij}e_{ij}+ \\Delta{x}^TJ_{ij}^T\\Omega_{ij}J_{ij}\\Delta x\\\\ &amp;= e_{ij}^T\\Omega_{ij}e_{ij}+e_{ij}^T\\Omega_{ij}J_{ij}\\Delta x + \\left(\\Delta{x}^TJ_{ij}^T\\Omega_{ij}e_{ij}\\right)^T+ \\Delta{x}^TJ_{ij}^T\\Omega_{ij}J_{ij}\\Delta x\\\\ &amp;= e_{ij}^T\\Omega_{ij}e_{ij}+e_{ij}^T\\Omega_{ij}J_{ij}\\Delta x + e_{ij}^T\\Omega_{ij}^TJ_{ij}\\Delta x+ \\Delta{x}^TJ_{ij}^T\\Omega_{ij}J_{ij}\\Delta x\\\\ \\end{align} \\] <p>Since \\(\\Omega_{ij}\\) is a symmetric matrix, it follows that \\(\\Omega_{ij} = \\Omega_{ij}^T\\).</p> \\[ \\begin{align} F_{ij}(x+\\Delta x) =  \\underbrace{e_{ij}^T\\Omega_{ij}e_{ij}}_{c}+ 2\\underbrace{e_{ij}^T\\Omega_{ij}J_{ij}}_{b}\\Delta x + \\Delta{x}^T\\underbrace{J_{ij}^T\\Omega_{ij}J_{ij}}_{H}\\Delta x \\end{align} \\] <p>The first derivative of \\(F_{ij}(x + \\Delta x)\\) can be obtained,</p> \\[ \\begin{align} \\frac{\\partial{F_{ij}(x+\\Delta x)}}{\\partial\\Delta x} &amp;\\approx 2b+2H\\Delta x = 0\\\\ \\Delta x &amp;= -H^{-1}b\\\\ x &amp;\\leftarrow x+\\Delta x \\end{align} \\] <p>\\(\\hat{z}_{ij}\\) is calculated using inverse pose composition,</p> \\[ \\begin{align} T_i^{-1} &amp;= \\begin{bmatrix} R_i^T &amp; -R_i^Tt_i\\\\ 0 &amp; 1 \\end{bmatrix}\\\\ T_j &amp;= \\begin{bmatrix} R_j &amp; t_j\\\\ 0 &amp; 1 \\end{bmatrix}\\\\ \\hat{z}_{ij} &amp;= T_i^{-1}\\cdot T_j\\\\ \\end{align} \\] <p>Where \\(T \\in SE(n)\\) and \\(R \\in SO(n)\\).</p> \\[ \\begin{align} \\hat{z}_{ij}=  \\begin{bmatrix} R_i^TR_j &amp; R_i^T(t_j-t_i)\\\\ 0 &amp; 1 \\end{bmatrix} \\triangleq  \\begin{bmatrix} R_i^T(t_j-t_i)\\\\ \\theta_j - \\theta_i \\end{bmatrix} =  \\begin{bmatrix} \\Delta t\\\\ \\Delta \\theta \\end{bmatrix} \\end{align} \\] <p>\\(\\triangleq\\) represented in vector space.  The value of \\(e_{ij}\\) is obtained in the same way as \\(\\hat{z}_{ij}\\). Therefore, \\(e_{ij} = z_{ij}^{-1} T_i^{-1} T_j\\).</p> \\[ \\begin{align} e_{ij} \\triangleq \\begin{bmatrix} R_{ij}^T(R_i^T(t_j-t_i)-t_{ij})\\\\ \\theta_j - \\theta_i - \\theta_{ij}  \\end{bmatrix} \\end{align} \\] <p>Determine the partial derivatives of \\(e_{ij}\\) with respect to \\(x_i\\) and \\(x_j\\),</p> \\[ \\begin{align} x_i &amp;= \\begin{bmatrix} t_i \\\\ \\theta_i \\end{bmatrix} \\\\ x_j &amp;= \\begin{bmatrix} t_j \\\\ \\theta_j \\end{bmatrix} \\\\ \\frac{\\partial e_{ij}}{\\partial x_i} &amp;=  \\begin{bmatrix} \\frac{\\partial \\Delta t}{\\partial t_i} &amp; \\frac{\\partial \\Delta t}{\\partial \\theta_i} \\\\ \\frac{\\partial \\Delta \\theta}{\\partial t_i} &amp; \\frac{\\partial \\Delta \\theta}{\\partial \\theta_i} \\end{bmatrix} \\\\ \\frac{\\partial e_{ij}}{\\partial x_j} &amp;=  \\begin{bmatrix} \\frac{\\partial \\Delta t}{\\partial t_j} &amp; \\frac{\\partial \\Delta t}{\\partial \\theta_j} \\\\ \\frac{\\partial \\Delta \\theta}{\\partial t_j} &amp; \\frac{\\partial \\Delta \\theta}{\\partial \\theta_j} \\end{bmatrix} \\\\ \\frac{\\partial e_{ij}}{\\partial x_i} &amp;=  \\begin{bmatrix} -R_{ij}^T R_i^T &amp; R_{ij}^T \\frac{\\partial R_i^T}{\\partial \\theta_i}(t_j - t_i) \\\\ 0 &amp; -1 \\end{bmatrix} \\\\ \\frac{\\partial e_{ij}}{\\partial x_j} &amp;=  \\begin{bmatrix} R_{ij}^T R_i^T &amp; 0 \\\\ 0 &amp; 1 \\end{bmatrix} \\end{align} \\] <p>The Jacobian matrix \\(J_{ij}\\) contains only the value \\(\\frac{\\partial e_{ij}}{\\partial x_i}\\) in the \\(i\\)-th row, \\(\\frac{\\partial e_{ij}}{\\partial x_j}\\) in the \\(j\\)-th row, and the other elements are 0.</p> \\[ \\begin{align} J_{ij} &amp;= \\begin{bmatrix} 0&amp;0&amp;0&amp;...&amp;\\frac{\\partial e_{ij}}{\\partial x_i}&amp;...&amp;\\frac{\\partial e_{ij}}{\\partial x_j}&amp;...&amp;0&amp;0&amp;0 \\end{bmatrix}\\\\ \\nabla_{ij} &amp;=J_{ij}^T\\Omega_{ij}e_{ij}\\\\ H_{ij} &amp;=J_{ij}^T\\Omega_{ij}J_{ij}\\\\ \\nabla &amp;=\\sum_{i,j}J_{ij}^T\\Omega_{ij}e_{ij}\\\\ H &amp;=\\sum_{i,j}J_{ij}^T\\Omega_{ij}J_{ij} \\end{align} \\] <p>After \\(\\nabla\\) and \\(H\\) are obtained, the Non-Linear Least Squares problem can be solved by iterating the optimization process using Gauss-Newton or Levenberg-Marquardt until \\(\\Delta F(x) &lt; \\text{tolerance}\\).</p> \\[ \\begin{align} \\text{(GN) } \\Delta x &amp;= -H^{-1}\\nabla\\\\ \\text{(LM) } \\Delta x &amp;= -(H+\\lambda \\text{ diag}(H))^{-1}\\nabla\\\\ x&amp;\\leftarrow x+\\Delta x \\end{align} \\]"},{"location":"robotics/slam/pose_graph/#references","title":"References","text":"<ul> <li> <p>[SLAM]Errors and Jacobian Derivations for SLAM Part 1</p> </li> <li> <p>A Technical Walkthrough of the SLAM Back-end</p> </li> <li> <p>Graph-based SLAM using Pose Graphs (Cyrill Stachniss)</p> </li> </ul>"},{"location":"robotics/sys_iden/wynda/","title":"WyNDA","text":"<p>Wide-Array of Nonlinear Dynamics Approximation (WyNDA) is a method to discovering mathematical models of dynamical system given datas.  There are many existing approaches related to this method such as SINDy, PINN, PySR, etc. Most of them rely on optimization or Machine Learning where they need dataset to discovered the govering equations [1].</p> <p>On other hand, WyNDA provides an on-line discovering mathematical models of dynamical system. WyNDA uses an Adaptive Observer to iteratively refine the approximation of the system's dynamics and estimate the associated parameters. This Adaptive Observer share conceptual similarity with Kalman Filter, particularly in its use of a prediction-update framework to correct estimates based on new measurements. </p> <p>Expressed continuous-time dynamical systems as :</p> \\[ \\newcommand{\\bm}[1]{\\boldsymbol{#1}} \\newcommand\\given[1][]{\\:#1\\vert\\:} \\begin{align} \\dot{\\bm{x}}_t &amp;= \\bm{f}\\left(\\bm{x}_t, \\bm{u}_t, \\bm{\\theta}\\right) \\\\ \\bm{x}_{t_0} &amp;= \\bm{x}_0 \\\\ \\bm{y}_k &amp;= \\bm{x}_k + \\bm{v}_k \\end{align} \\] <p>where \\(\\bm{x}_t\\) is the state vector, \\(\\bm{u}_t\\) is the control input, and \\(\\bm{\\theta}\\) is the parameter vector. Assume noise of sensor \\(\\bm{v}_k\\) with Gaussian distribution \\(\\bm{v}_k \\sim \\mathcal{N}\\left(0, \\bm{R}_k\\right)\\). The aim is to identify the unknown function \\(\\bm{f}\\) and the parameters \\(\\bm{\\theta}\\) from sensor data. W here \\(k\\) and \\(t\\) are discrete time and continuous time, respectively.</p>"},{"location":"robotics/sys_iden/wynda/#the-algorithm","title":"The Algorithm","text":"<p>The approximation model (step 1) Eq. (4) is expressed as follows : </p> \\[ \\begin{align} \\bm{x}(k+1) &amp;= \\bm{x}_k + \\bm{\\Psi}(\\bm{y}_k, \\bm{u}_k)\\bm{\\theta} \\\\ \\bm{x}(k+1) &amp;\\equiv \\bm{x}_k + \\bm{f}\\left(\\bm{x}_t, \\bm{u}_t, \\bm{\\theta} \\right) \\Delta{t} \\end{align} \\] <p>Eq. (5) is dynamical system represented by Euler discretization of Eq. (4). Where \\(\\bm{\\Psi}(\\bm{y}_k, \\bm{u}_k) \\in \\mathbb{R}^{n \\times r}\\) is approximation function, given by :</p> \\[ \\begin{align} \\bm{\\Psi}(\\bm{y}_k, \\bm{u}_k) &amp;= \\begin{pmatrix} \\Phi_1(\\bm{y}_k, \\bm{u}_k) &amp; 0 &amp; 0 &amp; \\cdots &amp; 0 \\\\ 0 &amp; \\Phi_2(\\bm{y}_k, \\bm{u}_k) &amp; 0 &amp; \\cdots &amp; 0 \\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ 0 &amp; 0 &amp; 0 &amp; \\cdots &amp; \\Phi_n(\\bm{y}_k, \\bm{u}_k) \\end{pmatrix}\\\\ \\bm{\\Phi}_{i}(\\bm{y}_k, \\bm{u}_k) &amp;=  \\begin{pmatrix} 1 &amp; u_{i,k} &amp; x_{i,k} &amp; y_{i,k}^2 &amp; y_{i,k} &amp; \\cdots &amp; y_{i,k}^2 \\sin(y_{i,k}) &amp; \\cdots &amp; \\cos(y_{i,k}) \\end{pmatrix}\\\\ \\end{align} \\] <p>Where \\(\\bm{\\Phi}_i\\in \\mathbf{R}^n\\), where \\(i = 1, 2, 3, \\cdots, n\\)  is selected based on intuition or derived from the system's dynamics. These dynamics may be governed by frameworks such as Newtonian, Lagrangian, or Hamiltonian mechanics, or other methodologies, like employed in WyNDA-UAV [2].  After build the approximation function, then applied adaptive observer to estimate approximation model in Eq. (4).</p>"},{"location":"robotics/sys_iden/wynda/#initial-condition","title":"Initial Condition","text":"Descriptions Variabels Dimensions Condition State Gain \\(\\bm{K}_{\\bm{x}(k)}\\) \\(\\mathbb{R}^{n \\times n}\\) N/A Parameter Gain \\(\\bm{K}_{\\bm{\\theta}(k)}\\) \\(\\mathbb{R}^{r \\times n}\\) N/A Mapping Matrix \\(\\bm{\\Gamma}_{k \\given k}\\) \\(\\mathbb{R}^{n \\times r}\\) N/A State Covariance \\(\\bm{P}_{\\bm{x}(k \\given k)}\\) \\(\\mathbb{R}^{n \\times n}\\) \\(&gt; 0\\) Parameter Covariance \\(\\bm{P}_{\\bm{\\theta}(k \\given k)}\\) \\(\\mathbb{R}^{r \\times r}\\) \\(&gt; 0\\) Noise State (Able to tuning) \\(\\bm{R}_{\\bm{x}(k)}\\) \\(\\mathbb{R}^{n \\times n}\\) \\(&gt; 0\\) Noise Parameter (Able to tuning) \\(\\bm{R}_{\\bm{\\theta}(k)}\\) \\(\\mathbb{R}^{n \\times n}\\) \\(&gt; 0\\) State Forgetting Factor (Able to tuning) \\(\\lambda_{\\bm{x}}\\) \\(\\mathbb{R}^{1}\\) \\(\\left[0, 1\\right]\\) Parameter State Forgetting Factor (Able to tuning) \\(\\lambda_{\\bm{\\theta}}\\) \\(\\mathbb{R}^{1}\\) \\(\\left[0, 1\\right]\\)"},{"location":"robotics/sys_iden/wynda/#state-update","title":"State Update","text":"\\[ \\begin{align} \\bar{\\bm{x}}_{k|k} = \\bar{\\bm{x}}_{k|k-1} + \\left(\\bm{K}_{x(k)} + \\bm{\\Gamma}_{k|k} \\bm{K}_{\\bm{\\theta}(k)}\\right)\\left( \\bm{y}_k - \\bar{\\bm{x}}_{k|k-1} \\right) \\end{align} \\] <p>Eq. (8) is the equation for estimate state \\(\\bar{\\bm{x}}_{k|k}\\) at time \\(k\\) based on predicted state estimate \\(\\bar{\\bm{x}}_{k|k-1}\\) at time \\(k\\) and current sensor measurment \\(\\bm{y}_k\\).  The correction term is a weighted combination of the state observer gain \\(\\bm{K}_{x(k)}\\) and the parameter gain \\(\\bm{\\Gamma}_{k|k}\\bm{K}_{\\bm{\\theta}(k)}\\) for the state and parameter influence, applied to the measurement residual.  Where \\(\\bm{\\Gamma}_{k|k}\\) is mapping matrix for the parameter estimates to state estimation.</p> <p></p> \\[ \\begin{align} \\bar{\\bm{\\theta}}_{k|k} = \\bar{\\bm{\\theta}}_{k|k-1} - \\bm{K}_{\\bm{\\theta}(k)}\\left(\\bm{y}_k - \\bar{\\bm{x}}_{k|k-1}\\right) \\end{align} \\] <p>Eq. (9) adjusts the parameter estimates \\(\\bar{\\bm{\\theta}}_{k|k}\\) using the measurement residual.  The correction is proportional to the error, and the proportionality factor is \\(\\bm{K}_{\\bm{\\theta}(k)}\\). </p>"},{"location":"robotics/sys_iden/wynda/#gain-update","title":"Gain Update","text":"\\[ \\begin{align} \\bm{K}_{\\bm{x}(k)} = \\bm{P}_{\\bm{x}_{k|k-1}}\\left[\\bm{P}_{\\bm{x}_{k|k-1}} + \\bm{R}_{\\bm{x}(k)}\\right]^{-1} \\end{align} \\] <p>Eq. (10) for updates state gain \\(\\bm{K}_{\\bm{x}(k)}\\) computed as a ratio of the state prediction error covariance to the total uncertainty (prediction error + state noise).  This gain determines how much the state estimate should be adjusted based on the new measurement. A larger \\(\\bm{R}_{\\bm{x}(k)}\\) reduces the impact of noisy measurements, more believe on predictions, vice versa. If the prediction is very uncertain \\(\\bm{P}_{\\bm{x}_{k|k-1}}\\) is large, but the state noise \\(\\bm{R}_{\\bm{x}(k)}\\) is small, so the algorithm more trust to sensor and adjust the estimation significantly, vice versa.</p> <p></p> \\[ \\begin{align} \\bm{K}_{\\bm{\\theta}(k)} = \\bm{P}_{\\bm{\\theta}_{k|k-1}}\\bm{\\Gamma}_{k|k-1}^T \\left[\\bm{\\Gamma}_{k|k-1} \\bm{P}_{\\bm{\\theta}(k|k-1)} \\bm{\\Gamma}_{k|k-1} + \\bm{R}_{\\bm{\\theta}(k)}\\right]^{-1} \\end{align} \\] <p>Eq. (11) for updates parameter gain \\(\\bm{K}_{\\bm{\\theta}(k)}\\) computed similarly as Eq. (10).  This gain determines how much the parameter estimate should be adjusted based on the new measurement.</p> <p></p> \\[ \\begin{align} \\bm{\\Gamma}_{k|k} = \\left(\\mathbf{I} - \\bm{K}_{\\bm{x}(k)}\\right)\\bm{\\Gamma}_{k|k-1} \\end{align} \\] <p>Eq. (12) for updated by scaling the previous \\(\\bm{\\Gamma}\\) by \\(\\left(\\mathbf{I} - \\bm{K}_{\\bm{x}(k)}\\right)\\).  This ensures that the relationship between parameter estimation and state estimation is adjusted based on the state gain. If the state update trusted  (\\(\\bm{K}_{\\bm{x}(k)}\\) is large), mapping matrix becomes weaker because the estimate is already reliable, vice versa.</p>"},{"location":"robotics/sys_iden/wynda/#state-prediction","title":"State Prediction","text":"\\[ \\begin{align} \\bar{\\bm{x}}_{k+1|k} = \\bar{\\bm{x}(k|k)} + \\Psi(\\bm{y}_k, \\bm{u}_k)\\bar{\\bm{\\theta}}_{k|k} \\end{align} \\] <p>Eq. (13) for predicted state at the next step using the current estimates.  This equations incorporating the effects of control inputs and parameter estimates weighted by the parameter estimate.  </p> <p></p> \\[ \\begin{align} \\bar{\\bm{\\theta}}_{k+1|k} = \\bar{\\bm{\\theta}}_{k|k} \\end{align} \\] <p>Assumes parameters are constant or piece-wise constant over a short time step in Eq. (14), so the prediction is simply the current estimate.</p> <p></p> \\[ \\begin{align} \\bm{P}_{\\bm{x}(k+1|k) }= \\frac{1}{\\lambda_{\\bm{x}}}\\left(\\bm{I} - \\bm{K}_{\\bm{x}(k)}\\right)\\bm{P}_{\\bm{x}(k|k-1)} \\end{align} \\] <p>State error covariance in Eq. (15) is updated by scaling the previous covariance by \\(\\left(\\bm{I} - \\bm{K}_{\\bm{x}(k)}\\right)\\) and applying the forgetting factor \\(\\lambda_{\\bm{x}}\\).</p> <p></p> \\[ \\begin{align} \\bm{P}_{\\bm{\\theta}(k+1|k)} = \\frac{1}{\\lambda_{\\bm{\\theta}}}\\left(\\bm{I} - \\bm{K}_{\\bm{\\theta}(k)}\\bm{\\Gamma}_{k|k-1}\\right)\\bm{P}_{\\theta(k|k-1)} \\end{align} \\] <p>Eq. (16) updates parameter error covariance similar to Eq. (15) but different forgetting factor.</p> <p></p> \\[ \\begin{align} \\bm{\\Gamma_{k+1|k}} = \\bm{\\Gamma}_{k|k} - \\bm{\\Psi}(\\bm{y}_k, \\bm{u}_k) \\end{align} \\] <p>Eq. (17) adjusts the parameter-to-state estimation mapping to align with system behavior.</p> <p>Forgetting Factor</p> <p>Lower values \\((\\lambda \\rightarrow 0)\\) more sensitive to new data (more trusts to new data).  Higher values \\((\\lambda \\rightarrow 1)\\) less sensitive to new data (more trusts to old data).  The forgetting factor \\(\\lambda\\) is trade-off between the stability and adaptability.</p> <p>After prediction step, convert the parameters in discrete to continunous by using \\(\\frac{\\bm{\\theta}}{\\Delta t}\\) </p>"},{"location":"robotics/sys_iden/wynda/#the-presistance-of-exicitation","title":"The Presistance of Exicitation","text":"<p>In short, Presistance of Exicitation (PE) is concept to ensures the input to the sytems sufficiently rich and varied to allow the algorithm reaches convergance of parameters estimitation. In WyNDA the PE condition state as follows :</p> \\[ \\begin{align} 0 &lt; \\kappa \\bm{I} \\leq \\sum_{i=\\kappa - \\xi}^\\kappa \\bm{\\Psi}(i)^T\\bm{\\Psi}(i) \\end{align} \\] <p>It state to ensure approximation function \\(\\bm{\\Psi(\\bm{y}_k, \\bm{u}_k)}\\) is rich and varied enough to estimates \"real\" parameters. If the condition satisfied, the algorithm convergenced exponentially (proven in WyNDA paper [1]). </p>"},{"location":"robotics/sys_iden/wynda/#references","title":"References","text":"<p>[1] WyNDA: A method to discover mathematical models of dynamical systems from data </p> <p>[2] Data-Driven Discovery of Unmanned Aerial Vehicles Dynamics </p>"}]}